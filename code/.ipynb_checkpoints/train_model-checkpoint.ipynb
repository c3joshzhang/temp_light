{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gurobipy as gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learn.train import build_inst, build_graphs, remove_redundant_nodes, get_train_mask, get_solution_mask, get_mask_node_feature\n",
    "from learn.model import Model, FocalLoss\n",
    "from learn.generator import maximum_independent_set_problem\n",
    "from learn.info import ModelInfo, VarInfo, ConInfo\n",
    "from learn import solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def with_lic(m):\n",
    "    with open(\"gb.lic\") as f:\n",
    "        env = gp.Env(params=json.load(f))\n",
    "    return m.copy(env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_constraint_side_matrices(var_info: VarInfo, con_info: ConInfo):\n",
    "\n",
    "    idxs = [[], []]\n",
    "    vals = []\n",
    "\n",
    "    for con_idx in tqdm(range(con_info.n)):\n",
    "        var_idxs = con_info.lhs_p[con_idx]\n",
    "        var_cefs = con_info.lhs_c[con_idx]\n",
    "        for var_idx, var_cef in zip(var_idxs, var_cefs):\n",
    "            idxs[0].append(con_idx)\n",
    "            idxs[1].append(var_idx)\n",
    "            vals.append(var_cef)\n",
    "\n",
    "    lhs = torch.sparse_coo_tensor(idxs, vals, (con_info.n, var_info.n))\n",
    "    rhs = np.array(con_info.rhs)[:, np.newaxis]\n",
    "    ops = np.array(con_info.types)[:, np.newaxis]\n",
    "    return lhs, rhs, ops\n",
    "\n",
    "\n",
    "def get_constraint_violations(lhs, vs, rhs, ops):\n",
    "    # TODO: add type handling/preprocessing\n",
    "    vs = torch.as_tensor(np.array(vs)[:, np.newaxis]).float()\n",
    "    lt_ops = ops == ConInfo.ENUM_TO_OP[\"<=\"]\n",
    "    eq_ops = ops == ConInfo.ENUM_TO_OP[\"==\"]\n",
    "    gt_ops = ops == ConInfo.ENUM_TO_OP[\">=\"]\n",
    "\n",
    "    lhs_vs = lhs @ vs\n",
    "    lhs_vs = lhs_vs.numpy()\n",
    "\n",
    "    diff = lhs_vs - rhs\n",
    "    violations = np.zeros_like(diff, dtype=bool)\n",
    "    violations[lt_ops] = diff[lt_ops] <= 0\n",
    "    violations[gt_ops] = diff[gt_ops] >= 0\n",
    "    violations[eq_ops] = diff[eq_ops] == 0\n",
    "    diff[violations] = 0\n",
    "    return np.abs(diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch._VariableFunctionsClass.tensor>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restricted license - for non-production use only - expires 2026-11-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 2489/2489 [00:00<00:00, 709117.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter CloudAccessID\n",
      "Set parameter CloudSecretKey\n",
      "Set parameter CloudPool to value \"831775-C3Dev\"\n",
      "Set parameter CSAppName to value \"Josh\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute Server job ID: 5cd76ef2-93cc-4129-9e65-038202ebccbf\n",
      "Capacity available on '831775-C3Dev' cloud pool - connecting...\n",
      "Established HTTPS encrypted connection\n",
      "Set parameter NoRelHeurTime to value 30\n",
      "Set parameter PoolSolutions to value 64\n",
      "Set parameter PoolSearchMode to value 2\n",
      "Gurobi Optimizer version 12.0.0 build v12.0.0rc1 (mac64[x86] - Darwin 22.4.0 22E252)\n",
      "Gurobi Compute Server Worker version 12.0.0 build v12.0.0rc1 (linux64 - \"Ubuntu 20.04.6 LTS\")\n",
      "\n",
      "CPU model: Intel(R) Xeon(R) Platinum 8375C CPU @ 2.90GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Non-default parameters:\n",
      "NoRelHeurTime  30\n",
      "CSIdleTimeout  1800\n",
      "PoolSolutions  64\n",
      "PoolSearchMode  2\n",
      "\n",
      "Optimize a model with 2489 rows, 129 columns and 4978 nonzeros\n",
      "Model fingerprint: 0x0700a2ed\n",
      "Variable types: 1 continuous, 128 integer (128 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Found heuristic solution: objective 11.0000000\n",
      "Presolve removed 1813 rows and 0 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 676 rows, 129 columns, 3003 nonzeros\n",
      "Variable types: 1 continuous, 128 integer (128 binary)\n",
      "Starting NoRel heuristic\n",
      "Found heuristic solution: objective 12.0000000\n",
      "Found heuristic solution: objective 13.0000000\n",
      "Found heuristic solution: objective 14.0000000\n",
      "Found heuristic solution: objective 15.0000000\n",
      "Elapsed time for NoRel heuristic: 7s (best bound 25.3269)\n",
      "Elapsed time for NoRel heuristic: 12s (best bound 25.3269)\n",
      "Elapsed time for NoRel heuristic: 18s (best bound 25.3269)\n",
      "Elapsed time for NoRel heuristic: 25s (best bound 25.3269)\n",
      "Elapsed time for NoRel heuristic: 31s (best bound 25.3269)\n",
      "NoRel heuristic complete\n",
      "Root relaxation presolved: 676 rows, 129 columns, 3003 nonzeros\n",
      "\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    5.3000000e+01   5.890000e+02   0.000000e+00     31s\n",
      "     557    2.5326940e+01   0.000000e+00   0.000000e+00     31s\n",
      "\n",
      "Root relaxation: objective 2.532694e+01, 557 iterations, 0.02 seconds (0.04 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0   25.32694    0  127   15.00000   25.32694  68.8%     -   31s\n",
      "     0     0   25.03731    0  127   15.00000   25.03731  66.9%     -   31s\n",
      "     0     0   25.03731    0  127   15.00000   25.03731  66.9%     -   31s\n",
      "     0     0   24.57990    0  128   15.00000   24.57990  63.9%     -   31s\n",
      "     0     0   24.55193    0  128   15.00000   24.55193  63.7%     -   31s\n",
      "     0     0   24.41872    0  128   15.00000   24.41872  62.8%     -   31s\n",
      "     0     0   24.41872    0  128   15.00000   24.41872  62.8%     -   31s\n",
      "     0     0   24.14499    0  128   15.00000   24.14499  61.0%     -   31s\n",
      "     0     0   24.14499    0  128   15.00000   24.14499  61.0%     -   31s\n",
      "     0     2   24.14499    0  128   15.00000   24.14499  61.0%     -   31s\n",
      "  7645  4375   18.59767   59   78   15.00000   18.59767  24.0%  34.1   35s\n",
      "\n",
      "Optimal solution found at node 18289 - now completing solution pool...\n",
      "\n",
      "    Nodes    |    Current Node    |      Pool Obj. Bounds     |     Work\n",
      "             |                    |   Worst                   |\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      " 18289  1453     cutoff   31        14.00000   15.78049  12.7%  28.0   36s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 2\n",
      "  Clique: 13\n",
      "  Zero half: 3\n",
      "\n",
      "Explored 21354 nodes (546608 simplex iterations) in 36.28 seconds (40.35 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 64: 15 15 15 ... 14\n",
      "No other solutions better than 14\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.500000000000e+01, best bound 1.500000000000e+01, gap 0.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 64/64 [00:14<00:00,  4.57it/s]\n"
     ]
    }
   ],
   "source": [
    "def collect_feasible_solutions(model, n=64):\n",
    "    model.setParam('PoolSolutions', n)\n",
    "    model.setParam('PoolSearchMode', 2)\n",
    "    model.optimize()\n",
    "    \n",
    "    vs = model.getVars()\n",
    "    sols = []\n",
    "    for i in tqdm(range(model.SolCount)):\n",
    "        # TODO setting solution number actually takes long time\n",
    "        # try to optimize\n",
    "        model.params.SolutionNumber = i\n",
    "        obj_val = model.PoolObjVal\n",
    "        s = [v.Xn for v in vs]\n",
    "        sols.append((s, obj_val))\n",
    "    return sols\n",
    "        \n",
    "m = maximum_independent_set_problem(num_nodes=128)\n",
    "info = ModelInfo.from_model(m)\n",
    "\n",
    "lhs, rhs, ops = get_constraint_side_matrices(info.var_info, info.con_info)\n",
    "\n",
    "m = with_lic(m)\n",
    "m.params.NoRelHeurTime = 30\n",
    "s = collect_feasible_solutions(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sv(sol):\n",
    "    violation = get_constraint_violations(lhs, sol, rhs, ops) \n",
    "    return not any(violation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_solution(solution, validator, n=32, ratio=0.1):\n",
    "    \n",
    "    n_vars = len(solution)\n",
    "    rand_idxs = np.random.randint(0, len(solution), size=max(int(n_vars * ratio), 1))\n",
    "    \n",
    "    pos = []\n",
    "    neg = []\n",
    "\n",
    "    for _ in tqdm(range(n)):\n",
    "        cur_pos = []\n",
    "        cur_neg = []\n",
    "\n",
    "        s = solution\n",
    "        p = []\n",
    "        for i in rand_idxs:\n",
    "            \n",
    "            s = s.copy()\n",
    "            s[i] = 1 - s[i]\n",
    "            p.append(i)\n",
    "            perturbed = (s, p.copy())\n",
    "            \n",
    "            if cur_neg:\n",
    "                cur_neg.append(perturbed)\n",
    "                continue\n",
    "                \n",
    "            valid = validator(s)\n",
    "            if not valid:\n",
    "                cur_neg.append(perturbed)\n",
    "            else:\n",
    "                cur_pos.append(perturbed)\n",
    "\n",
    "        pos.extend(cur_pos)\n",
    "        neg.extend(cur_neg)\n",
    "        \n",
    "    return pos, neg\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 3212.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 1209.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 1890.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 3851.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 1766.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 1317.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 3367.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 3816.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 2927.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 4474.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 3960.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 2451.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 4152.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 4302.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 2610.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 3704.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 2207.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 2008.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 4696.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 2848.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 3895.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 3566.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 2648.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 2991.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 2873.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 2247.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1000/1000 [00:00<00:00, 3930.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|████████████████▊     | 762/1000 [00:00<00:00, 4405.27it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m each \u001b[38;5;129;01min\u001b[39;00m s:\n\u001b[0;32m----> 2\u001b[0m     pos, neg \u001b[38;5;241m=\u001b[39m \u001b[43mperturb_solution\u001b[49m\u001b[43m(\u001b[49m\u001b[43meach\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(pos))\n",
      "Cell \u001b[0;32mIn[49], line 28\u001b[0m, in \u001b[0;36mperturb_solution\u001b[0;34m(solution, validator, n, ratio)\u001b[0m\n\u001b[1;32m     26\u001b[0m valid \u001b[38;5;241m=\u001b[39m validator(s)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid:\n\u001b[0;32m---> 28\u001b[0m     \u001b[43mcur_neg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperturbed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     cur_pos\u001b[38;5;241m.\u001b[39mappend(perturbed)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for each in s:\n",
    "    pos, neg = perturb_solution(each[0], sv, n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 1 == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[0][0] == s[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m.setParam(\"PoolSolutions\", int(1e5))\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect solutions\n",
    "# random pertub to get feasible - infeasible solution\n",
    "    # continue infeasible solution\n",
    "    # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "inst = build_inst(maximum_independent_set_problem, 4096)\n",
    "graphs = build_graphs(inst)\n",
    "for g in graphs:\n",
    "    remove_redundant_nodes(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_feat_size = 2\n",
    "n_node_feats = graphs[0].ndata['feat'].shape[1] + mask_feat_size\n",
    "n_edge_feats = graphs[0].edata['feat'].shape[1]\n",
    "num_classes = int(graphs[0].ndata['label'].max()) + 1\n",
    "hidden_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(n_node_feats, n_edge_feats, hidden_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiLabelFocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-label Focal Loss for each class independently.\n",
    "    \n",
    "    Args:\n",
    "        alpha (float): Weighting factor for positive examples. Default: 0.25 (commonly 0.25 or 0.5).\n",
    "        gamma (float): Exponent for down-weighting easy examples. Default: 2.0.\n",
    "        reduction (str): 'mean', 'sum' or 'none'. Default: 'mean'.\n",
    "\n",
    "    Shapes:\n",
    "        pred: (batch_size, num_classes) - raw, unnormalized logits\n",
    "        target: (batch_size, num_classes) - multi-label targets in {0,1}\n",
    "\n",
    "    Example usage:\n",
    "        criterion = MultiLabelFocalLoss(alpha=0.5, gamma=2.0, reduction='mean')\n",
    "        logits = torch.randn(batch_size, num_classes)  # model outputs\n",
    "        targets = torch.randint(0, 2, (batch_size, num_classes)).float()\n",
    "        loss = criterion(logits, targets)\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n",
    "        super(MultiLabelFocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, probs, target):\n",
    "        # pred: (m, n) raw logits\n",
    "        # target: (m, n) in {0, 1}\n",
    "        \n",
    "        # Apply sigmoid to get probabilities\n",
    "        # probs = torch.sigmoid(pred)  # (m, n)\n",
    "        # Add a small epsilon to avoid log(0)\n",
    "        eps = 1e-8\n",
    "\n",
    "        # Calculate the focal loss\n",
    "        # Positive term\n",
    "        pos_loss = -self.alpha * (1 - probs).pow(self.gamma) * target * torch.log(probs + eps)\n",
    "        # Negative term\n",
    "        neg_loss = -(1 - self.alpha) * probs.pow(self.gamma) * (1 - target) * torch.log(1 - probs + eps)\n",
    "\n",
    "        loss = pos_loss + neg_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:  # 'none'\n",
    "            return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "print(\"Total number of graphs\", len(graphs))\n",
    "num_epochs = 5000\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    cntr = 0\n",
    "    loss = 0\n",
    "\n",
    "    random.shuffle(graphs)\n",
    "    for i, g in enumerate(graphs):\n",
    "\n",
    "        train_mask = get_train_mask(g, ratio=1.0)\n",
    "        solution_mask = get_solution_mask(train_mask, (0.2, 0.8))\n",
    "        node_feat_with_hint, hint_mask = get_mask_node_feature(g.ndata['feat'], g.ndata['label'], solution_mask)\n",
    "        \n",
    "        probs, dists = model(g, node_feat_with_hint, g.edata['feat'])\n",
    "        labels = g.ndata['label']\n",
    "        distances = g.ndata['distance'].float()\n",
    "\n",
    "        n_vars = g.ndata['feat'][:, 2].sum().int()\n",
    "        \n",
    "        fkl = MultiLabelFocalLoss()(\n",
    "            probs[:n_vars][~hint_mask[:n_vars]], \n",
    "            labels[:n_vars][~hint_mask[:n_vars]]\n",
    "        )\n",
    "        msl = MultiLabelFocalLoss()(\n",
    "            dists[:n_vars][hint_mask[:n_vars]], \n",
    "            distances[:n_vars][hint_mask[:n_vars]]\n",
    "        )\n",
    "        loss += fkl + msl\n",
    "        cntr += 1\n",
    "\n",
    "        if cntr == 256:\n",
    "            print(\"loss\", loss.detach().numpy())\n",
    "            print(\"#\"*78)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimizer.step()\n",
    "\n",
    "            loss = 0\n",
    "            cntr = 0\n",
    "\n",
    "    print(\"-\"*78)\n",
    "    print(probs[:n_vars][~hint_mask[:n_vars]].detach().numpy())\n",
    "    print(labels[:n_vars][~hint_mask[:n_vars]].detach().numpy())\n",
    "    print(\">\"*78)\n",
    "    print(dists[:n_vars][hint_mask[:n_vars]].detach().numpy())\n",
    "    print(distances[:n_vars][hint_mask[:n_vars]].detach().numpy())\n",
    "    print('^'*78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = maximum_independent_set_problem(num_nodes=128, edge_prob=0.5)\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = build_inst(lambda: maximum_independent_set_problem(num_nodes=128), 1)\n",
    "graphs = build_graphs(inst)\n",
    "for g in graphs:\n",
    "    remove_redundant_nodes(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL[0]\n",
    "model_vars = MODEL[0].getVars()\n",
    "model_vars[56].BranchPriority = 3\n",
    "model_vars[42].BranchPriority = 2\n",
    "model_vars[2].BranchPriority = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL[0].optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gb.lic\") as f:\n",
    "    env = gp.Env(params=json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import gurobipy as gp\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "MODEL = []\n",
    "def maximum_independent_set_problem(\n",
    "    num_nodes=128,\n",
    "    edge_prob=0.3,\n",
    ") -> gp.Model:\n",
    "    edges = []\n",
    "    num_nodes = random.randint(num_nodes-10, num_nodes)\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(i + 1, num_nodes):\n",
    "            if np.random.rand() < edge_prob:\n",
    "                edges.append((i, j))\n",
    "\n",
    "    m = gp.Model(\"maximum_independent_set\")\n",
    "    x = m.addVars(num_nodes, vtype=gp.GRB.BINARY, name=\"x\")\n",
    "\n",
    "    for i, j in edges:\n",
    "        m.addConstr(x[i] + x[j] <= 1, name=f\"edge_{i}_{j}\")\n",
    "\n",
    "    m.setObjective(gp.quicksum(x[i] for i in range(num_nodes)), gp.GRB.MAXIMIZE)\n",
    "    m.update()\n",
    "    MODEL.append(m.copy())\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = build_inst(maximum_independent_set_problem, 1, env=env)\n",
    "graphs = build_graphs(inst)\n",
    "for g in graphs:\n",
    "    remove_redundant_nodes(g)\n",
    "\n",
    "graph = graphs[0]\n",
    "is_var_flag_idx = 2\n",
    "var_flag = graph.ndata[\"feat\"][:, is_var_flag_idx]\n",
    "size = list(var_flag[var_flag == 1].size())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g.ndata['label'][:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "importances = {i: 0 for i in range(size)}\n",
    "\n",
    "for trial_idx in tqdm(range(500)):\n",
    "        \n",
    "    prev_count = 0\n",
    "    seeds = torch.zeros((g.ndata['feat'].shape[0], 2))\n",
    "    trail_importance = {i: 0 for i in range(size)}\n",
    "    while (seeds[:size, 1] == 0).any():\n",
    "        \n",
    "        for i in range(size//20):\n",
    "            rand_var_idx = random.randint(0, size)\n",
    "            rand_var_val = random.randint(0, 1)\n",
    "            seeds[rand_var_idx, 0] = rand_var_val\n",
    "            seeds[rand_var_idx, 1] = 1\n",
    "            \n",
    "        feat = torch.hstack([g.ndata['feat'], seeds])    \n",
    "        probs, dists = model(g, feat, g.edata['feat'])\n",
    "\n",
    "        new_vars = set()\n",
    "        for i in range(size):\n",
    "            if seeds[i, 1] == 1:\n",
    "                continue\n",
    "                \n",
    "            if probs[i, 0] >= 0.9:\n",
    "                seeds[i, 0] = 0\n",
    "                seeds[i, 1] = 1\n",
    "                new_vars.add(i)\n",
    "                \n",
    "            if probs[i, 1] >= 0.9:\n",
    "                seeds[i, 0] = 1\n",
    "                seeds[i, 1] = 1\n",
    "                new_vars.add(i)\n",
    "                \n",
    "        curr_count = seeds[:size, 1].sum()\n",
    "        if curr_count == prev_count:\n",
    "            for k in trail_importance:\n",
    "                trail_importance[k] = -trail_importance[k]\n",
    "            break\n",
    "\n",
    "        impv = curr_count - prev_count\n",
    "        for nv in new_vars:\n",
    "            trail_importance[nv] += impv/len(new_vars)\n",
    "        \n",
    "        prev_count = curr_count\n",
    "        \n",
    "    for k in importances:\n",
    "        importances[k] += trail_importance[k] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from functools import partial\n",
    "from typing import Callable, List, Tuple, Union\n",
    "\n",
    "import dgl\n",
    "import gurobipy as gp\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from learn.feature import ConFeature, EdgFeature, VarFeature\n",
    "from learn.info import ModelInfo\n",
    "\n",
    "__DEVICE_PTR = [torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")]\n",
    "\n",
    "\n",
    "def SET_DEVICE(device):\n",
    "    __DEVICE_PTR[0] = device\n",
    "\n",
    "\n",
    "def GET_DEVICE():\n",
    "    return __DEVICE_PTR[0]\n",
    "\n",
    "\n",
    "class Inst:\n",
    "    def __init__(\n",
    "        self,\n",
    "        v_features: List[VarFeature],\n",
    "        c_features: List[ConFeature],\n",
    "        e_features: List[EdgFeature],\n",
    "        solutions: List[List[Union[float, int]]],\n",
    "        distances: List[List[Union[float, int]]],\n",
    "    ):\n",
    "        assert len(v_features) == len(c_features) == len(e_features) == len(solutions)\n",
    "        self.v_features = v_features\n",
    "        self.c_features = c_features\n",
    "        self.e_features = e_features\n",
    "        self.solutions = solutions\n",
    "        self.distances = distances\n",
    "\n",
    "    @property\n",
    "    def n(self):\n",
    "        return len(self.solutions)\n",
    "\n",
    "    # TODO: use consistent naming for getting the features\n",
    "    @property\n",
    "    def xs(self):\n",
    "\n",
    "        n_var = []\n",
    "        n_con = []\n",
    "        c_v_edges = []\n",
    "        v_c_edges = []\n",
    "        node_features = []\n",
    "\n",
    "        for i in range(self.n):\n",
    "\n",
    "            # [v0, v1, v2, ... c0, c1, c2]\n",
    "            var_xs = self.v_features[i].values\n",
    "            con_xs = self.c_features[i].values\n",
    "\n",
    "            # TODO: use dgl or pyg to remove the need of padding\n",
    "            con_xs, var_xs = self._pad_features(con_xs, var_xs)\n",
    "            n_var.append(len(var_xs))\n",
    "            n_con.append(len(con_xs))\n",
    "            xs = np.vstack([var_xs, con_xs])\n",
    "            node_features.append(torch.as_tensor(xs, dtype=torch.float32))\n",
    "\n",
    "            con_idxs, var_idxs = self.e_features[i].indices\n",
    "            con_idxs, var_idxs = self._shift_idxs(con_idxs, var_idxs, len(var_xs))\n",
    "            assert len(con_idxs) == len(var_idxs)\n",
    "\n",
    "            cve = []\n",
    "            vce = []\n",
    "\n",
    "            n_edges = len(con_idxs)\n",
    "            for i in range(n_edges):\n",
    "                cve.append([con_idxs[i], var_idxs[i]])\n",
    "                vce.append([var_idxs[i], con_idxs[i]])\n",
    "            cve = torch.as_tensor(cve, dtype=torch.int)\n",
    "            vce = torch.as_tensor(vce, dtype=torch.int)\n",
    "\n",
    "            c_v_edges.append(cve)\n",
    "            v_c_edges.append(vce)\n",
    "\n",
    "        edge_features = [\n",
    "            torch.as_tensor(f.values, dtype=torch.float32) for f in self.e_features\n",
    "        ]\n",
    "        return c_v_edges, v_c_edges, node_features, edge_features, n_var, n_con\n",
    "\n",
    "    @staticmethod\n",
    "    def _shift_idxs(con_idxs, var_idxs, n_vars):\n",
    "        # [v0, v1, v2, ... c0, c1, c2]\n",
    "        return con_idxs + n_vars, var_idxs\n",
    "\n",
    "    @staticmethod\n",
    "    def _pad_features(con_xs, var_xs):\n",
    "        con_x_dim = con_xs.shape[1]\n",
    "        var_x_dim = var_xs.shape[1]\n",
    "\n",
    "        if con_x_dim < var_x_dim:\n",
    "            pad_size = var_x_dim - con_x_dim\n",
    "            con_xs = np.pad(\n",
    "                con_xs,\n",
    "                pad_width=((0, 0), (0, pad_size)),\n",
    "                mode=\"constant\",\n",
    "                constant_values=0,\n",
    "            )\n",
    "\n",
    "        if var_x_dim < con_x_dim:\n",
    "            pad_size = con_x_dim - var_x_dim\n",
    "            var_xs = np.pad(\n",
    "                var_xs,\n",
    "                pad_width=((0, 0), (0, pad_size)),\n",
    "                mode=\"constant\",\n",
    "                constant_values=0,\n",
    "            )\n",
    "\n",
    "        return con_xs, var_xs\n",
    "\n",
    "    @property\n",
    "    def ys(self):\n",
    "        # TODO: handle other type of x\n",
    "        values = []\n",
    "        for i, s in enumerate(self.solutions):\n",
    "\n",
    "            # TODO: use accessor method\n",
    "            n_constr = len(self.c_features[i].values)\n",
    "\n",
    "            # TODO: remove padding\n",
    "            # TODO: replace with hetro-graph\n",
    "\n",
    "            arr = np.array([[0, 1] if v == 1 else [1, 0] for v in s] + [[0, 0]] * n_constr)\n",
    "            values.append(torch.as_tensor(arr, dtype=torch.int32))\n",
    "\n",
    "        distances = []\n",
    "        for i, d in enumerate(self.distances):\n",
    "\n",
    "            # TODO: use accessor method\n",
    "            n_constr = len(self.c_features[i].values)\n",
    "\n",
    "            # TODO: remove padding\n",
    "            # TODO: replace with hetro-graph\n",
    "            arr = np.array(d + [[0, 0, 0]] * n_constr)\n",
    "            distances.append(torch.as_tensor(arr, dtype=torch.int32))\n",
    "\n",
    "        return values, distances\n",
    "\n",
    "\n",
    "def get_train_mask(graph, ratio: float):\n",
    "    \"\"\"return mask for solution that can be included as hint\"\"\"\n",
    "    assert 0.0 <= ratio <= 1.0\n",
    "    is_var_flag_idx = 2\n",
    "    var_flag = graph.ndata[\"feat\"][:, is_var_flag_idx]\n",
    "    size = list(var_flag[var_flag == 1].size())[0]\n",
    "    n_include = int(round(size * ratio))\n",
    "    mask = torch.zeros(size, dtype=torch.bool)\n",
    "    idx = torch.randperm(size)[:n_include]\n",
    "    mask[idx] = 1\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_solution_mask(\n",
    "    mask: torch.Tensor, ratio: Union[float, Tuple[float, float]] = (0.5, 1.0)\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"get solution mask that has ratio between given ratio range that can be included as hint\"\"\"\n",
    "    mask = mask.clone()\n",
    "    ones_indices = torch.where(mask == 1)[0]\n",
    "    ratio = (ratio, ratio) if isinstance(ratio, float) else ratio\n",
    "    assert 0.0 <= ratio[0] <= 1.0 and 0.0 <= ratio[1] <= 1.0\n",
    "\n",
    "    min_num_keep = int(round(len(ones_indices) * ratio[0]))\n",
    "    max_num_keep = int(round(len(ones_indices) * ratio[1]))\n",
    "    max_num_keep = max(min_num_keep, max_num_keep)\n",
    "    num_keep = random.randint(min_num_keep, max_num_keep)\n",
    "\n",
    "    if num_keep <= 0:\n",
    "        mask[ones_indices] = 0\n",
    "        return mask\n",
    "\n",
    "    if num_keep >= len(ones_indices):\n",
    "        return mask\n",
    "\n",
    "    selected_indices = torch.randperm(len(ones_indices))[:num_keep]\n",
    "    keep_indices = ones_indices[selected_indices]\n",
    "    mask[ones_indices] = 0\n",
    "    mask[keep_indices] = 1\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_mask_node_feature(node_feature, y, mask):\n",
    "    \"\"\"add mask and hint into feature\"\"\"\n",
    "    node_feature_with_y = torch.hstack([node_feature, (y[:, 1] == 0).unsqueeze(1)])\n",
    "    mask = torch.cat([mask, torch.zeros(len(y) - len(mask), dtype=torch.bool)])\n",
    "    masked = node_feature_with_y.clone()\n",
    "    masked[~mask, -1] = 0\n",
    "    return torch.hstack([masked, mask.unsqueeze(1)]), mask\n",
    "\n",
    "\n",
    "def build_graphs(inst):\n",
    "    c_v_edges, v_c_edges, node_features, edge_features, _, _ = inst.xs\n",
    "    ys, dists = inst.ys\n",
    "\n",
    "    graphs = []\n",
    "    for i in range(len(ys)):\n",
    "        srcs = torch.cat([c_v_edges[i][:, 0], v_c_edges[i][:, 0]])\n",
    "        dsts = torch.cat([c_v_edges[i][:, 1], v_c_edges[i][:, 1]])\n",
    "\n",
    "        # TODO: replace with hetro-graph\n",
    "        g = dgl.graph((srcs, dsts))\n",
    "        g.ndata[\"feat\"] = node_features[i]\n",
    "        g.ndata[\"label\"] = ys[i]\n",
    "        g.ndata[\"distance\"] = dists[i]\n",
    "        g.edata[\"feat\"] = torch.cat([edge_features[i], edge_features[i]])\n",
    "        assert (g.in_degrees() == g.out_degrees()).all()\n",
    "        graphs.append(g)\n",
    "\n",
    "    return graphs\n",
    "\n",
    "MODEL = []\n",
    "def build_inst(model_generator: Callable[[], gp.Model], n=1024, env=None) -> Inst:\n",
    "\n",
    "    # if env is None:\n",
    "    #     with open(\"gb.lic\") as f:\n",
    "    #         params = json.load(f)\n",
    "    #         env = gp.Env(params=params)\n",
    "\n",
    "    var_feats = []\n",
    "    con_feats = []\n",
    "    edg_feats = []\n",
    "    solutions = []\n",
    "    distances = []\n",
    "\n",
    "    for _ in range(n):\n",
    "        raw_m = model_generator()\n",
    "        MODEL.append(raw_m.copy())\n",
    "        info = ModelInfo.from_model(raw_m)\n",
    "        vf = VarFeature.from_info(info.var_info, info.obj_info)\n",
    "        cf = ConFeature.from_info(info.con_info)\n",
    "        ef = EdgFeature.from_info(info.con_info)\n",
    "        \n",
    "        m = raw_m if env is None else raw_m.copy(env=env) \n",
    "        m.update()\n",
    "\n",
    "        ss = []\n",
    "        vs = m.getVars()\n",
    "        m.optimize(partial(_collect_mip_sol, variables=vs, collection=ss))\n",
    "\n",
    "        final_s = [v.X for v in vs]\n",
    "        if ss and ss[-1] != final_s:\n",
    "            ss.append(final_s)\n",
    "\n",
    "        for s in ss:\n",
    "            var_feats.append(vf)\n",
    "            con_feats.append(cf)\n",
    "            edg_feats.append(ef)\n",
    "            solutions.append(s)\n",
    "            d = []\n",
    "            for v1, v2 in zip(s, ss[-1]):\n",
    "                if v1 == v2:\n",
    "                    d.append([0, 1, 0])\n",
    "                    continue\n",
    "                if v1 < v2:\n",
    "                    d.append([0, 0, 1])\n",
    "                    continue\n",
    "                if v1 > v2:\n",
    "                    d.append([1, 0, 0])\n",
    "                    continue\n",
    "            distances.append(d)\n",
    "\n",
    "        raw_m.dispose()\n",
    "        m.dispose()\n",
    "\n",
    "    return Inst(var_feats, con_feats, edg_feats, solutions, distances)\n",
    "\n",
    "\n",
    "def remove_redundant_nodes(g) -> None:\n",
    "    to_remove = (g.in_degrees() == 0).nonzero().reshape(-1).int()\n",
    "    g.remove_nodes(to_remove)\n",
    "\n",
    "\n",
    "# TODO: take the objective value into consideration and weight the sample\n",
    "def _collect_mip_sol(\n",
    "    model: gp.Model, where: int, variables: List, collection: List\n",
    ") -> None:\n",
    "    if where == gp.GRB.Callback.MIPSOL:\n",
    "        s = model.cbGetSolution(variables)\n",
    "        collection.append(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_solve = with_lic(MODEL[0])\n",
    "to_set = to_solve.getVars()\n",
    "\n",
    "imp = 1\n",
    "for vidx, _ in sorted(importances.items(), key=lambda tup: tup[1])[-len(to_set)//4: ]:\n",
    "    to_set[vidx].branch_priority = imp\n",
    "    imp += 1\n",
    "to_solve.update()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_solve.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "for i in range(size//6):\n",
    "    rand_var_idx = random.randint(0, size)\n",
    "    rand_var_val = random.randint(0, 1)\n",
    "    seeds[rand_var_idx, 0] = rand_var_val\n",
    "    seeds[rand_var_idx, 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = torch.hstack([g.ndata['feat'], seeds])    \n",
    "probs, dists = model(g, feat, g.edata['feat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(size):\n",
    "    if seeds[i, 1] == 1:\n",
    "        continue\n",
    "    if probs[i, 0] >= 0.9:\n",
    "        seeds[i, 0] = 0\n",
    "        seeds[i, 1] = 1\n",
    "    if probs[i, 1] >= 0.9:\n",
    "        seeds[i, 0] = 1\n",
    "        seeds[i, 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = torch.hstack([g.ndata['feat'], seeds])    \n",
    "probs, dists = model(g, feat, g.edata['feat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(size):\n",
    "    if seeds[i, 1] == 1:\n",
    "        continue\n",
    "    if probs[i, 0] >= 0.9:\n",
    "        seeds[i, 0] = 0\n",
    "        seeds[i, 1] = 1\n",
    "    if probs[i, 1] >= 0.9:\n",
    "        seeds[i, 0] = 1\n",
    "        seeds[i, 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
