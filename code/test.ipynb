{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch torch_geometric torch-scatter pandas scikit-learn wandb dill openpyxl torchmetrics\n",
    "# python -m pip install gurobipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temp.data.gen import parallel_generate_problem, parallel_generate_solutions\n",
    "from temp.data.problem import setcover, lot_sizing\n",
    "from temp.data.info import ModelInfo\n",
    "from temp.data.dataset import ModelGraphDataset\n",
    "from temp.data.aug import parallel_augment_info, augment_info\n",
    "\n",
    "\n",
    "from temp.solver.utils import solve_inst, with_lic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAIN_DIR = \"temp/pre_train_tiny\"\n",
    "TRAIN_DIR = \"temp/train_tiny\"\n",
    "VALID_DIR = \"temp/valid_tiny\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"gb.lic\") as f:\n",
    "    lic = json.load(f)\n",
    "\n",
    "# parallel_generate_problem(lot_sizing, PRE_TRAIN_DIR, 100, 10)\n",
    "# parallel_generate_solutions(PRE_TRAIN_DIR, 5, lic=lic)\n",
    "\n",
    "# parallel_generate_problem(lot_sizing, TRAIN_DIR, 100, 10)\n",
    "# parallel_generate_solutions(TRAIN_DIR, 5, lic=lic)\n",
    "\n",
    "# parallel_generate_problem(lot_sizing, VALID_DIR, 100, 10)\n",
    "# parallel_generate_solutions(VALID_DIR, 5, lic=lic)\n",
    "# assert 1 == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # Define the source and destination folders\n",
    "# src_folder = \"temp/valid_ls\"\n",
    "# dest_folder = \"temp/valid_ls_backup\"\n",
    "\n",
    "# # Create the destination folder if it doesn't exist\n",
    "# os.makedirs(dest_folder, exist_ok=True)\n",
    "\n",
    "# # List all files in the source folder\n",
    "# files = os.listdir(src_folder)\n",
    "\n",
    "# # First, process all .lp files: if a corresponding .npz file exists, move both to \"done\"\n",
    "# for file_name in os.listdir(src_folder):\n",
    "#     if file_name.endswith(\".lp\"):\n",
    "#         lp_path = os.path.join(src_folder, file_name)\n",
    "#         base_name = os.path.splitext(file_name)[0]\n",
    "#         npz_file = base_name + \".npz\"\n",
    "#         npz_path = os.path.join(src_folder, npz_file)\n",
    "        \n",
    "#         # If the corresponding .npz exists, move both files\n",
    "#         if os.path.exists(npz_path):\n",
    "#             shutil.move(lp_path, os.path.join(dest_folder, file_name))\n",
    "#             shutil.move(npz_path, os.path.join(dest_folder, npz_file))\n",
    "#             print(f\"Moved pair: {file_name} and {npz_file}\")\n",
    "\n",
    "# # Next, remove any .npz files that are left without a corresponding .lp file.\n",
    "# for file_name in os.listdir(src_folder):\n",
    "#     if file_name.endswith(\".npz\"):\n",
    "#         base_name = os.path.splitext(file_name)[0]\n",
    "#         lp_file = base_name + \".lp\"\n",
    "#         lp_path = os.path.join(src_folder, lp_file)\n",
    "#         npz_path = os.path.join(src_folder, file_name)\n",
    "        \n",
    "#         if not os.path.exists(lp_path):\n",
    "#             os.remove(npz_path)\n",
    "#             print(f\"Removed orphan npz: {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = lot_sizing()\n",
    "# model = m\n",
    "\n",
    "# # model.setParam(\"OutputFlag\", 0)\n",
    "# model.setParam(\"PoolSolutions\", 10)\n",
    "# model.setParam(\"PoolSearchMode\", 2)\n",
    "# model = with_lic(model)\n",
    "# model.optimize()\n",
    "\n",
    "# vs = model.getVars()\n",
    "# obj_val_and_sols = []\n",
    "\n",
    "# for i in range(model.SolCount):\n",
    "#     # TODO: setting solution number actually takes long time try to optimize\n",
    "#     # TODO: add function to round by tolerance\n",
    "#     model.params.SolutionNumber = i\n",
    "#     obj_val = model.PoolObjVal\n",
    "#     s = [obj_val] + [v.Xn for v in vs]\n",
    "#     obj_val_and_sols.append(s)\n",
    "# model.dispose()\n",
    "\n",
    "# info = ModelInfo.from_model(m)\n",
    "# info.var_info.sols = np.array(obj_val_and_sols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from temp.data.dataset import info_to_data\n",
    "# d = info_to_data(info)\n",
    "# aug = partial(parallel_augment_info, n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pickle\n",
    "# from temp.data.aug import augment_info, get_constraint_violations, get_lhs_matrix\n",
    "\n",
    "# for p in os.listdir(os.path.join(PRE_TRAIN_DIR, \"processed\")):\n",
    "#     if not p.endswith(\"pkl\"):\n",
    "#         continue\n",
    "#     with open(os.path.join(PRE_TRAIN_DIR, \"processed\", p), \"rb\") as f:\n",
    "#         info = pickle.load(f)\n",
    "\n",
    "#     lhs = get_lhs_matrix(info.var_info.n, info.con_info)\n",
    "#     rhs = np.array(info.con_info.rhs)\n",
    "#     ops = np.array(info.con_info.types)\n",
    "#     violations = get_constraint_violations(lhs, info.var_info.sols[0, 1:], rhs, ops)\n",
    "#     assert not (np.abs(violations) >= 1e-5).any(), violations\n",
    "\n",
    "    \n",
    "#     # for _ in range(100):\n",
    "#     #     aug_info = info.copy()\n",
    "#     #     augment_info(aug_info)\n",
    "#     #     lhs = get_lhs_matrix(aug_info.var_info.n, aug_info.con_info)\n",
    "#     #     rhs = np.array(aug_info.con_info.rhs)\n",
    "#     #     ops = np.array(aug_info.con_info.types)\n",
    "#     #     violations = get_constraint_violations(lhs, aug_info.var_info.sols[0, 1:], rhs, ops)\n",
    "#     #     assert not (np.abs(violations) >= 1e-5).any(), violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "\n",
    "from temp.data.info import ModelInfo\n",
    "from temp.data.problem import lot_sizing, setcover\n",
    "from temp.solver.utils import with_lic\n",
    "\n",
    "B_TYP = gp.GRB.BINARY\n",
    "I_TYP = gp.GRB.INTEGER\n",
    "C_TYP = gp.GRB.CONTINUOUS\n",
    "\n",
    "\n",
    "def model_with_one_var_each_type():\n",
    "    m = gp.Model()\n",
    "    b = m.addVar(vtype=B_TYP, name=\"b\")\n",
    "    i = m.addVar(vtype=I_TYP, name=\"I\")\n",
    "    c = m.addVar(vtype=C_TYP, name=\"C\")\n",
    "    m.addConstr(b + i + c <= 5)\n",
    "    m.setObjective(b + i + c, gp.GRB.MAXIMIZE)\n",
    "    m.update()\n",
    "    return m\n",
    "\n",
    "\n",
    "# def model_with_two_var_each_type():\n",
    "#     m = gp.Model()\n",
    "#     b1 = m.addVar(vtype=B_TYP, name=\"b1\")\n",
    "#     b2 = m.addVar(vtype=B_TYP, name=\"b2\")\n",
    "\n",
    "#     i1 = m.addVar(vtype=I_TYP, name=\"i1\")\n",
    "#     i2 = m.addVar(vtype=I_TYP, name=\"i2\")\n",
    "\n",
    "#     c1 = m.addVar(vtype=C_TYP, name=\"c1\")\n",
    "#     c2 = m.addVar(vtype=C_TYP, name=\"c2\")\n",
    "#     m.addConstr(b1 + i1 + c1 <= 5)\n",
    "#     m.addConstr(b2 + i2 + c2 <= 5)\n",
    "#     m.addConstr(b1 + i1 + c1 + b2 + i2 + c2 >= 5)\n",
    "#     m.setObjective(b1 + i1 + c1, gp.GRB.MAXIMIZE)\n",
    "#     m.update()\n",
    "#     return m\n",
    "\n",
    "\n",
    "# m = model_with_one_var_each_type()\n",
    "# # m = model_with_two_var_each_type()\n",
    "# info = ModelInfo.from_model(m)\n",
    "\n",
    "# m = with_lic(m)\n",
    "# m.optimize()\n",
    "# vals = [x.x for x in m.getVars()]\n",
    "# sols = [[m.ObjVal] + vals]\n",
    "# m.dispose()\n",
    "\n",
    "# info.var_info.sols = np.array(sols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temp.data.graph import get_bipartite_graph, add_label\n",
    "from temp.data.dataset import create_data_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "(model, solution) => info: 100%|██████████| 100/100 [00:16<00:00,  6.24it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "pre_train_d = ModelGraphDataset(PRE_TRAIN_DIR, augment=augment_info, force_reload=True)\n",
    "train_d = ModelGraphDataset(PRE_TRAIN_DIR, augment=augment_info)\n",
    "valid_d = ModelGraphDataset(PRE_TRAIN_DIR)\n",
    "\n",
    "# for i in range(len(pre_train_d)):\n",
    "#     print(i)\n",
    "#     data = pre_train_d[i][1]\n",
    "\n",
    "data = pre_train_d[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_feature_size = data.var_node_features.size(-1)\n",
    "con_feature_size = data.con_node_features.size(-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "CFG = pd.read_excel(\"temp/trained_models/setcover_model_configs.xlsx\", index_col=0).loc[0].to_dict()\n",
    "CFG[\"num_epochs\"] = 16\n",
    "CFG[\"num_layers\"] = 8\n",
    "CFG[\"hidden\"] = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temp.model.utils import get_model\n",
    "from temp.model.trainer import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, model, criterion, optimizer, scheduler = get_model(\".\", var_feature_size, con_feature_size, n_batches=1, **CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.total_steps = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed()\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "pretrain_loader = DataLoader(pre_train_d, batch_size=2, shuffle=True, num_workers=8, prefetch_factor=2, generator=torch.Generator().manual_seed(0))\n",
    "train_loader = DataLoader(train_d, batch_size=2, shuffle=True, num_workers=8, prefetch_factor=2, generator=torch.Generator().manual_seed(0))\n",
    "val_loader = DataLoader(valid_d, batch_size=2, shuffle=True, num_workers=8, generator=torch.Generator().manual_seed(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.total_steps = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Training starts on the current device cpu\n",
      ">> Pretraining for prenorm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:40<00:00,  5.60s/it] \n",
      " 88%|████████▊ | 44/50 [03:37<00:13,  2.17s/it] "
     ]
    }
   ],
   "source": [
    "train(model_name, model, criterion, optimizer, scheduler, pretrain_loader, train_loader, val_loader, CFG, False, \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 1 == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temp.data.dataset import info_to_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = lot_sizing(128, 16)\n",
    "to_dispose = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter CloudAccessID\n",
      "Set parameter CloudSecretKey\n",
      "Set parameter CloudPool to value \"831775-C3Dev\"\n",
      "Set parameter CSAppName to value \"Josh\"\n",
      "Compute Server job ID: 595213e8-92ff-4843-8d1e-48b70cd9283c\n",
      "Capacity available on '831775-C3Dev' cloud pool - connecting...\n",
      "Established HTTPS encrypted connection\n",
      "\n",
      "Compute Server communication statistics:\n",
      "  Sent: 0.098 MB in 57 msgs and 4.40s (0.02 MB/s)\n",
      "  Received: 1.146 MB in 345 msgs and 146.77s (0.01 MB/s)\n",
      "\n",
      "Set parameter TimeLimit to value 150\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (mac64[x86] - Darwin 22.4.0 22E252)\n",
      "Gurobi Compute Server Worker version 12.0.1 build v12.0.1rc0 (linux64 - \"Ubuntu 20.04.6 LTS\")\n",
      "\n",
      "CPU model: Intel(R) Xeon(R) Platinum 8375C CPU @ 2.90GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  150\n",
      "CSIdleTimeout  1800\n",
      "\n",
      "Optimize a model with 6160 rows, 6144 columns and 16256 nonzeros\n",
      "Model fingerprint: 0x384c8314\n",
      "Variable types: 4096 continuous, 2048 integer (2048 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [4e-02, 3e+04]\n",
      "  Objective range  [1e+00, 2e+02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [2e-02, 1e-01]\n",
      "Presolve removed 314 rows and 302 columns\n",
      "Presolve time: 0.04s\n",
      "Presolved: 5846 rows, 5842 columns, 16144 nonzeros\n",
      "Variable types: 3810 continuous, 2032 integer (2032 binary)\n",
      "\n",
      "Root relaxation: objective 3.799844e+05, 6559 iterations, 0.10 seconds (0.10 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 379984.397    0  184          - 379984.397      -     -    0s\n",
      "     0     0 381083.210    0  256          - 381083.210      -     -    0s\n",
      "     0     0 381089.162    0  269          - 381089.162      -     -    0s\n",
      "     0     0 381745.762    0  333          - 381745.762      -     -    0s\n",
      "     0     0 381818.780    0  331          - 381818.780      -     -    0s\n",
      "     0     0 381825.240    0  342          - 381825.240      -     -    0s\n",
      "     0     0 381825.415    0  343          - 381825.415      -     -    0s\n",
      "     0     0 382220.098    0  349          - 382220.098      -     -    0s\n",
      "     0     0 382271.009    0  363          - 382271.009      -     -    0s\n",
      "     0     0 382286.367    0  387          - 382286.367      -     -    0s\n",
      "     0     0 382289.664    0  379          - 382289.664      -     -    0s\n",
      "     0     0 382289.915    0  375          - 382289.915      -     -    0s\n",
      "     0     0 382516.908    0  408          - 382516.908      -     -    0s\n",
      "     0     0 382559.531    0  413          - 382559.531      -     -    0s\n",
      "     0     0 382574.331    0  423          - 382574.331      -     -    0s\n",
      "     0     0 382577.613    0  428          - 382577.613      -     -    0s\n",
      "     0     0 382578.675    0  432          - 382578.675      -     -    0s\n",
      "     0     0 382763.517    0  529          - 382763.517      -     -    1s\n",
      "     0     0 382790.402    0  510          - 382790.402      -     -    1s\n",
      "     0     0 382797.481    0  533          - 382797.481      -     -    1s\n",
      "     0     0 382799.681    0  581          - 382799.681      -     -    1s\n",
      "     0     0 382800.450    0  561          - 382800.450      -     -    1s\n",
      "     0     0 382903.177    0  557          - 382903.177      -     -    1s\n",
      "H    0     0                    389738.42687 382930.829  1.75%     -    1s\n",
      "H    0     0                    389733.27137 382930.829  1.75%     -    1s\n",
      "     0     0 382930.829    0  568 389733.271 382930.829  1.75%     -    1s\n",
      "H    0     0                    387866.93971 382941.235  1.27%     -    1s\n",
      "H    0     0                    387853.48081 382941.235  1.27%     -    1s\n",
      "     0     0 382941.235    0  629 387853.481 382941.235  1.27%     -    1s\n",
      "     0     0 382944.148    0  622 387853.481 382944.148  1.27%     -    1s\n",
      "     0     0 382944.442    0  615 387853.481 382944.442  1.27%     -    1s\n",
      "H    0     0                    387850.45681 383012.226  1.25%     -    1s\n",
      "H    0     0                    387848.19723 383012.226  1.25%     -    1s\n",
      "     0     0 383012.226    0  622 387848.197 383012.226  1.25%     -    1s\n",
      "H    0     0                    387847.18923 383034.532  1.24%     -    2s\n",
      "H    0     0                    387828.70024 383034.532  1.24%     -    2s\n",
      "H    0     0                    387808.76283 383034.532  1.23%     -    2s\n",
      "H    0     0                    387807.51683 383034.532  1.23%     -    2s\n",
      "     0     0 383034.532    0  593 387807.517 383034.532  1.23%     -    2s\n",
      "     0     0 383045.416    0  581 387807.517 383045.416  1.23%     -    2s\n",
      "H    0     0                    387807.49748 383050.198  1.23%     -    2s\n",
      "H    0     0                    387674.93537 383050.198  1.19%     -    2s\n",
      "H    0     0                    387672.93550 383050.198  1.19%     -    2s\n",
      "H    0     0                    387671.09800 383050.198  1.19%     -    2s\n",
      "     0     0 383050.198    0  584 387671.098 383050.198  1.19%     -    2s\n",
      "     0     0 383051.106    0  614 387671.098 383051.106  1.19%     -    2s\n",
      "     0     0 383112.540    0  542 387671.098 383112.540  1.18%     -    2s\n",
      "H    0     0                    387640.03630 383112.583  1.17%     -    2s\n",
      "     0     0 383130.833    0  571 387640.036 383130.833  1.16%     -    2s\n",
      "     0     0 383136.049    0  578 387640.036 383136.049  1.16%     -    2s\n",
      "     0     0 383137.394    0  589 387640.036 383137.394  1.16%     -    2s\n",
      "     0     0 383172.752    0  627 387640.036 383172.752  1.15%     -    2s\n",
      "     0     0 383191.500    0  624 387640.036 383191.500  1.15%     -    3s\n",
      "     0     0 383195.524    0  647 387640.036 383195.524  1.15%     -    3s\n",
      "     0     0 383197.212    0  625 387640.036 383197.212  1.15%     -    3s\n",
      "     0     0 383211.543    0  633 387640.036 383211.543  1.14%     -    3s\n",
      "     0     0 383220.926    0  618 387640.036 383220.926  1.14%     -    3s\n",
      "     0     0 383224.822    0  655 387640.036 383224.822  1.14%     -    3s\n",
      "     0     0 383228.104    0  641 387640.036 383228.104  1.14%     -    3s\n",
      "     0     0 383228.687    0  642 387640.036 383228.687  1.14%     -    3s\n",
      "H    0     0                    387191.62365 383242.319  1.02%     -    4s\n",
      "H    0     0                    387183.29740 383242.319  1.02%     -    4s\n",
      "H    0     0                    387183.05801 383242.319  1.02%     -    4s\n",
      "     0     0 383242.319    0  682 387183.058 383242.319  1.02%     -    4s\n",
      "     0     0 383245.721    0  659 387183.058 383245.721  1.02%     -    4s\n",
      "     0     0 383246.844    0  666 387183.058 383246.844  1.02%     -    4s\n",
      "     0     0 383263.281    0  662 387183.058 383263.281  1.01%     -    4s\n",
      "     0     0 383263.388    0  662 387183.058 383263.388  1.01%     -    4s\n",
      "H    0     0                    387181.81201 383263.388  1.01%     -    4s\n",
      "H    0     2                    387174.51801 383263.388  1.01%     -    5s\n",
      "     0     2 383263.388    0  662 387174.518 383263.388  1.01%     -    5s\n",
      "H   35    43                    387173.91743 383314.872  1.00%   340    6s\n",
      "H   81    90                    386940.39846 383314.872  0.94%   248    6s\n",
      "H  126   136                    386903.86982 383314.872  0.93%   205    6s\n",
      "H  216   228                    386899.28482 383314.872  0.93%   167    7s\n",
      "H  226   228                    386878.03114 383314.872  0.92%   163    7s\n",
      "H  269   275                    386877.30973 383314.872  0.92%   154    7s\n",
      "H  269   275                    386867.09932 383314.872  0.92%   154    7s\n",
      "H  302   307                    386860.98188 383314.872  0.92%   146    7s\n",
      "H  303   307                    386743.29763 383314.872  0.89%   146    7s\n",
      "H  306   315                    386740.79528 383314.872  0.89%   146    7s\n",
      "H  308   315                    386739.85363 383314.872  0.89%   145    7s\n",
      "H  366   375                    386739.59548 383314.872  0.89%   135    8s\n",
      "H  368   375                    386640.39958 383314.872  0.86%   136    8s\n",
      "H  602   610                    386506.23079 383314.872  0.83%   125    9s\n",
      "H  604   610                    386260.26303 383314.872  0.76%   125    9s\n",
      "H  606   610                    385952.17181 383314.872  0.68%   125    9s\n",
      "H  758   790                    385947.63859 383314.872  0.68%   117    9s\n",
      "   976  1098 383880.415   69  279 385947.639 383314.872  0.68%   105   10s\n",
      "H 1301  1308                    385923.24166 383314.872  0.68%  91.6   10s\n",
      "H 1444  1440                    385919.60026 383314.872  0.67%  87.2   10s\n",
      "H 1445  1440                    385877.65276 383314.872  0.66%  87.2   10s\n",
      "H 1449  1438                    385804.45871 383314.872  0.65%  87.1   10s\n",
      "H 2516  2459                    385801.00162 383314.872  0.64%  71.2   12s\n",
      "H 2615  2539                    385798.66954 383314.872  0.64%  72.9   13s\n",
      "H 2926  2830                    385796.56578 383322.801  0.64%  77.7   14s\n",
      "H 2926  2825                    385769.00328 383322.801  0.63%  77.7   14s\n",
      "H 2926  2825                    385767.91128 383322.801  0.63%  77.7   14s\n",
      "  2927  2826 385485.172  185  662 385767.911 383322.801  0.63%  77.7   16s\n",
      "H 2928  2685                    385767.82728 383322.801  0.63%  77.7   16s\n",
      "H 2928  2551                    385767.57528 383322.801  0.63%  77.7   16s\n",
      "H 2931  2425                    385765.24320 383322.801  0.63%  77.6   17s\n",
      "H 2934  2306                    385748.71885 383322.801  0.63%  77.5   18s\n",
      "  2942  2311 384402.538   96  652 385748.719 383364.070  0.62%  77.3   21s\n",
      "H 2950  2199                    385736.24268 383451.591  0.59%  77.1   22s\n",
      "H 2950  2089                    385735.77363 383451.591  0.59%  77.1   22s\n",
      "H 2950  1984                    385735.26988 383451.591  0.59%  77.1   22s\n",
      "H 2950  1885                    385733.91060 383451.591  0.59%  77.1   22s\n",
      "H 2950  1790                    385733.44154 383451.591  0.59%  77.1   22s\n",
      "H 2950  1700                    385732.93780 383451.591  0.59%  77.1   22s\n",
      "  2958  1706 384939.650  133  791 385732.938 383498.692  0.58%  76.9   25s\n",
      "H 2971  1628                    385732.37699 383552.227  0.57%  76.5   29s\n",
      "H 2971  1545                    385730.61984 383553.896  0.56%  76.5   29s\n",
      "H 2971  1467                    385725.04627 383553.896  0.56%  76.5   29s\n",
      "  2973  1469 384982.231  191  703 385725.046 383558.155  0.56%  76.5   30s\n",
      "H 2974  1395                    385717.35967 383560.840  0.56%  76.5   30s\n",
      "H 2974  1324                    385705.52688 383560.840  0.56%  76.5   30s\n",
      "H 2974  1257                    385659.24642 383560.840  0.54%  76.5   30s\n",
      "H 2977  1196                    385656.97842 383573.843  0.54%  76.4   31s\n",
      "H 2977  1135                    385654.52142 383573.843  0.54%  76.4   31s\n",
      "H 2977  1077                    385652.98842 383573.843  0.54%  76.4   31s\n",
      "H 2977  1023                    385649.22242 383573.843  0.54%  76.4   31s\n",
      "H 2978   971                    385559.46748 383578.973  0.51%  76.4   32s\n",
      "H 2978   922                    385549.87888 383578.973  0.51%  76.4   32s\n",
      "H 2978   875                    385492.23975 383578.973  0.50%  76.4   32s\n",
      "H 2978   830                    385482.49037 383578.973  0.49%  76.4   32s\n",
      "H 2978   788                    385459.93698 383578.973  0.49%  76.4   32s\n",
      "H 2978   748                    385459.39285 383578.973  0.49%  76.4   32s\n",
      "H 2983   712                    385434.30835 383594.258  0.48%  76.2   33s\n",
      "H 2983   676                    385427.71430 383594.607  0.48%  76.2   34s\n",
      "H 2984   642                    385358.55134 383597.283  0.46%  76.2   34s\n",
      "H 2984   609                    385333.17190 383597.283  0.45%  76.2   34s\n",
      "H 2984   577                    385330.78186 383597.283  0.45%  76.2   34s\n",
      "H 2984   548                    385330.20955 383597.283  0.45%  76.2   34s\n",
      "H 2985   520                    385329.98867 383599.769  0.45%  76.2   34s\n",
      "  2986   520 385329.989  208  808 385329.989 383599.769  0.45%  76.2   35s\n",
      "H 2991   497                    385327.60783 383623.205  0.44%  76.0   37s\n",
      "  3001   503 385319.675  159  760 385327.608 383649.096  0.44%  75.8   41s\n",
      "H 3006   480                    385326.41741 383655.245  0.43%  75.7   43s\n",
      "  3012   484 384992.410  178  757 385326.417 383661.581  0.43%  75.5   45s\n",
      "H 3018   462                    385325.22700 383668.517  0.43%  75.4   47s\n",
      "  3023   465 384253.671   88  667 385325.227 383673.406  0.43%  75.2   50s\n",
      "H 3029   444                    385304.27393 383678.752  0.42%  75.1   54s\n",
      "  3040   453 383680.783   10  378 385304.274 383680.783  0.42%  88.4   55s\n",
      "H 3045   433                    385301.82708 383682.182  0.42%  88.2   56s\n",
      "H 3054   416                    385299.03566 383686.222  0.42%  88.0   59s\n",
      "  3056   418 383995.871    7  662 385299.036 383688.410  0.42%  87.9   60s\n",
      "H 3066   403                    385296.58881 383703.581  0.41%  87.6   64s\n",
      "  3068   405 383820.419   32  739 385296.589 383707.509  0.41%  87.6   66s\n",
      "H 3072   386                    385295.19259 383711.962  0.41%  87.5   68s\n",
      "H 3072   366                    385283.69102 383711.962  0.41%  87.5   68s\n",
      "  3076   369 385225.508  130  796 385283.691 383717.556  0.41%  87.4   70s\n",
      "H 3079   351                    385282.29480 383720.418  0.41%  87.3   71s\n",
      "H 3083   336                    385276.73230 383723.345  0.40%  87.2   74s\n",
      "  3086   338 385276.732  208  837 385276.732 383723.787  0.40%  87.1   75s\n",
      "  3098   355 383752.315   28  683 385276.732 383734.666  0.40%  95.7   80s\n",
      "H 3188   419                    385260.04479 383760.911  0.39%   109   84s\n",
      "  3254   449 383898.682   34  567 385260.045 383760.911  0.39%   114   85s\n",
      "H 3272   442                    385258.31679 383760.911  0.39%   115   87s\n",
      "H 3334   473                    385238.17854 383760.911  0.38%   118   88s\n",
      "H 3392   506                    385238.11468 383760.911  0.38%   120   89s\n",
      "H 3394   491                    385225.84754 383760.911  0.38%   120   89s\n",
      "  3422   527 383948.614   39  564 385225.848 383760.911  0.38%   120   90s\n",
      "H 3467   536                    385222.76478 383760.911  0.38%   121   90s\n",
      "H 3503   511                    385213.45266 383760.911  0.38%   121   90s\n",
      "H 3551   561                    385211.44818 383760.911  0.38%   123   91s\n",
      "H 3670   624                    385210.90218 383760.911  0.38%   126   93s\n",
      "  3806   774 384019.757   49  547 385210.902 383760.911  0.38%   128   95s\n",
      "  4141  1166 384062.047   58  487 385210.902 383760.911  0.38%   133  100s\n",
      "H 4412  1411                    385205.21317 383760.911  0.37%   133  101s\n",
      "H 4434  1411                    385198.68018 383760.911  0.37%   133  101s\n",
      "H 4453  1411                    385195.93338 383760.911  0.37%   133  101s\n",
      "H 5017  1994                    385194.74296 383760.911  0.37%   136  104s\n",
      "  5118  2219 384546.442   79  491 385194.743 383760.911  0.37%   135  105s\n",
      "  5892  2687 384952.167   93  323 385194.743 383768.665  0.37%   134  110s\n",
      "H 5914  2686                    385193.04927 383768.665  0.37%   135  110s\n",
      "H 5960  2686                    385191.38404 383768.665  0.37%   134  110s\n",
      "H 6273  3068                    385189.04408 383768.665  0.37%   137  113s\n",
      "H 6278  3068                    385189.04134 383768.665  0.37%   137  113s\n",
      "H 6420  3068                    385188.83408 383768.665  0.37%   136  113s\n",
      "  6437  3359 384010.721   39  291 385188.834 383768.665  0.37%   136  115s\n",
      "H 7610  4182                    385188.49534 383800.078  0.36%   134  120s\n",
      "H 7640  4180                    385186.17617 383800.078  0.36%   133  120s\n",
      "H 7661  4154                    385166.92414 383800.078  0.35%   133  120s\n",
      "H 7763  4139                    385160.90601 383800.078  0.35%   133  120s\n",
      "  8464  4976 383995.721   42  614 385160.906 383800.078  0.35%   136  126s\n",
      "H 8776  5247                    385158.55890 383800.078  0.35%   136  128s\n",
      "H 8888  5241                    385154.94825 383800.078  0.35%   136  128s\n",
      "H 8966  5231                    385150.08885 383800.078  0.35%   136  128s\n",
      "  9329  5781 384296.471   83  348 385150.089 383800.078  0.35%   136  131s\n",
      "H10322  6681                    385148.62305 383800.078  0.35%   135  134s\n",
      " 10664  7120 384855.301  115  243 385148.623 383800.078  0.35%   133  136s\n",
      "H11868  7876                    385138.80801 383814.877  0.34%   129  140s\n",
      "H12896  8969                    385117.88459 383814.877  0.34%   128  145s\n",
      " 14470 10198 384419.211   38  579 385117.885 383814.877  0.34%   124  150s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 24\n",
      "  Cover: 6\n",
      "  Implied bound: 1\n",
      "  MIR: 618\n",
      "  Mixing: 9\n",
      "  Flow cover: 1741\n",
      "  Relax-and-lift: 2\n",
      "\n",
      "Explored 14975 nodes (1849491 simplex iterations) in 150.01 seconds (178.09 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 10: 385118 385149 385150 ... 385189\n",
      "\n",
      "Time limit reached\n",
      "Best objective 3.851178845870e+05, best bound 3.838148766356e+05, gap 0.3383%\n"
     ]
    }
   ],
   "source": [
    "gb_m = with_lic(m)\n",
    "gb_m.setParam(\"TimeLimit\", 150)\n",
    "# gb_m.setParam(\"NoRelHeurTime\", 60)\n",
    "gb_m.optimize()\n",
    "to_dispose.append(gb_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = ModelInfo.from_model(m)\n",
    "data = info_to_data(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6144"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_mask(model):\n",
    "    vs = model.getVars()\n",
    "    ts = model.getAttr(\"vType\", vs)\n",
    "    mask = [t == gp.GRB.BINARY for t in ts]\n",
    "    mask = torch.as_tensor(mask, dtype=bool)\n",
    "    return mask\n",
    "\n",
    "def get_binary_indices(model):\n",
    "    vs = model.getVars()\n",
    "    ts = model.getAttr(\"vType\", vs)\n",
    "    idxs = [i for i, t in enumerate(ts) if t == gp.GRB.BINARY]\n",
    "    idxs = torch.as_tensor(idxs, dtype=int)\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_mask = get_binary_mask(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temp.solver import upr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs, preds = upr.get_predictions(logits, binary_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0371833e-07, 3.1710293e-08, 3.1230822e-08, ..., 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "unc = upr.get_uncertainty(logits)\n",
    "unc = unc[binary_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = upr.get_threshold(unc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "import gurobipy as gp\n",
    "\n",
    "\n",
    "def fix_var(inst, idxs, vals):\n",
    "    assert len(idxs) == len(vals)\n",
    "    bounds = {}\n",
    "    vs = inst.getVars()\n",
    "    for idx, val in zip(idxs, vals):\n",
    "        v = vs[idx]\n",
    "        bounds[idx] = (v.lb, v.ub)\n",
    "        v.setAttr(\"lb\", val)\n",
    "        v.setAttr(\"ub\", val)\n",
    "    inst.update()\n",
    "    return bounds\n",
    "\n",
    "\n",
    "def unfix_var(inst, idxs, bounds):\n",
    "    assert len(idxs) == len(bounds)\n",
    "    vs = inst.getVars()\n",
    "    print(idxs, bounds)\n",
    "    for i, (lb, ub) in zip(idxs, bounds):\n",
    "        vs[i].setAttr(\"lb\", lb)\n",
    "        vs[i].setAttr(\"ub\", ub)\n",
    "\n",
    "\n",
    "def get_iis_vars(inst):\n",
    "    try:\n",
    "        inst.computeIIS()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        if \"Cannot compute IIS on a feasible model\" in str(e):\n",
    "            return set()\n",
    "        raise e\n",
    "\n",
    "    with NamedTemporaryFile(suffix=\".ilp\", mode=\"w+\") as f:\n",
    "        inst.write(f.name)\n",
    "        f.seek(0)\n",
    "        return set(f.read().split())\n",
    "\n",
    "\n",
    "def set_starts(inst, starts):\n",
    "    vs = inst.getVars()\n",
    "    for i, s in starts.items():\n",
    "        vs[i].setAttr(\"lb\", s)\n",
    "\n",
    "\n",
    "def solve_inst(inst):\n",
    "    vs = inst.getVars()\n",
    "    inst.optimize()\n",
    "    return inst.getAttr(\"X\", vs)\n",
    "\n",
    "\n",
    "def repair(inst, fixed: set, bounds: dict):\n",
    "    old_iis_method = getattr(inst, \"IISMethod\", -1)\n",
    "    # inst.setParam(\"IISMethod\", 0)\n",
    "\n",
    "    vs = inst.getVars()\n",
    "    ns = inst.getAttr(\"varName\", vs)\n",
    "    name_to_idx = {n: i for i, n in enumerate(ns)}\n",
    "\n",
    "    freed = set()\n",
    "    while iis_var_names := get_iis_vars(inst):\n",
    "        for n in iis_var_names:\n",
    "            if n not in name_to_idx:\n",
    "                continue\n",
    "            \n",
    "            var_idx = name_to_idx[n]\n",
    "            if var_idx not in fixed:\n",
    "                continue\n",
    "\n",
    "            if var_idx in freed:\n",
    "                continue\n",
    "            print(n, var_idx)\n",
    "            if var_idx not in bounds:\n",
    "                continue\n",
    "            \n",
    "            lb, ub = bounds[var_idx]\n",
    "            vs[var_idx].lb = lb\n",
    "            vs[var_idx].ub = ub\n",
    "            freed.add(var_idx)\n",
    "\n",
    "    inst.setParam(\"IISMethod\", old_iis_method)\n",
    "    return freed\n",
    "\n",
    "\n",
    "def set_hints(inst, hints):\n",
    "    vs = inst.getVars()\n",
    "    for i, (val, pri) in hints:\n",
    "        if 0 <= pri <= 1:\n",
    "            pri = int(pri * 100)\n",
    "        vs[i].setAttr(\"VarHintVal\", val)\n",
    "        vs[i].setAttr(\"VarHintPri\", pri)\n",
    "\n",
    "\n",
    "def with_lic(m, path=\"gb.lic\"):\n",
    "    with open(path) as f:\n",
    "        env = gp.Env(params=json.load(f))\n",
    "    return m.copy(env=env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(m.getVarByName(\"y[5,15]\").ub)\n",
    "print(m.getVarByName(\"y[5,15]\").lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# from temp.solver.utils import fix_var, repair, set_starts, unfix_var, solve_inst\n",
    "\n",
    "EVIDENCE_FUNCS = {\n",
    "    \"softplus\": (lambda y: F.softplus(y)),\n",
    "    \"relu\": (lambda y: F.relu(y)),\n",
    "    \"exp\": (lambda y: torch.exp(torch.clamp(y, -10, 10))),\n",
    "}\n",
    "\n",
    "\n",
    "def get_predictions(logits, binary_mask):\n",
    "    probs = torch.softmax(logits, axis=1)\n",
    "    preds = probs[:, 1]\n",
    "    probs = _to_numpy(probs)\n",
    "    preds = _to_numpy(preds).squeeze()\n",
    "    preds[binary_mask] = preds[binary_mask].round()\n",
    "    return probs, preds\n",
    "\n",
    "\n",
    "def get_uncertainty(logits, evidence_func_name: str = \"softplus\"):\n",
    "    evidence = EVIDENCE_FUNCS[evidence_func_name](logits)\n",
    "    alpha = evidence + 1\n",
    "    uncertainty = logits.shape[1] / torch.sum(alpha, dim=1, keepdim=True)\n",
    "    return uncertainty\n",
    "\n",
    "\n",
    "def get_threshold(uncertainty: torch.Tensor, r_min: float = 0.4, r_max: float = 0.55):\n",
    "    q = (r_min + r_max) / 2\n",
    "    threshold = torch.quantile(uncertainty, q)\n",
    "    r = (uncertainty <= threshold).float().mean()\n",
    "\n",
    "    if r > r_max:\n",
    "        threshold = torch.quantile(uncertainty, r_max)\n",
    "        return threshold\n",
    "\n",
    "    if r < r_min:\n",
    "        threshold = torch.quantile(uncertainty, r_min)\n",
    "        return threshold\n",
    "\n",
    "    return threshold\n",
    "\n",
    "\n",
    "def get_confident_idx(indices, uncertainty, threshold):\n",
    "    confident_mask = uncertainty <= threshold\n",
    "    confident_idx = indices[confident_mask]\n",
    "    return confident_idx.sort()[0]\n",
    "\n",
    "import os\n",
    "\n",
    "def solve(inst, prediction, uncertainty, indices, max_iter):\n",
    "    threshold = get_threshold(uncertainty)\n",
    "    conf_idxs = get_confident_idx(indices, uncertainty, threshold)\n",
    "    conf_vals = prediction[conf_idxs]\n",
    "\n",
    "    conf_idxs = conf_idxs.tolist()\n",
    "    bounds = fix_var(inst, conf_idxs, conf_vals)\n",
    "    \n",
    "    os.bnds = bounds\n",
    "    os.idxs = conf_idxs\n",
    "    os.vals = conf_vals\n",
    "\n",
    "    print(len(bounds), len(prediction))\n",
    "\n",
    "    min_q = sum(uncertainty <= threshold) / len(uncertainty)\n",
    "    max_q = 1.0\n",
    "    dq = (max_q - min_q) / (max_iter - 1)\n",
    "\n",
    "    fixed = set(conf_idxs)\n",
    "    freed = set(repair(inst, fixed, bounds))\n",
    "    for i in range(1, max_iter):\n",
    "        sol = solve_inst(inst)\n",
    "        q = max_q - dq * i\n",
    "        threshold = np.quantile(uncertainty, q)\n",
    "        conf_idxs = get_confident_idx(indices, uncertainty, threshold)\n",
    "        to_unfix = list(fixed - set(conf_idxs.tolist()))\n",
    "        to_unfix = [i for i in to_unfix if i not in freed]\n",
    "        print(len(to_unfix))\n",
    "        unfix_var(inst, to_unfix, [bounds[i] for i in to_unfix])\n",
    "        starts = {i: sol[i] for i in to_unfix}\n",
    "        starts.update({i: sol[i] for i in freed})\n",
    "        set_starts(inst, starts)\n",
    "    unfix_var(inst, bounds.keys(), bounds.values())\n",
    "    sol = solve_inst(inst)\n",
    "    return sol\n",
    "\n",
    "\n",
    "def _to_numpy(tensor_obj):\n",
    "    return tensor_obj.cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compute Server communication statistics:\n",
      "  Sent: 0.110 MB in 122 msgs and 9.32s (0.01 MB/s)\n",
      "  Received: 1.212 MB in 548 msgs and 201.05s (0.01 MB/s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d in to_dispose:\n",
    "    d.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter CloudAccessID\n",
      "Set parameter CloudSecretKey\n",
      "Set parameter CloudPool to value \"831775-C3Dev\"\n",
      "Set parameter CSAppName to value \"Josh\"\n",
      "Compute Server job ID: c9d5fa46-c9b5-4b8e-9e9c-676eb9ff4c53\n",
      "Capacity available on '831775-C3Dev' cloud pool - connecting...\n",
      "Established HTTPS encrypted connection\n",
      "Set parameter TimeLimit to value 10\n",
      "973 6144\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (mac64[x86] - Darwin 22.4.0 22E252)\n",
      "Gurobi Compute Server Worker version 12.0.1 build v12.0.1rc0 (linux64 - \"Ubuntu 20.04.6 LTS\")\n",
      "\n",
      "CPU model: Intel(R) Xeon(R) Platinum 8375C CPU @ 2.90GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  10\n",
      "CSIdleTimeout  1800\n",
      "\n",
      "IIS computation: initial model status unknown, solving to determine model status\n",
      "\n",
      "Computing Irreducible Inconsistent Subsystem (IIS)...\n",
      "\n",
      "           Constraints          |            Bounds           |  Runtime\n",
      "      Min       Max     Guess   |   Min       Max     Guess   |\n",
      "--------------------------------------------------------------------------\n",
      "        0      6160         -         0      5069         -           0s\n",
      "Numerical troubles encountered during IIS computation\n",
      "     1351      1351      1351       126       126       126           2s\n",
      "\n",
      "IIS computed: 1351 constraints, 126 bounds\n",
      "IIS runtime: 0.00 seconds (0.00 work units)\n",
      "y[84,7] 5447\n",
      "y[73,6] 5270\n",
      "y[82,7] 5415\n",
      "y[101,7] 5719\n",
      "y[35,6] 4662\n",
      "y[19,6] 4406\n",
      "y[25,6] 4502\n",
      "y[113,7] 5911\n",
      "y[110,7] 5863\n",
      "y[94,7] 5607\n",
      "y[12,6] 4294\n",
      "y[114,7] 5927\n",
      "y[6,6] 4198\n",
      "y[89,7] 5527\n",
      "y[54,6] 4966\n",
      "y[75,7] 5303\n",
      "y[49,6] 4886\n",
      "y[42,6] 4774\n",
      "y[55,6] 4982\n",
      "y[46,6] 4838\n",
      "y[70,6] 5222\n",
      "y[22,6] 4454\n",
      "y[11,6] 4278\n",
      "y[72,6] 5254\n",
      "y[90,7] 5543\n",
      "y[119,7] 6007\n",
      "y[81,7] 5399\n",
      "y[111,7] 5879\n",
      "y[36,6] 4678\n",
      "y[15,6] 4342\n",
      "y[74,6] 5286\n",
      "y[24,6] 4486\n",
      "y[67,6] 5174\n",
      "y[86,7] 5479\n",
      "y[50,6] 4902\n",
      "y[115,7] 5943\n",
      "y[27,6] 4534\n",
      "y[5,6] 4182\n",
      "y[68,6] 5190\n",
      "y[7,6] 4214\n",
      "y[127,12] 6140\n",
      "y[103,7] 5751\n",
      "y[122,7] 6055\n",
      "y[59,6] 5046\n",
      "y[123,7] 6071\n",
      "y[45,6] 4822\n",
      "y[61,6] 5078\n",
      "y[126,8] 6120\n",
      "y[40,6] 4742\n",
      "y[62,6] 5094\n",
      "y[43,6] 4790\n",
      "y[52,6] 4934\n",
      "y[29,6] 4566\n",
      "y[34,6] 4646\n",
      "y[65,6] 5142\n",
      "y[33,6] 4630\n",
      "y[77,7] 5335\n",
      "y[18,6] 4390\n",
      "y[79,7] 5367\n",
      "y[13,6] 4310\n",
      "y[78,7] 5351\n",
      "y[48,6] 4870\n",
      "y[93,7] 5591\n",
      "y[58,6] 5030\n",
      "y[69,6] 5206\n",
      "y[107,7] 5815\n",
      "y[56,6] 4998\n",
      "y[109,7] 5847\n",
      "y[106,7] 5799\n",
      "y[71,6] 5238\n",
      "y[17,6] 4374\n",
      "y[83,7] 5431\n",
      "y[104,7] 5767\n",
      "y[37,6] 4694\n",
      "y[44,6] 4806\n",
      "y[16,6] 4358\n",
      "y[31,6] 4598\n",
      "y[23,6] 4470\n",
      "y[10,6] 4262\n",
      "y[76,7] 5319\n",
      "y[9,6] 4246\n",
      "y[117,7] 5975\n",
      "y[28,6] 4550\n",
      "y[120,7] 6023\n",
      "y[124,8] 6088\n",
      "y[38,6] 4710\n",
      "y[51,6] 4918\n",
      "y[41,6] 4758\n",
      "y[14,6] 4326\n",
      "y[118,7] 5991\n",
      "y[91,7] 5559\n",
      "y[53,6] 4950\n",
      "y[112,7] 5895\n",
      "y[95,7] 5623\n",
      "y[99,7] 5687\n",
      "y[21,6] 4438\n",
      "y[96,7] 5639\n",
      "y[80,7] 5383\n",
      "y[30,6] 4582\n",
      "y[63,6] 5110\n",
      "y[26,6] 4518\n",
      "y[88,7] 5511\n",
      "y[39,6] 4726\n",
      "y[66,6] 5158\n",
      "y[57,6] 5014\n",
      "y[8,6] 4230\n",
      "y[47,6] 4854\n",
      "y[102,7] 5735\n",
      "y[85,7] 5463\n",
      "y[100,7] 5703\n",
      "y[121,7] 6039\n",
      "y[105,7] 5783\n",
      "y[32,6] 4614\n",
      "y[125,8] 6104\n",
      "y[20,6] 4422\n",
      "y[92,7] 5575\n",
      "y[60,6] 5062\n",
      "y[108,7] 5831\n",
      "y[116,7] 5959\n",
      "y[64,6] 5126\n",
      "y[87,7] 5495\n",
      "y[98,7] 5671\n",
      "y[97,7] 5655\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (mac64[x86] - Darwin 22.4.0 22E252)\n",
      "Gurobi Compute Server Worker version 12.0.1 build v12.0.1rc0 (linux64 - \"Ubuntu 20.04.6 LTS\")\n",
      "\n",
      "CPU model: Intel(R) Xeon(R) Platinum 8375C CPU @ 2.90GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  10\n",
      "CSIdleTimeout  1800\n",
      "\n",
      "IIS computation: initial model status unknown, solving to determine model status\n",
      "\n",
      "Computing Irreducible Inconsistent Subsystem (IIS)...\n",
      "\n",
      "           Constraints          |            Bounds           |  Runtime\n",
      "      Min       Max     Guess   |   Min       Max     Guess   |\n",
      "--------------------------------------------------------------------------\n",
      "        0      6160         -         0      4946         -           0s\n",
      "Numerical troubles encountered during IIS computation\n",
      "     1513      1513      1513       127       127       127           3s\n",
      "\n",
      "IIS computed: 1513 constraints, 127 bounds\n",
      "IIS runtime: 0.00 seconds (0.00 work units)\n",
      "y[51,5] 4917\n",
      "y[124,7] 6087\n",
      "y[42,5] 4773\n",
      "y[107,5] 5813\n",
      "y[45,5] 4821\n",
      "y[49,5] 4885\n",
      "y[115,6] 5942\n",
      "y[68,5] 5189\n",
      "y[33,5] 4629\n",
      "y[23,5] 4469\n",
      "y[58,5] 5029\n",
      "y[32,5] 4613\n",
      "y[54,5] 4965\n",
      "y[61,5] 5077\n",
      "y[78,5] 5349\n",
      "y[53,5] 4949\n",
      "y[71,5] 5237\n",
      "y[60,5] 5061\n",
      "y[29,5] 4565\n",
      "y[25,5] 4501\n",
      "y[44,5] 4805\n",
      "y[123,6] 6070\n",
      "y[46,5] 4837\n",
      "y[28,5] 4549\n",
      "y[9,5] 4245\n",
      "y[75,5] 5301\n",
      "y[118,6] 5990\n",
      "y[19,5] 4405\n",
      "y[11,5] 4277\n",
      "y[91,5] 5557\n",
      "y[56,5] 4997\n",
      "y[16,5] 4357\n",
      "y[99,5] 5685\n",
      "y[13,5] 4309\n",
      "y[79,5] 5365\n",
      "y[100,5] 5701\n",
      "y[59,5] 5045\n",
      "y[97,5] 5653\n",
      "y[92,5] 5573\n",
      "y[76,5] 5317\n",
      "y[77,5] 5333\n",
      "y[5,5] 4181\n",
      "y[52,5] 4933\n",
      "y[111,6] 5878\n",
      "y[66,5] 5157\n",
      "y[85,5] 5461\n",
      "y[89,5] 5525\n",
      "y[26,5] 4517\n",
      "y[106,5] 5797\n",
      "y[12,5] 4293\n",
      "y[37,5] 4693\n",
      "y[80,5] 5381\n",
      "y[101,5] 5717\n",
      "y[17,5] 4373\n",
      "y[10,5] 4261\n",
      "y[95,5] 5621\n",
      "y[108,6] 5830\n",
      "y[117,6] 5974\n",
      "y[50,5] 4901\n",
      "y[15,5] 4341\n",
      "y[48,5] 4869\n",
      "y[27,5] 4533\n",
      "y[122,6] 6054\n",
      "y[105,5] 5781\n",
      "y[103,5] 5749\n",
      "y[22,5] 4453\n",
      "y[41,5] 4757\n",
      "y[8,5] 4229\n",
      "y[63,5] 5109\n",
      "y[67,5] 5173\n",
      "y[96,5] 5637\n",
      "y[6,5] 4197\n",
      "y[43,5] 4789\n",
      "y[40,5] 4741\n",
      "y[36,5] 4677\n",
      "y[83,5] 5429\n",
      "y[7,5] 4213\n",
      "y[81,5] 5397\n",
      "y[64,5] 5125\n",
      "y[73,5] 5269\n",
      "y[88,5] 5509\n",
      "y[82,5] 5413\n",
      "y[74,5] 5285\n",
      "y[93,5] 5589\n",
      "y[110,6] 5862\n",
      "y[69,5] 5205\n",
      "y[21,5] 4437\n",
      "y[34,5] 4645\n",
      "y[87,5] 5493\n",
      "y[121,6] 6038\n",
      "y[98,5] 5669\n",
      "y[114,6] 5926\n",
      "y[39,5] 4725\n",
      "y[104,5] 5765\n",
      "y[113,6] 5910\n",
      "y[125,7] 6103\n",
      "y[86,5] 5477\n",
      "y[62,5] 5093\n",
      "y[112,6] 5894\n",
      "y[31,5] 4597\n",
      "y[47,5] 4853\n",
      "y[35,5] 4661\n",
      "y[126,7] 6119\n",
      "y[94,5] 5605\n",
      "y[65,5] 5141\n",
      "y[24,5] 4485\n",
      "y[57,5] 5013\n",
      "y[119,6] 6006\n",
      "y[55,5] 4981\n",
      "y[127,11] 6139\n",
      "y[102,5] 5733\n",
      "y[84,5] 5445\n",
      "y[116,6] 5958\n",
      "y[120,6] 6022\n",
      "y[20,5] 4421\n",
      "y[72,5] 5253\n",
      "y[38,5] 4709\n",
      "y[109,6] 5846\n",
      "y[14,5] 4325\n",
      "y[90,5] 5541\n",
      "y[18,5] 4389\n",
      "y[30,5] 4581\n",
      "y[70,5] 5221\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (mac64[x86] - Darwin 22.4.0 22E252)\n",
      "Gurobi Compute Server Worker version 12.0.1 build v12.0.1rc0 (linux64 - \"Ubuntu 20.04.6 LTS\")\n",
      "\n",
      "CPU model: Intel(R) Xeon(R) Platinum 8375C CPU @ 2.90GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  10\n",
      "CSIdleTimeout  1800\n",
      "\n",
      "IIS computation: initial model status unknown, solving to determine model status\n",
      "IIS runtime: 0.00 seconds (0.00 work units)\n",
      "Cannot compute IIS on a feasible model\n",
      "Set parameter IISMethod to value -1\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (mac64[x86] - Darwin 22.4.0 22E252)\n",
      "Gurobi Compute Server Worker version 12.0.1 build v12.0.1rc0 (linux64 - \"Ubuntu 20.04.6 LTS\")\n",
      "\n",
      "CPU model: Intel(R) Xeon(R) Platinum 8375C CPU @ 2.90GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  10\n",
      "CSIdleTimeout  1800\n",
      "\n",
      "Optimize a model with 6160 rows, 6144 columns and 16256 nonzeros\n",
      "Model fingerprint: 0x41b7e970\n",
      "Variable types: 4096 continuous, 2048 integer (2048 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [4e-02, 3e+04]\n",
      "  Objective range  [1e+00, 2e+02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [2e-02, 1e-01]\n",
      "Presolve removed 2756 rows and 2741 columns\n",
      "Presolve time: 0.03s\n",
      "Presolved: 3404 rows, 3403 columns, 9499 nonzeros\n",
      "Variable types: 2186 continuous, 1217 integer (1217 binary)\n",
      "\n",
      "Root relaxation: objective 5.377909e+05, 4010 iterations, 0.06 seconds (0.07 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 537790.883    0  106          - 537790.883      -     -    0s\n",
      "     0     0 538738.438    0   90          - 538738.438      -     -    0s\n",
      "     0     0 538747.697    0   96          - 538747.697      -     -    0s\n",
      "     0     0 538747.885    0   96          - 538747.885      -     -    0s\n",
      "     0     0 538913.806    0  132          - 538913.806      -     -    0s\n",
      "     0     0 538922.170    0  141          - 538922.170      -     -    0s\n",
      "     0     0 538925.949    0  138          - 538925.949      -     -    0s\n",
      "     0     0 538926.307    0  141          - 538926.307      -     -    0s\n",
      "     0     0 538990.756    0  148          - 538990.756      -     -    0s\n",
      "     0     0 538999.049    0  158          - 538999.049      -     -    0s\n",
      "     0     0 539000.202    0  165          - 539000.202      -     -    0s\n",
      "     0     0 539000.857    0  164          - 539000.857      -     -    0s\n",
      "H    0     0                    680858.90409 539000.857  20.8%     -    0s\n",
      "     0     0 539035.486    0  179 680858.904 539035.486  20.8%     -    0s\n",
      "H    0     0                    680275.56900 539035.673  20.8%     -    0s\n",
      "H    0     0                    680091.57100 539035.673  20.7%     -    0s\n",
      "     0     0 539041.100    0  179 680091.571 539041.100  20.7%     -    0s\n",
      "     0     0 539043.249    0  182 680091.571 539043.249  20.7%     -    0s\n",
      "     0     0 539043.837    0  185 680091.571 539043.837  20.7%     -    0s\n",
      "H    0     0                    541649.55732 539061.523  0.48%     -    0s\n",
      "H    0     0                    541639.72657 539061.523  0.48%     -    0s\n",
      "H    0     0                    541632.74757 539061.523  0.47%     -    0s\n",
      "     0     0 539061.523    0  189 541632.748 539061.523  0.47%     -    0s\n",
      "H    0     0                    540803.51895 539065.233  0.32%     -    0s\n",
      "     0     0 539065.233    0  161 540803.519 539065.233  0.32%     -    0s\n",
      "H    0     0                    540801.59800 539066.892  0.32%     -    0s\n",
      "     0     0 539066.892    0  171 540801.598 539066.892  0.32%     -    0s\n",
      "     0     0 539067.101    0  161 540801.598 539067.101  0.32%     -    0s\n",
      "     0     0 539075.698    0  183 540801.598 539075.698  0.32%     -    0s\n",
      "     0     0 539078.787    0  192 540801.598 539078.787  0.32%     -    0s\n",
      "H    0     0                    540795.90923 539079.596  0.32%     -    0s\n",
      "     0     0 539079.596    0  192 540795.909 539079.596  0.32%     -    0s\n",
      "H    0     0                    540794.78923 539079.596  0.32%     -    0s\n",
      "H    0     0                    540766.23844 539079.596  0.31%     -    0s\n",
      "H    0     0                    540765.27797 539093.216  0.31%     -    0s\n",
      "     0     0 539093.216    0  190 540765.278 539093.216  0.31%     -    0s\n",
      "H    0     0                    540763.19750 539096.673  0.31%     -    0s\n",
      "     0     0 539096.673    0  191 540763.197 539096.673  0.31%     -    0s\n",
      "     0     0 539097.310    0  185 540763.197 539097.310  0.31%     -    0s\n",
      "H    0     0                    540761.31737 539097.310  0.31%     -    1s\n",
      "     0     0 539102.975    0  211 540761.317 539102.975  0.31%     -    1s\n",
      "     0     0 539105.966    0  223 540761.317 539105.966  0.31%     -    1s\n",
      "     0     0 539107.204    0  224 540761.317 539107.204  0.31%     -    1s\n",
      "H    0     0                    540730.93916 539107.503  0.30%     -    1s\n",
      "     0     0 539107.503    0  221 540730.939 539107.503  0.30%     -    1s\n",
      "H    0     0                    540728.05775 539107.503  0.30%     -    1s\n",
      "H    0     0                    540722.14977 539107.503  0.30%     -    1s\n",
      "H    0     0                    540721.02977 539107.503  0.30%     -    1s\n",
      "H    0     0                    540720.67277 539107.503  0.30%     -    1s\n",
      "H    0     0                    540718.71207 539115.643  0.30%     -    1s\n",
      "     0     0 539115.643    0  188 540718.712 539115.643  0.30%     -    1s\n",
      "     0     0 539117.548    0  186 540718.712 539117.548  0.30%     -    1s\n",
      "     0     0 539118.233    0  212 540718.712 539118.233  0.30%     -    1s\n",
      "     0     0 539123.758    0  215 540718.712 539123.758  0.29%     -    1s\n",
      "     0     0 539123.840    0  215 540718.712 539123.840  0.29%     -    1s\n",
      "     0     2 539123.840    0  215 540718.712 539123.840  0.29%     -    1s\n",
      "H   43    53                    540716.90607 539139.153  0.29%   108    1s\n",
      "H  200   221                    540716.00307 539139.153  0.29%  62.9    2s\n",
      "H  203   221                    540715.10007 539139.153  0.29%  62.3    2s\n",
      "H  206   221                    540711.62112 539139.153  0.29%  62.3    2s\n",
      "H  212   221                    540637.86190 539139.153  0.28%  61.7    2s\n",
      "H  428   442                    540023.40053 539139.153  0.16%  44.9    2s\n",
      "H  449   458                    540013.30792 539139.153  0.16%  43.8    2s\n",
      "H  450   458                    539973.03535 539139.153  0.15%  43.8    2s\n",
      "H  456   458                    539881.06299 539139.153  0.14%  43.7    2s\n",
      "H 1051  1084                    539870.72955 539139.153  0.14%  28.7    2s\n",
      "H 1984  1912                    539865.58666 539144.693  0.13%  22.9    3s\n",
      "  2084  1993 539489.980  147  218 539865.587 539149.537  0.13%  23.9    5s\n",
      "H 2084  1893                    539864.30094 539152.288  0.13%  23.9    5s\n",
      "H 2092  1802                    539851.33949 539188.199  0.12%  23.8    6s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 15\n",
      "  Implied bound: 3\n",
      "  MIR: 237\n",
      "  Mixing: 2\n",
      "  Flow cover: 200\n",
      "  Relax-and-lift: 6\n",
      "\n",
      "Explored 2107 nodes (65404 simplex iterations) in 10.00 seconds (10.63 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 10: 539851 539864 539866 ... 540712\n",
      "\n",
      "Time limit reached\n",
      "Best objective 5.398513394868e+05, best bound 5.392053988380e+05, gap 0.1197%\n",
      "0\n",
      "[] []\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (mac64[x86] - Darwin 22.4.0 22E252)\n",
      "Gurobi Compute Server Worker version 12.0.1 build v12.0.1rc0 (linux64 - \"Ubuntu 20.04.6 LTS\")\n",
      "\n",
      "CPU model: Intel(R) Xeon(R) Platinum 8375C CPU @ 2.90GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  10\n",
      "CSIdleTimeout  1800\n",
      "\n",
      "Optimize a model with 6160 rows, 6144 columns and 16256 nonzeros\n",
      "Model fingerprint: 0xa7740f0d\n",
      "Variable types: 4096 continuous, 2048 integer (2048 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [4e-02, 3e+04]\n",
      "  Objective range  [1e+00, 2e+02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [2e-02, 1e-01]\n",
      "\n",
      "MIP start from previous solve produced solution with objective 539851 (0.01s)\n",
      "Loaded MIP start from previous solve with objective 539851\n",
      "\n",
      "Presolve removed 2774 rows and 2750 columns\n",
      "Presolve time: 0.03s\n",
      "Presolved: 3386 rows, 3394 columns, 9463 nonzeros\n",
      "Variable types: 2186 continuous, 1208 integer (1208 binary)\n",
      "\n",
      "Root relaxation: objective 5.379575e+05, 3855 iterations, 0.06 seconds (0.07 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 537957.489    0   99 539851.339 537957.489  0.35%     -    0s\n",
      "     0     0 538116.337    0   91 539851.339 538116.337  0.32%     -    0s\n",
      "     0     0 538810.513    0   88 539851.339 538810.513  0.19%     -    0s\n",
      "     0     0 538814.422    0   88 539851.339 538814.422  0.19%     -    0s\n",
      "     0     0 538957.979    0  134 539851.339 538957.979  0.17%     -    0s\n",
      "     0     0 538967.517    0  138 539851.339 538967.517  0.16%     -    0s\n",
      "     0     0 538969.986    0  140 539851.339 538969.986  0.16%     -    0s\n",
      "     0     0 538970.065    0  140 539851.339 538970.065  0.16%     -    0s\n",
      "H    0     0                    539847.35814 539020.796  0.15%     -    0s\n",
      "     0     0 539020.796    0  161 539847.358 539020.796  0.15%     -    0s\n",
      "     0     0 539032.169    0  163 539847.358 539032.169  0.15%     -    0s\n",
      "     0     0 539033.969    0  169 539847.358 539033.969  0.15%     -    0s\n",
      "     0     0 539034.458    0  170 539847.358 539034.458  0.15%     -    0s\n",
      "     0     0 539034.626    0  174 539847.358 539034.626  0.15%     -    0s\n",
      "     0     0 539059.718    0  159 539847.358 539059.718  0.15%     -    0s\n",
      "     0     0 539063.598    0  164 539847.358 539063.598  0.15%     -    0s\n",
      "     0     0 539064.881    0  165 539847.358 539064.881  0.14%     -    0s\n",
      "     0     0 539064.986    0  168 539847.358 539064.986  0.14%     -    0s\n",
      "     0     0 539082.991    0  181 539847.358 539082.991  0.14%     -    0s\n",
      "     0     0 539088.180    0  182 539847.358 539088.180  0.14%     -    0s\n",
      "     0     0 539092.058    0  184 539847.358 539092.058  0.14%     -    0s\n",
      "     0     0 539094.884    0  184 539847.358 539094.884  0.14%     -    0s\n",
      "     0     0 539096.110    0  177 539847.358 539096.110  0.14%     -    0s\n",
      "     0     0 539096.437    0  178 539847.358 539096.437  0.14%     -    0s\n",
      "     0     0 539110.589    0  179 539847.358 539110.589  0.14%     -    0s\n",
      "     0     0 539113.698    0  189 539847.358 539113.698  0.14%     -    0s\n",
      "     0     0 539114.606    0  183 539847.358 539114.606  0.14%     -    0s\n",
      "     0     0 539114.874    0  180 539847.358 539114.874  0.14%     -    0s\n",
      "     0     0 539123.793    0  191 539847.358 539123.793  0.13%     -    0s\n",
      "     0     0 539126.143    0  204 539847.358 539126.143  0.13%     -    1s\n",
      "     0     0 539128.096    0  205 539847.358 539128.096  0.13%     -    1s\n",
      "     0     0 539128.906    0  204 539847.358 539128.906  0.13%     -    1s\n",
      "     0     0 539129.007    0  204 539847.358 539129.007  0.13%     -    1s\n",
      "     0     0 539135.567    0  190 539847.358 539135.567  0.13%     -    1s\n",
      "     0     0 539138.072    0  197 539847.358 539138.072  0.13%     -    1s\n",
      "     0     0 539138.712    0  200 539847.358 539138.712  0.13%     -    1s\n",
      "     0     0 539139.120    0  201 539847.358 539139.120  0.13%     -    1s\n",
      "     0     0 539141.832    0  214 539847.358 539141.832  0.13%     -    1s\n",
      "     0     0 539142.127    0  214 539847.358 539142.127  0.13%     -    1s\n",
      "     0     2 539142.147    0  214 539847.358 539142.147  0.13%     -    1s\n",
      "  3079  3010 539742.965  253  203 539847.358 539168.846  0.13%  22.2    5s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 17\n",
      "  Implied bound: 4\n",
      "  MIR: 225\n",
      "  Mixing: 1\n",
      "  Flow cover: 162\n",
      "  Relax-and-lift: 2\n",
      "\n",
      "Explored 3103 nodes (83130 simplex iterations) in 10.01 seconds (11.12 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 2: 539847 539851 \n",
      "\n",
      "Time limit reached\n",
      "Best objective 5.398473581356e+05, best bound 5.392040138807e+05, gap 0.1192%\n",
      "0\n",
      "[] []\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (mac64[x86] - Darwin 22.4.0 22E252)\n",
      "Gurobi Compute Server Worker version 12.0.1 build v12.0.1rc0 (linux64 - \"Ubuntu 20.04.6 LTS\")\n",
      "\n",
      "CPU model: Intel(R) Xeon(R) Platinum 8375C CPU @ 2.90GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  10\n",
      "CSIdleTimeout  1800\n",
      "\n",
      "Optimize a model with 6160 rows, 6144 columns and 16256 nonzeros\n",
      "Model fingerprint: 0xa7740f0d\n",
      "Variable types: 4096 continuous, 2048 integer (2048 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [4e-02, 3e+04]\n",
      "  Objective range  [1e+00, 2e+02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [2e-02, 1e-01]\n",
      "\n",
      "MIP start from previous solve produced solution with objective 539847 (0.01s)\n",
      "MIP start from previous solve produced solution with objective 539847 (0.01s)\n",
      "Loaded MIP start from previous solve with objective 539847\n",
      "\n",
      "Presolve removed 2774 rows and 2750 columns\n",
      "Presolve time: 0.03s\n",
      "Presolved: 3386 rows, 3394 columns, 9463 nonzeros\n",
      "Variable types: 2186 continuous, 1208 integer (1208 binary)\n",
      "\n",
      "Root relaxation: objective 5.379575e+05, 3855 iterations, 0.06 seconds (0.07 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 537957.489    0   99 539847.358 537957.489  0.35%     -    0s\n",
      "     0     0 538116.337    0   91 539847.358 538116.337  0.32%     -    0s\n",
      "     0     0 538813.655    0   89 539847.358 538813.655  0.19%     -    0s\n",
      "     0     0 538814.427    0   88 539847.358 538814.427  0.19%     -    0s\n",
      "     0     0 538958.134    0  133 539847.358 538958.134  0.16%     -    0s\n",
      "     0     0 538968.867    0  139 539847.358 538968.867  0.16%     -    0s\n",
      "     0     0 538971.658    0  140 539847.358 538971.658  0.16%     -    0s\n",
      "     0     0 538971.722    0  143 539847.358 538971.722  0.16%     -    0s\n",
      "     0     0 539020.368    0  165 539847.358 539020.368  0.15%     -    0s\n",
      "     0     0 539030.379    0  177 539847.358 539030.379  0.15%     -    0s\n",
      "     0     0 539032.387    0  176 539847.358 539032.387  0.15%     -    0s\n",
      "     0     0 539033.648    0  176 539847.358 539033.648  0.15%     -    0s\n",
      "     0     0 539033.706    0  177 539847.358 539033.706  0.15%     -    0s\n",
      "     0     0 539053.288    0  152 539847.358 539053.288  0.15%     -    0s\n",
      "     0     0 539057.722    0  182 539847.358 539057.722  0.15%     -    0s\n",
      "     0     0 539058.918    0  183 539847.358 539058.918  0.15%     -    0s\n",
      "     0     0 539059.372    0  165 539847.358 539059.372  0.15%     -    0s\n",
      "     0     0 539085.189    0  187 539847.358 539085.189  0.14%     -    0s\n",
      "     0     0 539093.160    0  183 539847.358 539093.160  0.14%     -    0s\n",
      "     0     0 539095.368    0  184 539847.358 539095.368  0.14%     -    0s\n",
      "     0     0 539095.860    0  184 539847.358 539095.860  0.14%     -    0s\n",
      "     0     0 539096.201    0  182 539847.358 539096.201  0.14%     -    0s\n",
      "     0     0 539106.136    0  189 539847.358 539106.136  0.14%     -    0s\n",
      "     0     0 539107.466    0  197 539847.358 539107.466  0.14%     -    0s\n",
      "     0     0 539108.050    0  198 539847.358 539108.050  0.14%     -    0s\n",
      "     0     0 539108.263    0  190 539847.358 539108.263  0.14%     -    0s\n",
      "     0     0 539122.953    0  172 539847.358 539122.953  0.13%     -    0s\n",
      "     0     0 539126.303    0  190 539847.358 539126.303  0.13%     -    1s\n",
      "     0     0 539127.034    0  196 539847.358 539127.034  0.13%     -    1s\n",
      "     0     0 539127.239    0  197 539847.358 539127.239  0.13%     -    1s\n",
      "     0     0 539132.677    0  200 539847.358 539132.677  0.13%     -    1s\n",
      "     0     0 539134.328    0  213 539847.358 539134.328  0.13%     -    1s\n",
      "     0     0 539134.810    0  222 539847.358 539134.810  0.13%     -    1s\n",
      "     0     0 539140.664    0  221 539847.358 539140.664  0.13%     -    1s\n",
      "     0     0 539141.409    0  219 539847.358 539141.409  0.13%     -    1s\n",
      "     0     0 539141.756    0  222 539847.358 539141.756  0.13%     -    1s\n",
      "     0     0 539145.043    0  215 539847.358 539145.043  0.13%     -    1s\n",
      "     0     0 539145.307    0  215 539847.358 539145.307  0.13%     -    1s\n",
      "     0     2 539145.307    0  215 539847.358 539145.307  0.13%     -    1s\n",
      "H 1348  1346                    539829.67077 539153.069  0.13%  19.2    2s\n",
      "H 2200  2216                    539826.85677 539155.667  0.12%  18.6    2s\n",
      "H 2263  2214                    539819.85573 539155.667  0.12%  18.7    2s\n",
      "H 2378  2194                    539807.67249 539155.667  0.12%  19.6    3s\n",
      "H 2382  2086                    539804.85849 539155.667  0.12%  19.5    4s\n",
      "  2389  2091 539347.211   98  203 539804.858 539170.413  0.12%  19.5    5s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 12\n",
      "  Implied bound: 3\n",
      "  MIR: 175\n",
      "  Mixing: 2\n",
      "  Flow cover: 182\n",
      "  Relax-and-lift: 2\n",
      "\n",
      "Explored 2423 nodes (62075 simplex iterations) in 10.00 seconds (10.84 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 7: 539805 539805 539808 ... 539847\n",
      "\n",
      "Time limit reached\n",
      "Best objective 5.398048584887e+05, best bound 5.392115131519e+05, gap 0.1099%\n",
      "0\n",
      "[] []\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (mac64[x86] - Darwin 22.4.0 22E252)\n",
      "Gurobi Compute Server Worker version 12.0.1 build v12.0.1rc0 (linux64 - \"Ubuntu 20.04.6 LTS\")\n",
      "\n",
      "CPU model: Intel(R) Xeon(R) Platinum 8375C CPU @ 2.90GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  10\n",
      "CSIdleTimeout  1800\n",
      "\n",
      "Optimize a model with 6160 rows, 6144 columns and 16256 nonzeros\n",
      "Model fingerprint: 0xa7740f0d\n",
      "Variable types: 4096 continuous, 2048 integer (2048 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [4e-02, 3e+04]\n",
      "  Objective range  [1e+00, 2e+02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [2e-02, 1e-01]\n",
      "\n",
      "MIP start from previous solve produced solution with objective 539805 (0.01s)\n",
      "MIP start from previous solve produced solution with objective 539805 (0.01s)\n",
      "Loaded MIP start from previous solve with objective 539805\n",
      "\n",
      "Presolve removed 2774 rows and 2750 columns\n",
      "Presolve time: 0.03s\n",
      "Presolved: 3386 rows, 3394 columns, 9463 nonzeros\n",
      "Variable types: 2186 continuous, 1208 integer (1208 binary)\n",
      "\n",
      "Root relaxation: objective 5.379575e+05, 3855 iterations, 0.06 seconds (0.07 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 537957.489    0   99 539804.858 537957.489  0.34%     -    0s\n",
      "     0     0 538116.337    0   91 539804.858 538116.337  0.31%     -    0s\n",
      "     0     0 538810.513    0   88 539804.858 538810.513  0.18%     -    0s\n",
      "     0     0 538814.422    0   88 539804.858 538814.422  0.18%     -    0s\n",
      "     0     0 538959.226    0  131 539804.858 538959.226  0.16%     -    0s\n",
      "     0     0 538968.039    0  136 539804.858 538968.039  0.16%     -    0s\n",
      "     0     0 538970.455    0  137 539804.858 538970.455  0.15%     -    0s\n",
      "     0     0 538970.540    0  139 539804.858 538970.540  0.15%     -    0s\n",
      "     0     0 539023.977    0  163 539804.858 539023.977  0.14%     -    0s\n",
      "     0     0 539039.849    0  171 539804.858 539039.849  0.14%     -    0s\n",
      "     0     0 539041.167    0  170 539804.858 539041.167  0.14%     -    0s\n",
      "     0     0 539041.186    0  170 539804.858 539041.186  0.14%     -    0s\n",
      "     0     0 539066.198    0  150 539804.858 539066.198  0.14%     -    0s\n",
      "     0     0 539072.520    0  178 539804.858 539072.520  0.14%     -    0s\n",
      "     0     0 539072.991    0  178 539804.858 539072.991  0.14%     -    0s\n",
      "     0     0 539073.178    0  179 539804.858 539073.178  0.14%     -    0s\n",
      "     0     0 539092.271    0  180 539804.858 539092.271  0.13%     -    0s\n",
      "     0     0 539094.298    0  183 539804.858 539094.298  0.13%     -    0s\n",
      "     0     0 539095.571    0  191 539804.858 539095.571  0.13%     -    0s\n",
      "     0     0 539096.177    0  192 539804.858 539096.177  0.13%     -    0s\n",
      "     0     0 539096.360    0  197 539804.858 539096.360  0.13%     -    0s\n",
      "     0     0 539104.029    0  188 539804.858 539104.029  0.13%     -    0s\n",
      "     0     0 539110.005    0  188 539804.858 539110.005  0.13%     -    0s\n",
      "     0     0 539111.076    0  186 539804.858 539111.076  0.13%     -    0s\n",
      "     0     0 539111.710    0  192 539804.858 539111.710  0.13%     -    0s\n",
      "     0     0 539111.888    0  195 539804.858 539111.888  0.13%     -    0s\n",
      "     0     0 539123.414    0  181 539804.858 539123.414  0.13%     -    0s\n",
      "     0     0 539125.787    0  196 539804.858 539125.787  0.13%     -    0s\n",
      "     0     0 539126.888    0  196 539804.858 539126.888  0.13%     -    0s\n",
      "     0     0 539127.344    0  197 539804.858 539127.344  0.13%     -    1s\n",
      "     0     0 539133.883    0  194 539804.858 539133.883  0.12%     -    1s\n",
      "     0     0 539135.741    0  214 539804.858 539135.741  0.12%     -    1s\n",
      "     0     0 539136.632    0  207 539804.858 539136.632  0.12%     -    1s\n",
      "     0     0 539136.931    0  208 539804.858 539136.931  0.12%     -    1s\n",
      "     0     0 539141.561    0  204 539804.858 539141.561  0.12%     -    1s\n",
      "     0     0 539142.877    0  196 539804.858 539142.877  0.12%     -    1s\n",
      "     0     0 539143.371    0  203 539804.858 539143.371  0.12%     -    1s\n",
      "     0     0 539146.946    0  200 539804.858 539146.946  0.12%     -    1s\n",
      "     0     0 539147.189    0  200 539804.858 539147.189  0.12%     -    1s\n",
      "     0     2 539147.189    0  200 539804.858 539147.189  0.12%     -    1s\n",
      "  2454  2364 539396.790  155  166 539804.858 539156.148  0.12%  27.2    5s\n",
      "H 2488  2266                    539792.47281 539212.250  0.11%  26.8    9s\n",
      "H 2488  2152                    539791.90094 539212.250  0.11%  26.8    9s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 17\n",
      "  Implied bound: 5\n",
      "  MIR: 206\n",
      "  Mixing: 2\n",
      "  Flow cover: 164\n",
      "  Relax-and-lift: 3\n",
      "\n",
      "Explored 2488 nodes (80895 simplex iterations) in 10.01 seconds (11.20 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 2: 539792 539805 \n",
      "\n",
      "Time limit reached\n",
      "Best objective 5.397919009394e+05, best bound 5.392122502435e+05, gap 0.1074%\n",
      "0\n",
      "[] []\n",
      "dict_keys([4108, 4144, 4145, 4161, 4162, 4178, 4179, 4180, 4181, 4182, 4183, 4194, 4195, 4196, 4197, 4198, 4199, 4200, 4209, 4210, 4211, 4212, 4213, 4214, 4215, 4224, 4225, 4226, 4227, 4228, 4229, 4230, 4231, 4240, 4241, 4242, 4243, 4244, 4245, 4246, 4247, 4257, 4258, 4259, 4260, 4261, 4262, 4263, 4264, 4273, 4274, 4275, 4276, 4277, 4278, 4279, 4280, 4288, 4289, 4290, 4291, 4292, 4293, 4294, 4295, 4304, 4305, 4306, 4307, 4308, 4309, 4310, 4311, 4321, 4322, 4323, 4324, 4325, 4326, 4327, 4328, 4337, 4338, 4339, 4340, 4341, 4342, 4343, 4344, 4354, 4355, 4356, 4357, 4358, 4359, 4360, 4370, 4371, 4372, 4373, 4374, 4375, 4376, 4386, 4387, 4388, 4389, 4390, 4391, 4392, 4402, 4403, 4404, 4405, 4406, 4407, 4408, 4416, 4417, 4418, 4419, 4420, 4421, 4422, 4423, 4433, 4434, 4435, 4436, 4437, 4438, 4439, 4440, 4449, 4450, 4451, 4452, 4453, 4454, 4455, 4456, 4465, 4466, 4467, 4468, 4469, 4470, 4471, 4472, 4482, 4483, 4484, 4485, 4486, 4487, 4488, 4497, 4498, 4499, 4500, 4501, 4502, 4503, 4504, 4513, 4514, 4515, 4516, 4517, 4518, 4519, 4520, 4529, 4530, 4531, 4532, 4533, 4534, 4535, 4536, 4545, 4546, 4547, 4548, 4549, 4550, 4551, 4552, 4560, 4561, 4562, 4563, 4564, 4565, 4566, 4567, 4577, 4578, 4579, 4580, 4581, 4582, 4583, 4584, 4593, 4594, 4595, 4596, 4597, 4598, 4599, 4600, 4609, 4610, 4611, 4612, 4613, 4614, 4615, 4616, 4625, 4626, 4627, 4628, 4629, 4630, 4631, 4632, 4641, 4642, 4643, 4644, 4645, 4646, 4647, 4648, 4656, 4657, 4658, 4659, 4660, 4661, 4662, 4663, 4673, 4674, 4675, 4676, 4677, 4678, 4679, 4680, 4688, 4689, 4690, 4691, 4692, 4693, 4694, 4695, 4704, 4705, 4706, 4707, 4708, 4709, 4710, 4711, 4720, 4721, 4722, 4723, 4724, 4725, 4726, 4736, 4737, 4738, 4739, 4740, 4741, 4742, 4743, 4752, 4753, 4754, 4755, 4756, 4757, 4758, 4759, 4768, 4769, 4770, 4771, 4772, 4773, 4774, 4784, 4785, 4786, 4787, 4788, 4789, 4790, 4791, 4800, 4801, 4802, 4803, 4804, 4805, 4806, 4817, 4818, 4819, 4820, 4821, 4822, 4823, 4824, 4834, 4835, 4836, 4837, 4838, 4839, 4840, 4850, 4851, 4852, 4853, 4854, 4855, 4856, 4865, 4866, 4867, 4868, 4869, 4870, 4871, 4872, 4882, 4883, 4884, 4885, 4886, 4887, 4888, 4897, 4898, 4899, 4900, 4901, 4902, 4903, 4904, 4912, 4913, 4914, 4915, 4916, 4917, 4918, 4919, 4929, 4930, 4931, 4932, 4933, 4934, 4935, 4936, 4945, 4946, 4947, 4948, 4949, 4950, 4951, 4952, 4960, 4961, 4962, 4963, 4964, 4965, 4966, 4967, 4976, 4977, 4978, 4979, 4980, 4981, 4982, 4983, 4993, 4994, 4995, 4996, 4997, 4998, 4999, 5000, 5009, 5010, 5011, 5012, 5013, 5014, 5015, 5016, 5025, 5026, 5027, 5028, 5029, 5030, 5031, 5032, 5040, 5041, 5042, 5043, 5044, 5045, 5046, 5047, 5057, 5058, 5059, 5060, 5061, 5062, 5063, 5064, 5073, 5074, 5075, 5076, 5077, 5078, 5079, 5080, 5089, 5090, 5091, 5092, 5093, 5094, 5104, 5105, 5106, 5107, 5108, 5109, 5110, 5111, 5120, 5121, 5122, 5123, 5124, 5125, 5126, 5127, 5137, 5138, 5139, 5140, 5141, 5142, 5143, 5144, 5152, 5153, 5154, 5155, 5156, 5157, 5158, 5159, 5168, 5169, 5170, 5171, 5172, 5173, 5174, 5175, 5184, 5185, 5186, 5187, 5188, 5189, 5190, 5191, 5201, 5202, 5203, 5204, 5205, 5206, 5207, 5208, 5217, 5218, 5219, 5220, 5221, 5222, 5223, 5224, 5232, 5233, 5234, 5235, 5236, 5237, 5238, 5239, 5240, 5248, 5249, 5250, 5251, 5252, 5253, 5254, 5255, 5264, 5265, 5266, 5267, 5268, 5269, 5270, 5271, 5280, 5281, 5282, 5283, 5284, 5285, 5286, 5287, 5297, 5298, 5299, 5300, 5301, 5302, 5303, 5304, 5312, 5313, 5314, 5315, 5316, 5317, 5318, 5319, 5329, 5330, 5331, 5332, 5333, 5334, 5335, 5336, 5345, 5346, 5347, 5348, 5349, 5350, 5351, 5352, 5361, 5362, 5363, 5364, 5365, 5366, 5367, 5368, 5376, 5377, 5378, 5379, 5380, 5381, 5382, 5383, 5392, 5393, 5394, 5395, 5396, 5397, 5398, 5399, 5408, 5409, 5410, 5411, 5412, 5413, 5414, 5415, 5425, 5426, 5427, 5428, 5429, 5430, 5431, 5432, 5441, 5442, 5443, 5444, 5445, 5446, 5447, 5456, 5457, 5458, 5459, 5460, 5461, 5462, 5463, 5472, 5473, 5474, 5475, 5476, 5477, 5478, 5479, 5489, 5490, 5491, 5492, 5493, 5494, 5495, 5496, 5505, 5506, 5507, 5508, 5509, 5510, 5511, 5520, 5521, 5522, 5523, 5524, 5525, 5526, 5527, 5536, 5537, 5538, 5539, 5540, 5541, 5542, 5543, 5553, 5554, 5555, 5556, 5557, 5558, 5559, 5560, 5569, 5570, 5571, 5572, 5573, 5574, 5575, 5576, 5585, 5586, 5587, 5588, 5589, 5590, 5591, 5592, 5600, 5601, 5602, 5603, 5604, 5605, 5606, 5607, 5617, 5618, 5619, 5620, 5621, 5622, 5623, 5624, 5633, 5634, 5635, 5636, 5637, 5638, 5639, 5640, 5649, 5650, 5651, 5652, 5653, 5654, 5655, 5656, 5664, 5665, 5666, 5667, 5668, 5669, 5670, 5671, 5680, 5681, 5682, 5683, 5684, 5685, 5686, 5687, 5688, 5696, 5697, 5698, 5699, 5700, 5701, 5702, 5703, 5712, 5713, 5714, 5715, 5716, 5717, 5718, 5719, 5728, 5729, 5730, 5731, 5732, 5733, 5734, 5735, 5744, 5745, 5746, 5747, 5748, 5749, 5750, 5751, 5761, 5762, 5763, 5764, 5765, 5766, 5767, 5768, 5778, 5779, 5780, 5781, 5782, 5783, 5784, 5792, 5793, 5794, 5795, 5796, 5797, 5798, 5799, 5808, 5809, 5810, 5811, 5812, 5813, 5814, 5815, 5825, 5826, 5827, 5828, 5829, 5830, 5831, 5832, 5841, 5842, 5843, 5844, 5845, 5846, 5847, 5848, 5858, 5859, 5860, 5861, 5862, 5863, 5864, 5873, 5874, 5875, 5876, 5877, 5878, 5879, 5880, 5889, 5890, 5891, 5892, 5893, 5894, 5895, 5896, 5905, 5906, 5907, 5908, 5909, 5910, 5911, 5912, 5921, 5922, 5923, 5924, 5925, 5926, 5927, 5928, 5937, 5938, 5939, 5940, 5941, 5942, 5943, 5944, 5954, 5955, 5956, 5957, 5958, 5959, 5960, 5969, 5970, 5971, 5972, 5973, 5974, 5975, 5976, 5985, 5986, 5987, 5988, 5989, 5990, 5991, 6000, 6001, 6002, 6003, 6004, 6005, 6006, 6007, 6017, 6018, 6019, 6020, 6021, 6022, 6023, 6024, 6033, 6034, 6035, 6036, 6037, 6038, 6039, 6040, 6049, 6050, 6051, 6052, 6053, 6054, 6055, 6056, 6064, 6065, 6066, 6067, 6068, 6069, 6070, 6071, 6081, 6082, 6083, 6084, 6085, 6086, 6087, 6088, 6097, 6098, 6099, 6100, 6101, 6102, 6103, 6104, 6113, 6114, 6115, 6116, 6117, 6118, 6119, 6120, 6128, 6129, 6130, 6131, 6132, 6133, 6134, 6135, 6136, 6137, 6138, 6139, 6140]) dict_values([(0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0)])\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (mac64[x86] - Darwin 22.4.0 22E252)\n",
      "Gurobi Compute Server Worker version 12.0.1 build v12.0.1rc0 (linux64 - \"Ubuntu 20.04.6 LTS\")\n",
      "\n",
      "CPU model: Intel(R) Xeon(R) Platinum 8375C CPU @ 2.90GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  10\n",
      "CSIdleTimeout  1800\n",
      "\n",
      "Optimize a model with 6160 rows, 6144 columns and 16256 nonzeros\n",
      "Model fingerprint: 0x384c8314\n",
      "Variable types: 4096 continuous, 2048 integer (2048 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [4e-02, 3e+04]\n",
      "  Objective range  [1e+00, 2e+02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [2e-02, 1e-01]\n",
      "\n",
      "MIP start from previous solve produced solution with objective 539792 (0.01s)\n",
      "MIP start from previous solve produced solution with objective 539792 (0.01s)\n",
      "Loaded MIP start from previous solve with objective 539792\n",
      "\n",
      "Presolve removed 314 rows and 302 columns\n",
      "Presolve time: 0.04s\n",
      "Presolved: 5846 rows, 5842 columns, 16144 nonzeros\n",
      "Variable types: 3810 continuous, 2032 integer (2032 binary)\n",
      "\n",
      "Root relaxation: objective 3.799844e+05, 6559 iterations, 0.09 seconds (0.10 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 379984.397    0  184 539791.901 379984.397  29.6%     -    0s\n",
      "     0     0 380978.096    0  248 539791.901 380978.096  29.4%     -    0s\n",
      "     0     0 381080.322    0  267 539791.901 381080.322  29.4%     -    0s\n",
      "     0     0 381089.254    0  269 539791.901 381089.254  29.4%     -    0s\n",
      "H    0     0                    538837.85841 381736.113  29.2%     -    0s\n",
      "H    0     0                    538671.65617 381736.113  29.1%     -    0s\n",
      "     0     0 381736.113    0  324 538671.656 381736.113  29.1%     -    0s\n",
      "     0     0 381810.363    0  336 538671.656 381810.363  29.1%     -    0s\n",
      "     0     0 381817.705    0  338 538671.656 381817.705  29.1%     -    0s\n",
      "     0     0 381818.031    0  340 538671.656 381818.031  29.1%     -    0s\n",
      "H    0     0                    537726.32879 382201.874  28.9%     -    0s\n",
      "     0     0 382201.874    0  349 537726.329 382201.874  28.9%     -    0s\n",
      "H    0     0                    491654.80211 382273.959  22.2%     -    0s\n",
      "H    0     0                    491542.42220 382273.959  22.2%     -    0s\n",
      "H    0     0                    491351.55292 382273.959  22.2%     -    0s\n",
      "     0     0 382273.959    0  383 491351.553 382273.959  22.2%     -    0s\n",
      "     0     0 382286.890    0  388 491351.553 382286.890  22.2%     -    0s\n",
      "     0     0 382288.396    0  402 491351.553 382288.396  22.2%     -    0s\n",
      "     0     0 382288.434    0  407 491351.553 382288.434  22.2%     -    0s\n",
      "H    0     0                    489998.89840 382511.040  21.9%     -    0s\n",
      "H    0     0                    489961.44700 382511.040  21.9%     -    0s\n",
      "     0     0 382511.040    0  397 489961.447 382511.040  21.9%     -    0s\n",
      "H    0     0                    489013.38119 382512.951  21.8%     -    0s\n",
      "H    0     0                    484340.23863 382554.373  21.0%     -    0s\n",
      "H    0     0                    464043.40351 382554.373  17.6%     -    0s\n",
      "H    0     0                    460584.93024 382554.373  16.9%     -    0s\n",
      "     0     0 382554.373    0  476 460584.930 382554.373  16.9%     -    0s\n",
      "     0     0 382558.844    0  488 460584.930 382558.844  16.9%     -    0s\n",
      "     0     0 382560.251    0  508 460584.930 382560.251  16.9%     -    1s\n",
      "     0     0 382560.690    0  511 460584.930 382560.690  16.9%     -    1s\n",
      "     0     0 382706.691    0  394 460584.930 382706.691  16.9%     -    1s\n",
      "     0     0 382746.287    0  429 460584.930 382746.287  16.9%     -    1s\n",
      "     0     0 382763.092    0  451 460584.930 382763.092  16.9%     -    1s\n",
      "H    0     0                    447385.58100 382769.999  14.4%     -    1s\n",
      "H    0     0                    447134.26312 382769.999  14.4%     -    1s\n",
      "     0     0 382769.999    0  503 447134.263 382769.999  14.4%     -    1s\n",
      "H    0     0                    446909.47056 382771.509  14.4%     -    1s\n",
      "     0     0 382771.509    0  502 446909.471 382771.509  14.4%     -    1s\n",
      "     0     0 382771.738    0  485 446909.471 382771.738  14.4%     -    1s\n",
      "     0     0 382884.040    0  457 446909.471 382884.040  14.3%     -    1s\n",
      "H    0     0                    446695.23927 382884.963  14.3%     -    1s\n",
      "H    0     0                    446615.41550 382884.963  14.3%     -    1s\n",
      "H    0     0                    446555.04167 382884.963  14.3%     -    1s\n",
      "H    0     0                    446553.66994 382884.963  14.3%     -    1s\n",
      "     0     0 382925.818    0  563 446553.670 382925.818  14.2%     -    1s\n",
      "     0     0 382934.841    0  558 446553.670 382934.841  14.2%     -    1s\n",
      "     0     0 382939.622    0  567 446553.670 382939.622  14.2%     -    1s\n",
      "     0     0 382940.946    0  570 446553.670 382940.946  14.2%     -    1s\n",
      "H    0     0                    436880.86314 383020.221  12.3%     -    2s\n",
      "H    0     0                    421632.68430 383020.221  9.16%     -    2s\n",
      "H    0     0                    420776.62608 383020.221  8.97%     -    2s\n",
      "H    0     0                    400079.40787 383020.221  4.26%     -    2s\n",
      "H    0     0                    399873.08342 383020.221  4.21%     -    2s\n",
      "H    0     0                    388051.67328 383020.221  1.30%     -    2s\n",
      "H    0     0                    388049.47878 383020.221  1.30%     -    2s\n",
      "     0     0 383020.221    0  584 388049.479 383020.221  1.30%     -    2s\n",
      "     0     0 383043.429    0  596 388049.479 383043.429  1.29%     -    2s\n",
      "     0     0 383050.559    0  632 388049.479 383050.559  1.29%     -    2s\n",
      "     0     0 383051.966    0  588 388049.479 383051.966  1.29%     -    2s\n",
      "H    0     0                    388041.47568 383096.564  1.27%     -    2s\n",
      "H    0     0                    388039.87210 383096.564  1.27%     -    2s\n",
      "     0     0 383096.564    0  590 388039.872 383096.564  1.27%     -    2s\n",
      "H    0     0                    388037.12088 383096.699  1.27%     -    2s\n",
      "H    0     0                    388035.80838 383096.699  1.27%     -    2s\n",
      "     0     0 383107.896    0  628 388035.808 383107.896  1.27%     -    2s\n",
      "     0     0 383114.741    0  562 388035.808 383114.741  1.27%     -    2s\n",
      "     0     0 383119.220    0  642 388035.808 383119.220  1.27%     -    2s\n",
      "     0     0 383120.364    0  665 388035.808 383120.364  1.27%     -    2s\n",
      "H    0     0                    386739.57230 383159.067  0.93%     -    3s\n",
      "H    0     0                    386445.53413 383159.067  0.85%     -    3s\n",
      "     0     0 383159.067    0  664 386445.534 383159.067  0.85%     -    3s\n",
      "H    0     0                    386444.44471 383173.408  0.85%     -    3s\n",
      "     0     0 383173.408    0  674 386444.445 383173.408  0.85%     -    3s\n",
      "     0     0 383177.115    0  667 386444.445 383177.115  0.85%     -    3s\n",
      "     0     0 383178.221    0  660 386444.445 383178.221  0.85%     -    3s\n",
      "     0     0 383197.344    0  657 386444.445 383197.344  0.84%     -    3s\n",
      "H    0     0                    386442.17230 383197.468  0.84%     -    3s\n",
      "     0     0 383204.179    0  687 386442.172 383204.179  0.84%     -    3s\n",
      "     0     0 383205.891    0  681 386442.172 383205.891  0.84%     -    3s\n",
      "     0     0 383215.990    0  640 386442.172 383215.990  0.83%     -    4s\n",
      "     0     0 383216.038    0  640 386442.172 383216.038  0.83%     -    4s\n",
      "     0     2 383216.094    0  640 386442.172 383216.094  0.83%     -    4s\n",
      "    15    24 383280.032    4  598 386442.172 383250.266  0.83%   391    5s\n",
      "H   47    54                    386441.19230 383250.379  0.83%   296    5s\n",
      "H   49    54                    386437.64330 383250.379  0.82%   287    5s\n",
      "H   97   105                    386349.18113 383250.379  0.80%   203    5s\n",
      "H  169   176                    386347.65421 383250.379  0.80%   162    6s\n",
      "H  315   320                    385720.93204 383250.379  0.64%   143    7s\n",
      "H  319   333                    385665.47549 383250.379  0.63%   142    7s\n",
      "H  371   380                    385659.75293 383250.379  0.62%   133    7s\n",
      "H  372   380                    385480.04030 383250.379  0.58%   133    7s\n",
      "H  376   380                    385129.86388 383250.379  0.49%   133    7s\n",
      "H  425   432                    385121.41281 383250.379  0.49%   125    7s\n",
      "H 1376  1336                    385119.67201 383260.635  0.48%  70.1    9s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 20\n",
      "  Cover: 3\n",
      "  Implied bound: 6\n",
      "  MIR: 496\n",
      "  Mixing: 8\n",
      "  Flow cover: 1443\n",
      "\n",
      "Explored 1594 nodes (128769 simplex iterations) in 10.01 seconds (13.51 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 10: 385120 385121 385130 ... 386441\n",
      "\n",
      "Time limit reached\n",
      "Best objective 3.851196720126e+05, best bound 3.832606348296e+05, gap 0.4827%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5086.771200000001,\n",
       " 1695.5904000000003,\n",
       " 1695.5904000000003,\n",
       " 847.7952000000001,\n",
       " 423.89760000000007,\n",
       " 423.89760000000007,\n",
       " 167.17688340479998,\n",
       " 83.58844170239999,\n",
       " 29.023764479999986,\n",
       " 14.511882239999998,\n",
       " 6.046617599999999,\n",
       " 5.038848,\n",
       " 2.099519999999998,\n",
       " 0.5831999999999999,\n",
       " 0.486,\n",
       " 0.20249999999999999,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 44.771916595200054,\n",
       " 22.385958297600027,\n",
       " 23.963435520000022,\n",
       " 11.981717760000006,\n",
       " 7.2001824000000125,\n",
       " 3.5734560000000326,\n",
       " 2.2066320000000186,\n",
       " 0.7905599999999997,\n",
       " 0.4836000000000037,\n",
       " 0.27449999999999997,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.634496,\n",
       " 2.317248,\n",
       " 0.6164400000000264,\n",
       " 0.5364,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.21759999999984436,\n",
       " 0.0,\n",
       " 0.276000000000002,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.7017999999998675,\n",
       " 0.2939999999999968,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4613.997896663039,\n",
       " 1537.9992988876795,\n",
       " 1537.9992988876795,\n",
       " 768.9996494438366,\n",
       " 384.4998247219199,\n",
       " 384.4998247219199,\n",
       " 192.24991236095994,\n",
       " 96.12495618047997,\n",
       " 44.288114688000135,\n",
       " 22.144057343999993,\n",
       " 8.940533759999674,\n",
       " 7.688908799999998,\n",
       " 3.2037119999999994,\n",
       " 0.8899199999999999,\n",
       " 0.7416,\n",
       " 0.3090000000000003,\n",
       " 6627.634666536889,\n",
       " 2209.2115555122964,\n",
       " 2209.2115555122964,\n",
       " 1104.6057777561482,\n",
       " 552.3028888780741,\n",
       " 552.3028888780652,\n",
       " 276.15144443904,\n",
       " 138.07572221952,\n",
       " 47.942959103999996,\n",
       " 23.971479551999998,\n",
       " 9.988116479999999,\n",
       " 5.685811199999973,\n",
       " 3.468096,\n",
       " 0.9633599999999999,\n",
       " 0.8028,\n",
       " 0.3345000000000006,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 24.869265407999944,\n",
       " 12.434632703999608,\n",
       " 10.346434559999999,\n",
       " 8.622028799999999,\n",
       " 3.5925119999999744,\n",
       " 0.997919999999994,\n",
       " 0.8316,\n",
       " 0.3465000000000008,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 7.2783359999999995,\n",
       " 3.0326399999999962,\n",
       " 0.8424,\n",
       " 0.7020000000000001,\n",
       " 0.29250000000000087,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.23700000000000088,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.7387199999999996,\n",
       " 0.6984,\n",
       " 0.29100000000000126,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6551999999999999,\n",
       " 0.27300000000000124,\n",
       " 6276.443878195188,\n",
       " 2092.147959398396,\n",
       " 2092.147959398396,\n",
       " 1046.073979699198,\n",
       " 523.0369898495999,\n",
       " 523.0369898496002,\n",
       " 261.51849492480056,\n",
       " 130.75924746240028,\n",
       " 49.87787673600026,\n",
       " 24.93893836799999,\n",
       " 8.659353600000099,\n",
       " 8.6593536,\n",
       " 3.6080639999999997,\n",
       " 1.0022399999999934,\n",
       " 0.8351999999999999,\n",
       " 0.34800000000000253,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 15.501746995199877,\n",
       " 7.75087349760007,\n",
       " 7.685552332799932,\n",
       " 6.606489599999998,\n",
       " 2.752703999999979,\n",
       " 0.7646399999999999,\n",
       " 0.6372,\n",
       " 0.2655000000000056,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 2.6127359999999995,\n",
       " 0.7257599999999998,\n",
       " 0.0,\n",
       " 0.2520000000000042,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.49852800000000425,\n",
       " 0.6335999999999997,\n",
       " 0.26400000000000756,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6587999999999999,\n",
       " 0.27450000000000274,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 7132.880358604816,\n",
       " 2377.6267862016052,\n",
       " 2377.626786201608,\n",
       " 1188.813393100804,\n",
       " 594.4066965504013,\n",
       " 594.4066965504006,\n",
       " 297.2033482752,\n",
       " 148.60167413759999,\n",
       " 51.59780351999968,\n",
       " 25.798901759999996,\n",
       " 10.74954239999995,\n",
       " 8.95795199999994,\n",
       " 3.73248,\n",
       " 1.0368,\n",
       " 0.864,\n",
       " 0.3600000000000012,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 22.70303354880007,\n",
       " 11.351516774399983,\n",
       " 7.825666867200054,\n",
       " 4.4789760000000545,\n",
       " 2.9859839999999975,\n",
       " 0.82944,\n",
       " 0.6911999999999999,\n",
       " 0.2879999999999998,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 6.217344000000008,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2624999999999704,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 3.108672000000137,\n",
       " 0.88128,\n",
       " 0.7343999999999999,\n",
       " 0.3060000000000014,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5281920000000107,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5796,\n",
       " 0.24149999999999983,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6336,\n",
       " 0.26399999999999935,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.19700000000000123,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " ...]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = get_binary_indices(m)\n",
    "unc = unc.squeeze()\n",
    "to_solve = with_lic(m)\n",
    "to_dispose.append(to_solve)\n",
    "to_solve.setParam(\"TimeLimit\", 10)\n",
    "solve(to_solve, preds, unc, indices, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn4co",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
