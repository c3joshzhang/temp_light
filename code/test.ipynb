{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch torch_geometric torch-scatter pandas scikit-learn wandb\n",
    "# python -m pip install gurobipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temp.data.gen import parallel_generate_problem, parallel_generate_solutions\n",
    "from temp.data.problem import setcover\n",
    "from temp.data.info import ModelInfo\n",
    "from temp.data.dataset import ModelGraphDataset\n",
    "from temp.data.aug import parallel_augment_info, augment_info\n",
    "\n",
    "\n",
    "from temp.solver.utils import solve_inst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAIN_DIR = \"temp/pre_train\"\n",
    "TRAIN_DIR = \"temp/train\"\n",
    "VALID_DIR = \"temp/valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel_generate_problem(setcover, PRE_TRAIN_DIR, 100, 10)\n",
    "# parallel_generate_solutions(PRE_TRAIN_DIR, 10)\n",
    "\n",
    "# parallel_generate_problem(setcover, TRAIN_DIR, 10000, 10)\n",
    "# parallel_generate_solutions(TRAIN_DIR, 10)\n",
    "\n",
    "# parallel_generate_problem(setcover, VALID_DIR, 100, 10)\n",
    "# parallel_generate_solutions(VALID_DIR, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (mac64[x86] - Darwin 22.4.0 22E252)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i9-9980HK CPU @ 2.40GHz\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Optimize a model with 128 rows, 256 columns and 3285 nonzeros\n",
      "Model fingerprint: 0x3820ea4a\n",
      "Variable types: 0 continuous, 256 integer (256 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [5e+00, 2e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Found heuristic solution: objective 216.0000000\n",
      "Presolve time: 0.04s\n",
      "Presolved: 128 rows, 256 columns, 3285 nonzeros\n",
      "Variable types: 0 continuous, 256 integer (256 binary)\n",
      "\n",
      "Root relaxation: objective 7.016822e+01, 213 iterations, 0.01 seconds (0.01 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0   70.16822    0   69  216.00000   70.16822  67.5%     -    0s\n",
      "H    0     0                     202.0000000   70.16822  65.3%     -    0s\n",
      "H    0     0                     171.0000000   70.16822  59.0%     -    0s\n",
      "H    0     0                     133.0000000   70.16822  47.2%     -    0s\n",
      "H    0     0                     114.0000000   70.16822  38.4%     -    0s\n",
      "H    0     0                     109.0000000   70.16822  35.6%     -    0s\n",
      "H    0     0                     106.0000000   70.16822  33.8%     -    0s\n",
      "H    0     0                      96.0000000   70.16822  26.9%     -    0s\n",
      "H    0     0                      94.0000000   70.16822  25.4%     -    0s\n",
      "H    0     0                      93.0000000   70.16822  24.6%     -    0s\n",
      "     0     0   71.39116    0   76   93.00000   71.39116  23.2%     -    0s\n",
      "H    0     0                      92.0000000   71.39116  22.4%     -    0s\n",
      "     0     0   71.39545    0   72   92.00000   71.39545  22.4%     -    0s\n",
      "     0     0   71.58340    0   73   92.00000   71.58340  22.2%     -    0s\n",
      "     0     0   71.58340    0   73   92.00000   71.58340  22.2%     -    0s\n",
      "     0     0   71.58340    0   71   92.00000   71.58340  22.2%     -    0s\n",
      "     0     0   71.58340    0   75   92.00000   71.58340  22.2%     -    0s\n",
      "     0     0   71.58340    0   71   92.00000   71.58340  22.2%     -    0s\n",
      "     0     0   71.63132    0   73   92.00000   71.63132  22.1%     -    0s\n",
      "     0     0   73.84439    0   75   92.00000   73.84439  19.7%     -    0s\n",
      "     0     2   73.84439    0   75   92.00000   73.84439  19.7%     -    0s\n",
      "H 1086   827                      91.0000000   75.94282  16.5%  27.2    0s\n",
      "H 1179   837                      90.0000000   76.14113  15.4%  27.1    0s\n",
      "H 1591   944                      89.0000000   77.30206  13.1%  27.7    0s\n",
      "H 3306  1365                      88.0000000   80.19751  8.87%  27.3    1s\n",
      "* 3573  1352              28      87.0000000   80.19751  7.82%  28.1    1s\n",
      "\n",
      "Explored 6234 nodes (167924 simplex iterations) in 1.52 seconds (1.76 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 10: 87 88 89 ... 106\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 8.700000000000e+01, best bound 8.700000000000e+01, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "m = setcover()\n",
    "vals = solve_inst(m)\n",
    "info = ModelInfo.from_model(m)\n",
    "info.var_info.sols = np.array([[m.objVal] + vals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from temp.data.dataset import info_to_data\n",
    "# d = info_to_data(info)\n",
    "# aug = partial(parallel_augment_info, n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train_d = ModelGraphDataset(PRE_TRAIN_DIR, augment=augment_info)\n",
    "train_d = ModelGraphDataset(TRAIN_DIR, augment=augment_info)\n",
    "valid_d = ModelGraphDataset(VALID_DIR)\n",
    "\n",
    "data = pre_train_d[0][1]\n",
    "var_feature_size = data.var_node_features.size(-1)\n",
    "con_feature_size = data.con_node_features.size(-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "CFG = pd.read_excel(\"temp/trained_models/setcover_model_configs.xlsx\", index_col=0).loc[0].to_dict()\n",
    "CFG[\"num_epochs\"] = 5\n",
    "CFG[\"num_layers\"] = 8\n",
    "CFG[\"hidden\"] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temp.model.utils import get_model\n",
    "from temp.model.trainer import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, model, criterion, optimizer, scheduler = get_model(\".\", var_feature_size, con_feature_size, n_batches=1, **CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.total_steps = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed()\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "pretrain_loader = DataLoader(pre_train_d, batch_size=8, shuffle=True, worker_init_fn=seed_worker, generator=torch.Generator().manual_seed(0))\n",
    "train_loader = DataLoader(train_d, batch_size=8, shuffle=True, worker_init_fn=seed_worker, generator=torch.Generator().manual_seed(0))\n",
    "val_loader = DataLoader(valid_d, batch_size=8, shuffle=True, worker_init_fn=seed_worker, generator=torch.Generator().manual_seed(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.total_steps = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Training starts on the current device cpu\n",
      ">> Pretraining for prenorm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:04<00:00,  3.23it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  6.94it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  9.63it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00, 11.63it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00, 11.54it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00, 12.64it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 14.03it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 16.47it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 19.00it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 14.27it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 18.11it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 17.14it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 13.32it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00, 12.73it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 13.82it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00, 11.65it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00, 10.75it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  9.02it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 1 ----------------------------------------------------------------------------------------------------\n",
      "Training... 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 131/1250 [02:28<18:53,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> tensor(1.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 535/1250 [07:52<08:08,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> tensor(1.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [20:01<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss                0.550505\n",
      "train_acc                 0.870563\n",
      "train_f1                  0.631856\n",
      "train_precision           0.755118\n",
      "train_recall              0.543188\n",
      "train_evidence_succ       2.914634\n",
      "train_evidence_fail       1.849753\n",
      "train_uncertainty_succ    0.456933\n",
      "train_uncertainty_fail    0.549807\n",
      "train_true_bias           0.204493\n",
      "train_pred_bias           0.147100\n",
      "train_soft_pred_bias      0.187517\n",
      "train_bias_error          0.061853\n",
      "train_lr                  0.000165\n",
      "dtype: float32\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:04<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss                0.380519\n",
      "val_acc                 0.919700\n",
      "val_f1                  0.091629\n",
      "val_precision           0.195652\n",
      "val_recall              0.059823\n",
      "val_evidence_succ       5.408840\n",
      "val_evidence_fail       3.815121\n",
      "val_uncertainty_succ    0.286269\n",
      "val_uncertainty_fail    0.397229\n",
      "val_true_bias           0.067692\n",
      "val_pred_bias           0.020529\n",
      "val_soft_pred_bias      0.027706\n",
      "val_bias_error          0.047163\n",
      "val_lr                  0.000165\n",
      "dtype: float32\n",
      ">> Epoch 2 ----------------------------------------------------------------------------------------------------\n",
      "Training... 1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 433/1250 [05:17<12:16,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> tensor(1.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [13:54<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss                0.286877\n",
      "train_acc                 0.939923\n",
      "train_f1                  0.838443\n",
      "train_precision           0.931952\n",
      "train_recall              0.761987\n",
      "train_evidence_succ       7.607777\n",
      "train_evidence_fail       3.096649\n",
      "train_uncertainty_succ    0.246288\n",
      "train_uncertainty_fail    0.447585\n",
      "train_true_bias           0.204588\n",
      "train_pred_bias           0.167276\n",
      "train_soft_pred_bias      0.172706\n",
      "train_bias_error          0.037312\n",
      "train_lr                  0.000345\n",
      "dtype: float32\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:01<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss                 0.317361\n",
      "val_acc                  0.928000\n",
      "val_f1                   0.220779\n",
      "val_precision            0.412955\n",
      "val_recall               0.150665\n",
      "val_evidence_succ       10.376875\n",
      "val_evidence_fail        5.138944\n",
      "val_uncertainty_succ     0.179912\n",
      "val_uncertainty_fail     0.332089\n",
      "val_true_bias            0.067837\n",
      "val_pred_bias            0.025385\n",
      "val_soft_pred_bias       0.027084\n",
      "val_bias_error           0.042452\n",
      "val_lr                   0.000345\n",
      "dtype: float32\n",
      ">> Epoch 3 ----------------------------------------------------------------------------------------------------\n",
      "Training... 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 873/1250 [08:31<05:40,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> tensor(1.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [12:16<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss                 0.232688\n",
      "train_acc                  0.948236\n",
      "train_f1                   0.862121\n",
      "train_precision            0.947083\n",
      "train_recall               0.791147\n",
      "train_evidence_succ       11.991218\n",
      "train_evidence_fail        3.571007\n",
      "train_uncertainty_succ     0.182977\n",
      "train_uncertainty_fail     0.435264\n",
      "train_true_bias            0.204555\n",
      "train_pred_bias            0.170875\n",
      "train_soft_pred_bias       0.177347\n",
      "train_bias_error           0.033680\n",
      "train_lr                   0.000989\n",
      "dtype: float32\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:01<00:00, 11.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss                 0.269169\n",
      "val_acc                  0.933850\n",
      "val_f1                   0.321190\n",
      "val_precision            0.526050\n",
      "val_recall               0.231167\n",
      "val_evidence_succ       15.130222\n",
      "val_evidence_fail        4.686167\n",
      "val_uncertainty_succ     0.150822\n",
      "val_uncertainty_fail     0.387273\n",
      "val_true_bias            0.067644\n",
      "val_pred_bias            0.029760\n",
      "val_soft_pred_bias       0.031571\n",
      "val_bias_error           0.037885\n",
      "val_lr                   0.000989\n",
      "dtype: float32\n",
      ">> Epoch 4 ----------------------------------------------------------------------------------------------------\n",
      "Training... 3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 78/1250 [00:39<08:03,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> tensor(1.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 514/1250 [04:58<07:08,  1.72it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/__workspace__/temp/neural_solver/temp_light/code/temp/model/trainer.py:161\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model_name, model, criterion, optimizer, scheduler, pretrain_loader, train_loader, val_loader, config, WANDB_LOG, model_dir)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>> Epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, epoch, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m))\n\u001b[1;32m    159\u001b[0m epoch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 161\u001b[0m train_log \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    174\u001b[0m     free_gpu_memory()\n",
      "File \u001b[0;32m~/Desktop/__workspace__/temp/neural_solver/temp_light/code/temp/model/trainer.py:77\u001b[0m, in \u001b[0;36mstep\u001b[0;34m(epoch, model, loader, optimizer, scheduler, criterion, step_type, bias_threshold, binary_pred, eval, print_log, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m loss, evidence_tuple, uncertainty \u001b[38;5;241m=\u001b[39m criterion(\n\u001b[1;32m     73\u001b[0m     GLOBAL_STEP, graph_idx, batch, output, y, binary_pred, step_type\n\u001b[1;32m     74\u001b[0m )\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28meval\u001b[39m:\n\u001b[0;32m---> 77\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(scheduler) \u001b[38;5;129;01min\u001b[39;00m [NoamLR, lr_scheduler\u001b[38;5;241m.\u001b[39mOneCycleLR]:\n",
      "File \u001b[0;32m/usr/local/share/c3/v8/conda/Miniconda3-py38_4.9.2-MacOSX-x86_64/envs/gnn4co/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/c3/v8/conda/Miniconda3-py38_4.9.2-MacOSX-x86_64/envs/gnn4co/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model_name, model, criterion, optimizer, scheduler, pretrain_loader, train_loader, val_loader, CFG, False, \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temp.data.dataset import info_to_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = setcover(512, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = ModelInfo.from_model(m)\n",
    "data = info_to_data(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_mask = torch.ones(len(logits), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temp.solver import upr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs, preds = upr.get_predictions(logits, binary_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "unc = upr.get_uncertainty(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = upr.get_threshold(unc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "import gurobipy as gp\n",
    "\n",
    "\n",
    "def fix_var(inst, idxs, vals):\n",
    "    assert len(idxs) == len(vals)\n",
    "    bounds = {}\n",
    "    vs = inst.getVars()\n",
    "    for idx, val in zip(idxs, vals):\n",
    "        v = vs[idx]\n",
    "        bounds[idx] = (v.lb, v.ub)\n",
    "        v.setAttr(\"lb\", val)\n",
    "        v.setAttr(\"ub\", val)\n",
    "    inst.update()\n",
    "    return bounds\n",
    "\n",
    "\n",
    "def unfix_var(inst, idxs, bounds):\n",
    "    assert len(idxs) == len(bounds)\n",
    "    vs = inst.getVars()\n",
    "    print(idxs, bounds)\n",
    "    for i, (lb, ub) in zip(idxs, bounds):\n",
    "        vs[i].setAttr(\"lb\", lb)\n",
    "        vs[i].setAttr(\"ub\", ub)\n",
    "\n",
    "\n",
    "def get_iis_vars(inst):\n",
    "    try:\n",
    "        inst.computeIIS()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        if \"Cannot compute IIS on a feasible model\" in str(e):\n",
    "            return set()\n",
    "        raise e\n",
    "\n",
    "    with NamedTemporaryFile(suffix=\".ilp\", mode=\"w+\") as f:\n",
    "        inst.write(f.name)\n",
    "        f.seek(0)\n",
    "        return set(f.read().split())\n",
    "\n",
    "\n",
    "def set_starts(inst, starts):\n",
    "    vs = inst.getVars()\n",
    "    for i, s in starts.items():\n",
    "        vs[i].setAttr(\"lb\", s)\n",
    "\n",
    "\n",
    "def solve_inst(inst):\n",
    "    vs = inst.getVars()\n",
    "    inst.optimize()\n",
    "    return inst.getAttr(\"X\", vs)\n",
    "\n",
    "\n",
    "def repair(inst, fixed: set, bounds: dict):\n",
    "    old_iis_method = getattr(inst, \"IISMethod\", -1)\n",
    "    inst.setParam(\"IISMethod\", 0)\n",
    "\n",
    "    vs = inst.getVars()\n",
    "    ns = inst.getAttr(\"varName\", vs)\n",
    "    name_to_idx = {n: i for i, n in enumerate(ns)}\n",
    "\n",
    "    freed = set()\n",
    "    while iis_var_names := get_iis_vars(inst):\n",
    "        for n in iis_var_names:\n",
    "            if n not in name_to_idx:\n",
    "                continue\n",
    "\n",
    "            var_idx = name_to_idx[n]\n",
    "            if var_idx not in fixed:\n",
    "                continue\n",
    "\n",
    "            if var_idx in freed:\n",
    "                continue\n",
    "\n",
    "            lb, ub = bounds[var_idx]\n",
    "            vs[var_idx].lb = lb\n",
    "            vs[var_idx].ub = ub\n",
    "            freed.add(var_idx)\n",
    "\n",
    "    inst.setParam(\"IISMethod\", old_iis_method)\n",
    "    return freed\n",
    "\n",
    "\n",
    "def with_lic(m, path=\"gb.lic\"):\n",
    "    with open(path) as f:\n",
    "        env = gp.Env(params=json.load(f))\n",
    "    return m.copy(env=env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# from temp.solver.utils import fix_var, repair, set_starts, unfix_var, solve_inst\n",
    "\n",
    "EVIDENCE_FUNCS = {\n",
    "    \"softplus\": (lambda y: F.softplus(y)),\n",
    "    \"relu\": (lambda y: F.relu(y)),\n",
    "    \"exp\": (lambda y: torch.exp(torch.clamp(y, -10, 10))),\n",
    "}\n",
    "\n",
    "\n",
    "def get_predictions(logits, binary_mask):\n",
    "    probs = torch.softmax(logits, axis=1)\n",
    "    preds = probs[:, 1]\n",
    "    probs = _to_numpy(probs)\n",
    "    preds = _to_numpy(preds).squeeze()\n",
    "    preds[binary_mask] = preds[binary_mask].round()\n",
    "    return probs, preds\n",
    "\n",
    "\n",
    "def get_uncertainty(logits, evidence_func_name: str = \"softplus\"):\n",
    "    evidence = EVIDENCE_FUNCS[evidence_func_name](logits)\n",
    "    alpha = evidence + 1\n",
    "    uncertainty = logits.shape[1] / torch.sum(alpha, dim=1, keepdim=True)\n",
    "    return uncertainty\n",
    "\n",
    "\n",
    "def get_threshold(uncertainty: torch.Tensor, r_min: float = 0.4, r_max: float = 0.55):\n",
    "    q = (r_min + r_max) / 2\n",
    "    threshold = torch.quantile(uncertainty, q)\n",
    "    r = (uncertainty <= threshold).float().mean()\n",
    "\n",
    "    if r > r_max:\n",
    "        threshold = torch.quantile(uncertainty, r_max)\n",
    "        return threshold\n",
    "\n",
    "    if r < r_min:\n",
    "        threshold = torch.quantile(uncertainty, r_min)\n",
    "        return threshold\n",
    "\n",
    "    return threshold\n",
    "\n",
    "\n",
    "def get_confident_idx(indices, uncertainty, threshold):\n",
    "    confident_mask = uncertainty <= threshold\n",
    "    confident_idx = indices[confident_mask]\n",
    "    return confident_idx.sort()[0]\n",
    "\n",
    "\n",
    "def solve(inst, prediction, uncertainty, indices, max_iter):\n",
    "    threshold = get_threshold(uncertainty)\n",
    "    conf_idxs = get_confident_idx(indices, uncertainty, threshold)\n",
    "    conf_vals = prediction[conf_idxs]\n",
    "    bounds = fix_var(inst, conf_idxs, conf_vals)\n",
    "    print(len(bounds), len(prediction))\n",
    "\n",
    "    min_q = sum(uncertainty <= threshold) / len(uncertainty)\n",
    "    max_q = 1.0\n",
    "    dq = (max_q - min_q) / (max_iter - 1)\n",
    "\n",
    "    fixed = set(conf_idxs.tolist())\n",
    "    freed = set(repair(inst, fixed, bounds))\n",
    "    for i in range(1, max_iter):\n",
    "        sol = solve_inst(inst)\n",
    "        q = max_q - dq * i\n",
    "        threshold = np.quantile(uncertainty, q)\n",
    "        conf_idxs = get_confident_idx(indices, uncertainty, threshold)\n",
    "        to_unfix = list(fixed - set(conf_idxs.tolist()))\n",
    "        to_unfix = [i for i in to_unfix if i not in freed]\n",
    "        unfix_var(inst, to_unfix, [bounds[i] for i in to_unfix])\n",
    "        starts = {i: sol[i] for i in to_unfix}\n",
    "        starts.update({i: sol[i] for i in freed})\n",
    "        set_starts(inst, starts)\n",
    "    return sol\n",
    "\n",
    "\n",
    "def _to_numpy(tensor_obj):\n",
    "    return tensor_obj.cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 20\n",
      "122 256\n",
      "Set parameter IISMethod to value 0\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (mac64[x86] - Darwin 22.4.0 22E252)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i9-9980HK CPU @ 2.40GHz\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  20\n",
      "IISMethod  0\n",
      "\n",
      "IIS computation: initial model status unknown, solving to determine model status\n",
      "Found heuristic solution: objective 0.0000000\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 16 available processors)\n",
      "\n",
      "Solution count 1: 0 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 0.000000000000e+00, best bound 0.000000000000e+00, gap 0.0000%\n",
      "IIS runtime: 0.01 seconds (0.00 work units)\n",
      "Cannot compute IIS on a feasible model\n",
      "Set parameter IISMethod to value -1\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (mac64[x86] - Darwin 22.4.0 22E252)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i9-9980HK CPU @ 2.40GHz\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  20\n",
      "\n",
      "Optimize a model with 512 rows, 256 columns and 13120 nonzeros\n",
      "Model fingerprint: 0x974d528e\n",
      "Variable types: 0 continuous, 256 integer (256 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [5e+00, 2e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Found heuristic solution: objective 247.0000000\n",
      "Presolve removed 0 rows and 122 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 512 rows, 134 columns, 7245 nonzeros\n",
      "Variable types: 0 continuous, 134 integer (134 binary)\n",
      "\n",
      "Root relaxation: objective 9.505609e+01, 419 iterations, 0.02 seconds (0.03 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0   95.05609    0   93  247.00000   95.05609  61.5%     -    0s\n",
      "H    0     0                     244.0000000   95.05609  61.0%     -    0s\n",
      "H    0     0                     202.0000000   95.05609  52.9%     -    0s\n",
      "H    0     0                     186.0000000   95.05609  48.9%     -    0s\n",
      "H    0     0                     170.0000000   95.05609  44.1%     -    0s\n",
      "H    0     0                     164.0000000   95.05609  42.0%     -    0s\n",
      "H    0     0                     160.0000000   95.05609  40.6%     -    0s\n",
      "     0     0   95.64288    0   96  160.00000   95.64288  40.2%     -    0s\n",
      "H    0     0                     156.0000000   95.64288  38.7%     -    0s\n",
      "H    0     0                     155.0000000   95.64288  38.3%     -    0s\n",
      "     0     0   95.74005    0   96  155.00000   95.74005  38.2%     -    0s\n",
      "     0     0   96.52595    0   95  155.00000   96.52595  37.7%     -    0s\n",
      "     0     0   96.52595    0   93  155.00000   96.52595  37.7%     -    0s\n",
      "     0     0   96.52595    0   93  155.00000   96.52595  37.7%     -    0s\n",
      "     0     0   96.52595    0   93  155.00000   96.52595  37.7%     -    0s\n",
      "     0     0   98.18940    0   95  155.00000   98.18940  36.7%     -    0s\n",
      "     0     0   98.18940    0   97  155.00000   98.18940  36.7%     -    0s\n",
      "     0     0   98.18940    0   97  155.00000   98.18940  36.7%     -    0s\n",
      "     0     0   98.18940    0   98  155.00000   98.18940  36.7%     -    0s\n",
      "     0     0   98.18940    0   96  155.00000   98.18940  36.7%     -    0s\n",
      "     0     0   98.25786    0   99  155.00000   98.25786  36.6%     -    0s\n",
      "     0     0   98.25786    0   97  155.00000   98.25786  36.6%     -    0s\n",
      "     0     0   98.25786    0   97  155.00000   98.25786  36.6%     -    0s\n",
      "     0     0   98.25786    0   96  155.00000   98.25786  36.6%     -    0s\n",
      "     0     0   98.25786    0   97  155.00000   98.25786  36.6%     -    0s\n",
      "     0     0   98.25786    0   96  155.00000   98.25786  36.6%     -    0s\n",
      "     0     0   99.86021    0   97  155.00000   99.86021  35.6%     -    0s\n",
      "     0     0  102.25563    0  100  155.00000  102.25563  34.0%     -    0s\n",
      "H    0     0                     154.0000000  102.25563  33.6%     -    0s\n",
      "     0     2  102.25563    0  100  154.00000  102.25563  33.6%     -    0s\n",
      "H   74    97                     152.0000000  102.25563  32.7%  66.5    0s\n",
      "H   90    97                     151.0000000  102.25563  32.3%  65.3    0s\n",
      "H  271   280                     147.0000000  102.25563  30.4%  51.2    0s\n",
      "H  841   724                     146.0000000  103.72396  29.0%  46.5    0s\n",
      "H 1351  1122                     145.0000000  104.21841  28.1%  43.4    1s\n",
      "H 2835  1895                     143.0000000  104.72634  26.8%  49.2    2s\n",
      "H 6573  3182                     138.0000000  109.34023  20.8%  47.2    3s\n",
      "  9240  5049  136.69231   29   54  138.00000  113.08841  18.1%  46.3    5s\n",
      " 25503 14868  123.06493   22   71  138.00000  117.41252  14.9%  45.3   10s\n",
      " 42337 23721     cutoff   33       138.00000  119.39949  13.5%  44.2   20s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 4\n",
      "  MIR: 3\n",
      "  Zero half: 3\n",
      "\n",
      "Explored 43851 nodes (1936354 simplex iterations) in 20.02 seconds (19.90 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 10: 138 143 145 ... 156\n",
      "\n",
      "Time limit reached\n",
      "Best objective 1.380000000000e+02, best bound 1.200000000000e+02, gap 13.0435%\n",
      "[] []\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (mac64[x86] - Darwin 22.4.0 22E252)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i9-9980HK CPU @ 2.40GHz\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  20\n",
      "\n",
      "Optimize a model with 512 rows, 256 columns and 13120 nonzeros\n",
      "Model fingerprint: 0x974d528e\n",
      "Variable types: 0 continuous, 256 integer (256 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [5e+00, 2e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolved: 512 rows, 134 columns, 7245 nonzeros\n",
      "\n",
      "Continuing optimization...\n",
      "\n",
      " 43851 23729  124.27036   26   65  138.00000  119.53385  13.4%  44.1   20s\n",
      " 56080 29953  135.47862   46   55  138.00000  120.52458  12.7%  43.6   25s\n",
      " 73551 37313  127.88704   40   64  138.00000  121.60482  11.9%  43.0   30s\n",
      " 92466 44828  135.58159   27   59  138.00000  122.50209  11.2%  42.6   35s\n",
      " 109915 51113  129.31565   31   62  138.00000  123.16318  10.8%  42.3   40s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 4\n",
      "  MIR: 3\n",
      "  Flow cover: 9\n",
      "  Zero half: 3\n",
      "\n",
      "Explored 110718 nodes (4685189 simplex iterations) in 20.01 seconds (35.11 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 10: 138 143 145 ... 156\n",
      "\n",
      "Time limit reached\n",
      "Best objective 1.380000000000e+02, best bound 1.240000000000e+02, gap 10.1449%\n",
      "[] []\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (mac64[x86] - Darwin 22.4.0 22E252)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i9-9980HK CPU @ 2.40GHz\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  20\n",
      "\n",
      "Optimize a model with 512 rows, 256 columns and 13120 nonzeros\n",
      "Model fingerprint: 0x974d528e\n",
      "Variable types: 0 continuous, 256 integer (256 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [5e+00, 2e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolved: 512 rows, 134 columns, 7245 nonzeros\n",
      "\n",
      "Continuing optimization...\n",
      "\n",
      " 110718 51453  127.11108   26   65  138.00000  123.18622  10.7%  42.3   40s\n",
      " 128443 57329  135.23149   28   61  138.00000  123.75122  10.3%  42.0   45s\n",
      " 144137 62292     cutoff   40       138.00000  124.20523  10.0%  41.8   50s\n",
      " 160758 67012  130.18861   28   61  138.00000  124.59763  9.71%  41.6   55s\n",
      " 176529 71270  133.84146   32   63  138.00000  124.97261  9.44%  41.4   60s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 4\n",
      "  MIR: 4\n",
      "  Flow cover: 10\n",
      "  Zero half: 3\n",
      "\n",
      "Explored 176830 nodes (7319459 simplex iterations) in 20.01 seconds (31.49 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 10: 138 143 145 ... 156\n",
      "\n",
      "Time limit reached\n",
      "Best objective 1.380000000000e+02, best bound 1.250000000000e+02, gap 9.4203%\n",
      "[] []\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (mac64[x86] - Darwin 22.4.0 22E252)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i9-9980HK CPU @ 2.40GHz\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  20\n",
      "\n",
      "Optimize a model with 512 rows, 256 columns and 13120 nonzeros\n",
      "Model fingerprint: 0x974d528e\n",
      "Variable types: 0 continuous, 256 integer (256 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [5e+00, 2e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolved: 512 rows, 134 columns, 7245 nonzeros\n",
      "\n",
      "Continuing optimization...\n",
      "\n",
      " 176830 71517     cutoff   29       138.00000  124.98277  9.43%  41.4   60s\n",
      " 190041 74766     cutoff   28       138.00000  125.24866  9.24%  41.3   65s\n",
      " 203259 77744  132.26667   32   61  138.00000  125.49545  9.06%  41.1   70s\n",
      " 213996 80527  135.46389   37   63  138.00000  125.70830  8.91%  41.0   75s\n",
      " 228188 83670  131.38762   29   61  138.00000  125.95093  8.73%  40.9   80s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 4\n",
      "  MIR: 4\n",
      "  Flow cover: 10\n",
      "  Zero half: 3\n",
      "\n",
      "Explored 228884 nodes (9354249 simplex iterations) in 20.02 seconds (23.79 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 10: 138 143 145 ... 156\n",
      "\n",
      "Time limit reached\n",
      "Best objective 1.380000000000e+02, best bound 1.260000000000e+02, gap 8.6957%\n",
      "[] []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = torch.arange(0, len(unc), dtype=int)\n",
    "unc = unc.squeeze()\n",
    "to_solve = m.copy()\n",
    "to_solve.setParam(\"TimeLimit\", 20)\n",
    "solve(to_solve, preds, unc, indices, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 150\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (mac64[x86] - Darwin 22.4.0 22E252)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i9-9980HK CPU @ 2.40GHz\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  150\n",
      "\n",
      "Optimize a model with 512 rows, 256 columns and 13120 nonzeros\n",
      "Model fingerprint: 0x7090591e\n",
      "Variable types: 0 continuous, 256 integer (256 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [5e+00, 2e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Found heuristic solution: objective 299.0000000\n",
      "Presolve time: 0.01s\n",
      "Presolved: 512 rows, 256 columns, 13120 nonzeros\n",
      "Variable types: 0 continuous, 256 integer (256 binary)\n",
      "\n",
      "Root relaxation: objective 9.193545e+01, 578 iterations, 0.04 seconds (0.05 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0   91.93545    0  116  299.00000   91.93545  69.3%     -    0s\n",
      "H    0     0                     295.0000000   91.93545  68.8%     -    0s\n",
      "H    0     0                     294.0000000   91.93545  68.7%     -    0s\n",
      "H    0     0                     292.0000000   91.93545  68.5%     -    0s\n",
      "H    0     0                     286.0000000   91.93545  67.9%     -    0s\n",
      "H    0     0                     185.0000000   91.93545  50.3%     -    0s\n",
      "H    0     0                     163.0000000   91.93545  43.6%     -    0s\n",
      "H    0     0                     162.0000000   91.93545  43.2%     -    0s\n",
      "H    0     0                     161.0000000   91.93545  42.9%     -    0s\n",
      "H    0     0                     153.0000000   91.93545  39.9%     -    0s\n",
      "     0     0   93.15528    0  115  153.00000   93.15528  39.1%     -    0s\n",
      "H    0     0                     152.0000000   93.15528  38.7%     -    0s\n",
      "H    0     0                     150.0000000   93.15528  37.9%     -    0s\n",
      "     0     0   93.15528    0  111  150.00000   93.15528  37.9%     -    0s\n",
      "     0     0   94.23914    0  110  150.00000   94.23914  37.2%     -    0s\n",
      "     0     0   94.23914    0  110  150.00000   94.23914  37.2%     -    0s\n",
      "     0     0   94.23914    0  111  150.00000   94.23914  37.2%     -    0s\n",
      "     0     0   94.23914    0  111  150.00000   94.23914  37.2%     -    0s\n",
      "     0     0   94.23914    0  112  150.00000   94.23914  37.2%     -    0s\n",
      "     0     0   98.69326    0  110  150.00000   98.69326  34.2%     -    0s\n",
      "H    0     0                     147.0000000   98.69326  32.9%     -    0s\n",
      "     0     0   98.77419    0  112  147.00000   98.77419  32.8%     -    0s\n",
      "     0     0   98.77419    0  114  147.00000   98.77419  32.8%     -    0s\n",
      "     0     0   98.77419    0  112  147.00000   98.77419  32.8%     -    0s\n",
      "     0     0   98.77419    0  111  147.00000   98.77419  32.8%     -    0s\n",
      "     0     0   98.84561    0  112  147.00000   98.84561  32.8%     -    0s\n",
      "     0     0   98.84561    0  113  147.00000   98.84561  32.8%     -    0s\n",
      "     0     0   98.84561    0  109  147.00000   98.84561  32.8%     -    0s\n",
      "     0     0   99.28252    0  114  147.00000   99.28252  32.5%     -    0s\n",
      "     0     2   99.28252    0  114  147.00000   99.28252  32.5%     -    1s\n",
      "H  914   793                     139.0000000   99.28252  28.6%  48.8    1s\n",
      "H 1683  1394                     138.0000000   99.28252  28.1%  54.5    2s\n",
      "  5009  3238  129.54553   78   91  138.00000  100.35344  27.3%  76.6    5s\n",
      " 15634 12340  121.77556   37   91  138.00000  106.70230  22.7%  63.5   10s\n",
      " 26753 21481  112.59410   25  101  138.00000  108.84013  21.1%  63.8   15s\n",
      " 39706 32131  136.66038   54   76  138.00000  110.09381  20.2%  62.4   20s\n"
     ]
    }
   ],
   "source": [
    "gb_m = m.copy()\n",
    "gb_m.setParam(\"TimeLimit\", 150)\n",
    "gb_m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn4co",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
