{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6323072-0855-422d-b9b6-2db012ef1849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import time\n",
    "import argparse\n",
    "from typing import List, Dict\n",
    "import pickle\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from multiprocessing import Process\n",
    "\n",
    "from problem import setcover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "994b2a4d-4f79-4c97-9372-450ae3f9bd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70064a15-65be-4dd7-8a94-89a0b43512c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Tuple\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4043a30-c6d9-4f27-9252-32346fa33ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem import parallel_generate_problem, parallel_generate_solutions, setcover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c3549d4-c093-43e5-bf6f-24597951ea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel_generate_problem(setcover, \"temp_pretrain\", n_insts=100, n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8580df83-901a-4a98-a75e-056c88a344ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parallel_generate_solutions(\"temp_pretrain/\", 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5c9a909-24a5-49f4-875a-31b029cb27b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from info import ModelInfo, ConInfo, VarInfo\n",
    "\n",
    "\n",
    "def get_lhs_matrix(n_var: int, con_info: ConInfo) -> torch.Tensor:\n",
    "    n_con = con_info.n\n",
    "    shape = (n_con, n_var)\n",
    "    \n",
    "    idxs = [[], []]\n",
    "    vals = []\n",
    "\n",
    "    for con_idx in range(n_con):\n",
    "        var_idxs = con_info.lhs_p[con_idx]\n",
    "        var_cefs = con_info.lhs_c[con_idx]\n",
    "        for var_idx, var_cef in zip(var_idxs, var_cefs):\n",
    "            idxs[0].append(con_idx)\n",
    "            idxs[1].append(var_idx)\n",
    "            vals.append(var_cef)\n",
    "\n",
    "    lhs = torch.sparse_coo_tensor(idxs, vals, shape)\n",
    "    return lhs\n",
    "\n",
    "\n",
    "def random_shift_binary_var_val(vals, var_info: VarInfo, prob: float=0.2):\n",
    "    shifted = vals.copy()\n",
    "    for i, val in enumerate(vals):\n",
    "        if var_info.types[i] != gp.GRB.BINARY:\n",
    "            continue\n",
    "        if random.random() > prob:\n",
    "            continue\n",
    "        shifted[i] = 1 - vals[i]\n",
    "    return np.array(shifted)\n",
    "            \n",
    "\n",
    "def get_con_shift(lhs, dv):\n",
    "    dv = dv[:np.newaxis] if len(dv.shape) == 1 else dv\n",
    "    shift = lhs @ torch.as_tensor(dv).float()\n",
    "    return shift.numpy().squeeze()\n",
    "\n",
    "\n",
    "def get_obj_shift(ks, dv):\n",
    "    dv = dv.squeeze() if len(dv.shape) == 2 else dv\n",
    "    shift = sum(k * dv[i] for i, k in ks.items())\n",
    "    return shift\n",
    "\n",
    "\n",
    "def shift_model(model, var_shift, rhs_shift):\n",
    "    # ONLY USED FOR VALIDATION\n",
    "    var_shift = var_shift.squeeze() if len(var_shift.shape) == 2 else var_shift\n",
    "    \n",
    "    shifted = model.copy()\n",
    "    vs = shifted.getVars()\n",
    "    # TODO: allow C and I variable bound change\n",
    "    for v, v_shift in zip(vs, var_shift):\n",
    "        if v_shift == 0:\n",
    "            continue\n",
    "        if v_shift > 0:\n",
    "            v.setAttr(\"lb\", 1)\n",
    "            continue\n",
    "        if v_shift < 0:\n",
    "            v.setAttr(\"ub\", 0)\n",
    "            continue\n",
    "\n",
    "    cs = shifted.getConstrs()\n",
    "    for c, c_shift in zip(cs, rhs_shift):\n",
    "        c.setAttr(\"rhs\", c.rhs + c_shift)\n",
    "        \n",
    "    shifted.update()\n",
    "    return shifted\n",
    "\n",
    "\n",
    "def shift_model_info(info: ModelInfo, var_shift, con_shift, obj_shift):\n",
    "    info = info.copy()\n",
    "    var_shift = var_shift.squeeze() if len(var_shift.shape) == 2 else var_shift\n",
    "\n",
    "    info.var_info.sols[:, 1:] += var_shift\n",
    "    info.var_info.sols[:, 0]  += obj_shift\n",
    "    \n",
    "    for i, v_shift in enumerate(var_shift):\n",
    "        if v_shift == 0:\n",
    "            continue\n",
    "            \n",
    "        info.var_info.lbs[i] += v_shift\n",
    "        info.var_info.ubs[i] += v_shift\n",
    "        \n",
    "        if info.var_info.types[i] != gp.GRB.BINARY:            \n",
    "            continue\n",
    "\n",
    "        info.var_info.lbs[i] = max(info.var_info.lbs[i], 0.0)\n",
    "        info.var_info.ubs[i] = min(info.var_info.ubs[i], 1.0)\n",
    "    \n",
    "    for i, c_shift in enumerate(con_shift):\n",
    "        if c_shift == 0:\n",
    "            continue\n",
    "        info.con_info.rhs[i] += c_shift\n",
    "    \n",
    "    return info\n",
    "\n",
    "\n",
    "def augment_model_info(info: ModelInfo, prob=0.2, n=10):\n",
    "    assert info.var_info.sols is not None, \"info must contain solution at var_info.sols\"\n",
    "    aug = []\n",
    "    for i in range(n):\n",
    "        vals = info.var_info.sols[0, 1:]\n",
    "        shifted_vals = random_shift_binary_var_val(vals, info.var_info, prob=prob)\n",
    "        lhs = get_lhs_matrix(info.var_info.n, info.con_info)\n",
    "        var_shfit = shifted_vals - vals\n",
    "        con_shift = get_con_shift(lhs, var_shfit)\n",
    "        obj_shift = get_obj_shift(info.obj_info.ks, var_shfit)\n",
    "        shifted_info = shift_model_info(info, var_shfit, con_shift, obj_shift)\n",
    "        aug.append(shifted_info)\n",
    "    return aug\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ff11b87-98e0-4e9e-b6c1-9908c523a2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2d81eac-69a4-4e04-ae20-c2ddfdc8d52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restricted license - for non-production use only - expires 2026-11-23\n"
     ]
    }
   ],
   "source": [
    "m = setcover()\n",
    "m.update()\n",
    "info = ModelInfo.from_model(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e56ccc9-3854-44af-a91e-79cd7af5c94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (mac64[x86] - Darwin 22.4.0 22E252)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i9-9980HK CPU @ 2.40GHz\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Optimize a model with 100 rows, 200 columns and 2057 nonzeros\n",
      "Model fingerprint: 0xf16fb26f\n",
      "Variable types: 0 continuous, 200 integer (200 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [5e+00, 2e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Found heuristic solution: objective 216.0000000\n",
      "Presolve time: 0.00s\n",
      "Presolved: 100 rows, 200 columns, 2057 nonzeros\n",
      "Variable types: 0 continuous, 200 integer (200 binary)\n",
      "\n",
      "Root relaxation: objective 6.296904e+01, 230 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0   62.96904    0   51  216.00000   62.96904  70.8%     -    0s\n",
      "H    0     0                     205.0000000   62.96904  69.3%     -    0s\n",
      "H    0     0                     159.0000000   62.96904  60.4%     -    0s\n",
      "H    0     0                     158.0000000   62.96904  60.1%     -    0s\n",
      "H    0     0                     130.0000000   62.96904  51.6%     -    0s\n",
      "H    0     0                     100.0000000   62.96904  37.0%     -    0s\n",
      "H    0     0                      99.0000000   62.96904  36.4%     -    0s\n",
      "H    0     0                      95.0000000   62.96904  33.7%     -    0s\n",
      "H    0     0                      91.0000000   62.96904  30.8%     -    0s\n",
      "H    0     0                      89.0000000   65.04801  26.9%     -    0s\n",
      "     0     0   65.04801    0   56   89.00000   65.04801  26.9%     -    0s\n",
      "H    0     0                      86.0000000   65.04801  24.4%     -    0s\n",
      "     0     0   65.04801    0   54   86.00000   65.04801  24.4%     -    0s\n",
      "     0     0   65.04801    0   55   86.00000   65.04801  24.4%     -    0s\n",
      "     0     0   65.04801    0   51   86.00000   65.04801  24.4%     -    0s\n",
      "     0     0   65.04801    0   54   86.00000   65.04801  24.4%     -    0s\n",
      "     0     0   65.04801    0   51   86.00000   65.04801  24.4%     -    0s\n",
      "     0     0   65.04801    0   52   86.00000   65.04801  24.4%     -    0s\n",
      "     0     0   65.10723    0   52   86.00000   65.10723  24.3%     -    0s\n",
      "     0     0   65.10723    0   52   86.00000   65.10723  24.3%     -    0s\n",
      "H    0     0                      84.0000000   68.29830  18.7%     -    0s\n",
      "     0     0   69.60496    0   56   84.00000   69.60496  17.1%     -    0s\n",
      "     0     2   69.60496    0   56   84.00000   69.60496  17.1%     -    0s\n",
      "*  557   472              25      83.0000000   70.36848  15.2%  24.0    0s\n",
      "*  695   485              17      81.0000000   70.74564  12.7%  23.7    0s\n",
      "* 1980   171              18      80.0000000   76.57040  4.29%  22.2    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 6\n",
      "  MIR: 10\n",
      "  Zero half: 2\n",
      "\n",
      "Explored 2294 nodes (47880 simplex iterations) in 0.37 seconds (0.46 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 10: 80 81 83 ... 100\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 8.000000000000e+01, best bound 8.000000000000e+01, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "m.optimize()\n",
    "vals = [v.x for v in m.getVars()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dead52e-3136-40bd-8b96-57697d4de295",
   "metadata": {},
   "outputs": [],
   "source": [
    "info.var_info.sols = np.array([[m.objVal] + vals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44ba0b37-fad3-4df9-bd42-6344279aa2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = augment_model_info(info, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9f610ec-0cfd-48c3-b2f3-545dde4fc568",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_vals = random_shift_binary_var_val(vals, info.var_info)\n",
    "lhs = get_lhs_matrix(info.var_info.n, info.con_info)\n",
    "\n",
    "diff = shifted_vals - vals\n",
    "con_shift = get_con_shift(lhs, diff)\n",
    "obj_shift = get_obj_shift(info.obj_info.ks, diff)\n",
    "\n",
    "shifted_m = shift_model(m, diff, con_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b94faaf-bae4-44d1-a7b3-6d181beb6c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "361.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83a53994-f630-4ccc-a484-c71d0d12bf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (mac64[x86] - Darwin 22.4.0 22E252)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i9-9980HK CPU @ 2.40GHz\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Optimize a model with 100 rows, 200 columns and 2057 nonzeros\n",
      "Model fingerprint: 0x2b99be54\n",
      "Variable types: 0 continuous, 200 integer (200 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [5e+00, 2e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Found heuristic solution: objective 553.0000000\n",
      "Presolve removed 37 rows and 45 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 63 rows, 155 columns, 1018 nonzeros\n",
      "Variable types: 0 continuous, 155 integer (155 binary)\n",
      "\n",
      "Root relaxation: objective 4.397278e+02, 103 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0  439.72780    0   36  553.00000  439.72780  20.5%     -    0s\n",
      "H    0     0                     548.0000000  439.72780  19.8%     -    0s\n",
      "H    0     0                     502.0000000  439.72780  12.4%     -    0s\n",
      "H    0     0                     473.0000000  439.72780  7.03%     -    0s\n",
      "H    0     0                     465.0000000  439.72780  5.43%     -    0s\n",
      "H    0     0                     441.0000000  439.72780  0.29%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  MIR: 2\n",
      "\n",
      "Explored 1 nodes (103 simplex iterations) in 0.03 seconds (0.00 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 6: 441 465 473 ... 553\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.410000000000e+02, best bound 4.410000000000e+02, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "shifted_m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edac8ae9-e114-48ff-83a3-486fb7f222dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read LP format model from file temp/0_0.lp\n",
      "Reading time = 0.00 seconds\n",
      ": 100 rows, 200 columns, 2033 nonzeros\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from info import ModelInfo\n",
    "from graph_preprocessing import get_bipartite_graph, add_label\n",
    "\n",
    "m = gp.read(\"temp/0_0.lp\")\n",
    "s = np.load(\"temp/0_0.npz\")['solutions']\n",
    "\n",
    "info = ModelInfo.from_model(m)\n",
    "\n",
    "g, con_names = get_bipartite_graph(info)\n",
    "g = add_label(g, info, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c66b8eeb-ddcc-47cc-b20a-9f5dbb5aefee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_preprocessing import BipartiteData, constraint_valuation, create_data_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf794a86-3316-458e-b522-2a6a6d54691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from typing import Optional\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class ModelGraphDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None, augment=None):\n",
    "        self._inst_names = self._get_inst_names(root)\n",
    "        self._augment = augment\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def inst_names(self):\n",
    "        return list(self._inst_names)\n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        mdl_paths = [os.path.join(self.root, f\"{n}.lp\") for n in self._inst_names]\n",
    "        sol_paths = [os.path.join(self.root, f\"{n}.npz\") for n in self._inst_names]\n",
    "        return mdl_paths + sol_paths\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def process(self):\n",
    "        raw_info = []\n",
    "        for n in self._inst_names:\n",
    "            m = gp.read(os.path.join(self.root, f\"{n}.lp\"))\n",
    "            s = np.load(os.path.join(self.root, f\"{n}.npz\"))['solutions']\n",
    "            info = ModelInfo.from_model(m)\n",
    "            info.var_info.sols = s\n",
    "            raw_info.append((n, info))\n",
    "    \n",
    "        aug_info = []\n",
    "        if self._augment is not None:\n",
    "            for n, info in tqdm(raw_info, desc=\"model info augmentation\"):\n",
    "                aug_infos = self._augment(info)\n",
    "                aug_names = [f\"aug_{i}_{n}\" for i in range(len(aug_infos))]\n",
    "                aug_info.extend(zip(aug_names, aug_infos))\n",
    "\n",
    "        processed = []\n",
    "        for n, info in tqdm(raw_info + aug_info, desc=\"create data\"):\n",
    "            data = self.info_to_data(info)\n",
    "            data.instance_name = n\n",
    "            processed.append(data)\n",
    "\n",
    "        random.shuffle(processed)\n",
    "        torch.save(self.collate(processed), self.processed_paths[0])\n",
    "\n",
    "    @staticmethod\n",
    "    def info_to_data(info: ModelInfo):\n",
    "        sol = info.var_info.sols\n",
    "        g, _ = get_bipartite_graph(info)\n",
    "        g = add_label(g, info, sol) if sol is not None else g\n",
    "        data = create_data_object(g, sol is not None)\n",
    "        return data\n",
    "    \n",
    "    def get(self, idx):\n",
    "        data = super().get(idx)\n",
    "        return idx, data\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_inst_names(root):\n",
    "        mdl_paths = sorted(p for p in os.listdir(root) if p.endswith(\".lp\"))\n",
    "        sol_paths = sorted(p for p in os.listdir(root) if p.endswith(\".npz\"))\n",
    "        assert len(mdl_paths) == len(sol_paths), (len(mdl_paths), len(sol_paths))\n",
    "        assert set(mp[:-2] == sp[:-3] for mp, sp in zip(mdl_paths, sol_paths))\n",
    "        lp_suffix_len = len(\".lp\")\n",
    "        return [p[:-lp_suffix_len] for p in mdl_paths]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13968087-ab7f-4e0d-b559-f3d9a21eea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"temp\"\n",
    "mdl_paths = sorted(p for p in os.listdir(root) if p.endswith(\".lp\"))\n",
    "sol_paths = sorted(p for p in os.listdir(root) if p.endswith(\".npz\"))\n",
    "\n",
    "for p in mdl_paths:\n",
    "    if p.replace(\".lp\", \".npz\") not in sol_paths:\n",
    "        os.remove(os.path.join(root, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9cbc96f9-1b7d-4a70-a1c5-86a43d3ebf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ModelGraphDataset(\"./temp\", augment=augment_model_info)\n",
    "data = d[0][1]\n",
    "var_feature_size = data.var_node_features.size(-1)\n",
    "con_feature_size = data.con_node_features.size(-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "647158d8-0738-4257-9033-3a3a5e146fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"temp_pretrain\"\n",
    "mdl_paths = sorted(p for p in os.listdir(root) if p.endswith(\".lp\"))\n",
    "sol_paths = sorted(p for p in os.listdir(root) if p.endswith(\".npz\"))\n",
    "\n",
    "for p in mdl_paths:\n",
    "    if p.replace(\".lp\", \".npz\") not in sol_paths:\n",
    "        os.remove(os.path.join(root, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a9c1bc5-3341-4aa1-8e80-1233e616bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_pretrain = ModelGraphDataset(\"./temp_pretrain\", augment=augment_model_info)\n",
    "data = d[0][1]\n",
    "var_feature_size = data.var_node_features.size(-1)\n",
    "con_feature_size = data.con_node_features.size(-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21ba22d7-8cb2-4443-ab43-ee7ad9d4b26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"temp_valid\"\n",
    "mdl_paths = sorted(p for p in os.listdir(root) if p.endswith(\".lp\"))\n",
    "sol_paths = sorted(p for p in os.listdir(root) if p.endswith(\".npz\"))\n",
    "\n",
    "for p in mdl_paths:\n",
    "    if p.replace(\".lp\", \".npz\") not in sol_paths:\n",
    "        os.remove(os.path.join(root, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1d04bde7-b6f2-4d86-8e22-d3e3aa6f35e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_d = ModelGraphDataset(\"./temp_valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0afab5b4-1b4c-4572-8a65-646e6e15cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cfgs = pd.read_excel(\"trained_models/setcover_model_configs.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00a61e0e-5c47-45b5-889a-0b168756a337",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = cfgs.loc[0].T.to_dict()\n",
    "config[\"num_epochs\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "85fb73d2-acc2-4e8f-ab1b-5f7b324fc38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "06779d32-61d5-49a9-9f87-391ec62a9e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, model, criterion, optimizer, scheduler = get_model(\".\", var_feature_size, con_feature_size, n_batches=1, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf646da5-f44e-42e6-a50e-51bea8cae520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ae19ca77-7c57-4bff-b388-8ecb91036376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed()\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "pretrain_loader = DataLoader(d_pretrain, batch_size=8, shuffle=True, worker_init_fn=seed_worker, generator=torch.Generator().manual_seed(0))\n",
    "train_loader = DataLoader(d, batch_size=8, shuffle=True, worker_init_fn=seed_worker, generator=torch.Generator().manual_seed(0))\n",
    "val_loader = DataLoader(valid_d, batch_size=8, shuffle=True, worker_init_fn=seed_worker, generator=torch.Generator().manual_seed(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05e3c7c9-5992-45fb-88e8-a61742ea77e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.total_steps = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df77caf-bc19-4de5-bcfc-68eef564a155",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Training starts on the current device cpu\n",
      ">> Pretraining for prenorm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████| 132/132 [00:01<00:00, 131.08it/s]\n",
      "100%|████████████████████████| 132/132 [00:00<00:00, 216.40it/s]\n",
      "100%|████████████████████████| 132/132 [00:00<00:00, 161.25it/s]\n",
      "100%|█████████████████████████| 132/132 [00:01<00:00, 68.57it/s]\n",
      "100%|█████████████████████████| 132/132 [00:03<00:00, 41.31it/s]\n",
      "100%|█████████████████████████| 132/132 [00:04<00:00, 31.47it/s]\n",
      "100%|█████████████████████████| 132/132 [00:05<00:00, 23.68it/s]\n",
      "100%|█████████████████████████| 132/132 [00:06<00:00, 20.45it/s]\n",
      "100%|█████████████████████████| 132/132 [00:07<00:00, 16.60it/s]\n",
      "100%|█████████████████████████| 132/132 [00:09<00:00, 13.71it/s]\n",
      "100%|█████████████████████████| 132/132 [00:10<00:00, 12.76it/s]\n",
      "100%|█████████████████████████| 132/132 [00:13<00:00,  9.70it/s]\n",
      "100%|█████████████████████████| 132/132 [00:16<00:00,  8.10it/s]\n",
      "100%|█████████████████████████| 132/132 [00:16<00:00,  8.04it/s]\n",
      "100%|█████████████████████████| 132/132 [00:19<00:00,  6.65it/s]\n",
      "100%|█████████████████████████| 132/132 [00:21<00:00,  6.04it/s]\n",
      "100%|█████████████████████████| 132/132 [00:21<00:00,  6.27it/s]\n",
      "100%|█████████████████████████| 132/132 [00:29<00:00,  4.53it/s]\n",
      "  0%|                                   | 0/132 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 1 ----------------------------------------------------------------------------------------------------\n",
      "Training... 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█                        | 58/1364 [00:43<24:14,  1.11s/it]"
     ]
    }
   ],
   "source": [
    "train(model_name, model, criterion, optimizer, scheduler, pretrain_loader, train_loader, val_loader, config, False, \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1cfa90-6b60-4703-a8f3-2271dac75e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67c6f4b-7329-4749-b220-449e07fc127d",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_m = setcover(n_rows=200, n_cols=200)\n",
    "large_d = ModelGraphDataset.inst_to_data(large_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54d1e33-bd94-4137-bfe1-d5f1811f3803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c49cfde-ea85-4827-b31f-b7f30424b9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89814f66-edb1-4305-8d3e-26863e250dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(large_d)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c552bd84-b84e-45e0-a520-08b3b8d878a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "\n",
    "EVIDENCE_FUNCS = {\n",
    "    \"softplus\": (lambda y: F.softplus(y)),\n",
    "    \"relu\"    : (lambda y: F.relu(y)),\n",
    "    \"exp\"     : (lambda y: torch.exp(torch.clamp(y, -10, 10)))\n",
    "}\n",
    "\n",
    "\n",
    "def to_numpy(tensor_obj):\n",
    "    return tensor_obj.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "def get_predictions(logits):\n",
    "    \n",
    "    binary_mask = to_numpy(data.is_binary).squeeze()\n",
    "    binary_idx = np.arange(binary_mask.shape[0])[binary_mask]\n",
    "    probs = torch.softmax(output, axis=1)\n",
    "    preds = probs[:, 1]\n",
    "    \n",
    "    probs = to_numpy(probs)\n",
    "    preds = to_numpy(preds).squeeze()\n",
    "    preds[binary_mask] = preds[binary_mask].round()\n",
    "\n",
    "    return probs, preds\n",
    "\n",
    "\n",
    "def get_uncertainty(logits, evidence_func_name: str=\"softplus\"):\n",
    "    evidence = EVIDENCE_FUNCS[evidence_func_name](logits)\n",
    "    alpha = evidence + 1\n",
    "    uncertainty = logits.shape[1] / torch.sum(alpha, dim=1, keepdim=True)\n",
    "    return uncertainty\n",
    "\n",
    "\n",
    "def get_threshold(uncertainty: torch.Tensor, r_min: float=0.4, r_max: float=0.55):\n",
    "    q = (r_min + r_max) / 2\n",
    "    threshold = torch.quantile(uncertainty, q)\n",
    "    r = (uncertainty <= threshold).float().mean()\n",
    "\n",
    "    if r > r_max:\n",
    "        threshold = torch.quantile(uncertainty, r_max)\n",
    "        ratio = (uncertainty <= threshold).float().mean()\n",
    "        return threashold\n",
    "\n",
    "    if r < r_min:\n",
    "        threshold = torch.quantile(uncertainty, r_min)\n",
    "        ratio = (uncertainty <= threshold).float().mean()\n",
    "        return threashold\n",
    "\n",
    "    return threshold\n",
    "\n",
    "\n",
    "def get_confident_idx(indices, uncertainty, threashold):\n",
    "    confident_mask = uncertainty <= threashold\n",
    "    confident_idx = list(indices[confident_mask])\n",
    "    return sorted(confident_idx)\n",
    "\n",
    "\n",
    "def fix_var(inst, idxs, vals):\n",
    "    assert len(idxs) == len(vals)\n",
    "    bounds = {}\n",
    "    vs = inst.getVars()\n",
    "    for idx, val in zip(idxs, vals):\n",
    "        v = vs[idx]\n",
    "        bounds[idx] = (v.lb, v.ub)\n",
    "        v.setAttr(\"lb\", val)\n",
    "        v.setAttr(\"ub\", val)\n",
    "    inst.update()\n",
    "    return bounds\n",
    "        \n",
    "\n",
    "def unfix_var(inst, idxs, bounds):\n",
    "    assert len(idxs) == len(bounds)\n",
    "    vs = inst.getVars()\n",
    "    for i, (lb, ub) in zip(idxs, bounds):\n",
    "        v.setAttr(\"lb\", lb)\n",
    "        v.setAttr(\"ub\", ub)\n",
    "        \n",
    "\n",
    "def solve(inst):\n",
    "    vs = inst.getVars()\n",
    "    inst.optimize()\n",
    "    return inst.getAttr(\"X\", vs)\n",
    "\n",
    "\n",
    "def get_iis_vars(inst):\n",
    "    try:\n",
    "        inst.computeIIS()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        if \"Cannot compute IIS on a feasible model\" in str(e):\n",
    "            return set()\n",
    "        raise e\n",
    "    \n",
    "    with NamedTemporaryFile(suffix=\".ilp\", mode=\"w+\") as f:\n",
    "        m.write(f.name)\n",
    "        f.seek(0)\n",
    "        return set(f.read().split())\n",
    "\n",
    "\n",
    "def repair(inst, fixed: set, bounds: dict):\n",
    "    old_iis_method = getattr(inst, \"IISMethod\", -1)\n",
    "    inst.setParam(\"IISMethod\", 0)\n",
    "    \n",
    "    vs = inst.getVars()\n",
    "    ns = inst.getAttr(\"varName\", vs)\n",
    "    name_to_idx = {n: i for i, n in enumerate(ns)}\n",
    "\n",
    "    freed = set()\n",
    "    while iis_var_names := get_iis_vars(inst):\n",
    "        for n in iis_var_names:\n",
    "            \n",
    "            if n not in name_to_idx:\n",
    "                continue\n",
    "\n",
    "            var_idx = name_to_idx[n]\n",
    "            if var_idx not in fixed:\n",
    "                continue\n",
    "\n",
    "            if var_idx in freed:\n",
    "                continue\n",
    "            \n",
    "            lb, ub = bounds[var_idx]\n",
    "            vs[var_idx].lb = lb\n",
    "            vs[var_idx].ub = ub\n",
    "            freed.add(var_idx)\n",
    "\n",
    "    inst.setParam(\"IISMethod\", old_iis_method)\n",
    "    return freed\n",
    "    \n",
    "\n",
    "def set_warmstarts(inst, starts):\n",
    "    vs = inst.getVars()\n",
    "    for i, s in starts.items():\n",
    "        vs[i].setAttr(\"lb\", s)\n",
    "\n",
    "\n",
    "def get_priorities(uncertainty, indices):\n",
    "    ...\n",
    "\n",
    "\n",
    "def set_priority(inst, priorities: dict):\n",
    "    ...\n",
    "\n",
    "\n",
    "def reduce_by_uncertainty(inst, prediction, uncertainty, indices, max_iter, timelimit):\n",
    "\n",
    "    threshold = get_threshold(uncertainty)\n",
    "    conf_idxs = get_confident_idx(indices, uncertainty, prediction, threshold)\n",
    "    conf_vals = prediction[conf_idxs]\n",
    "    bounds = fix_var(inst, conf_idxs, conf_vals)\n",
    "    \n",
    "    min_q = sum(uncertainty <= threshold) / len(uncertainty)\n",
    "    max_q = 1.0\n",
    "    dq = (max_q - min_q) / (max_iter - 1)\n",
    "    \n",
    "    fixed = set(conf_idxs)\n",
    "    freed = set(repair(inst, fixed, bounds))\n",
    "    for i in range(1, max_iter):\n",
    "        sol = solve(inst)\n",
    "        q = max_q - dq * i\n",
    "        threshold = np.quantile(uncertainty, q)\n",
    "        conf_idxs = get_confident_idx(indices, uncertainty, prediction, threshold)\n",
    "        to_unfix = list(fixed - set(conf_idxs))\n",
    "        to_unfix = [i for i in to_unfix if i not in freed]\n",
    "        unfix_var(inst, to_unfix, bounds)\n",
    "        starts = {i: sol[i] for i in to_unfix}\n",
    "        starts.update({i: sol[i] for i in freed})\n",
    "        set_warmstart(inst, starts)\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461c5818-9332-4529-b09a-31a2fb2022eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from learn.info import ModelInfo\n",
    "from learn import solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeccd34-78bd-4f9e-9b00-a19e05521ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def with_lic(m):\n",
    "    with open(\"gb.lic\") as f:\n",
    "        env = gp.Env(params=json.load(f))\n",
    "    return m.copy(env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c968a4d9-7dad-4679-b0b5-db699ce5d832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "m = gp.read(\"model_11.lp\")\n",
    "info = ModelInfo.from_model(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306c7331-4f3b-41c7-845c-a0dab1d62ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [[], []]\n",
    "for con_i, lhs_p in enumerate(info.con_info.lhs_p):\n",
    "    shifted_con_i = con_i + info.var_info.n\n",
    "    for var_i in lhs_p: \n",
    "        edges[0].append(var_i)\n",
    "        edges[1].append(shifted_con_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc16eddc-0915-4956-baed-07baf7eaba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = solver.fennel_partition(edges, 4, 0.3, 1)\n",
    "sub_mappings = []\n",
    "sub_infos = []\n",
    "for var_idxs, _ in parts:\n",
    "    sub_info, sub_mapping = info.subset(var_idxs)\n",
    "    sub_infos.append(sub_info)\n",
    "    sub_mappings.append(sub_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0020ec7-259d-45c5-b39f-d1a0acddf7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "stitch_x = [0 for _ in range(info.var_info.n)]\n",
    "for sub_info, sub_mapping in zip(sub_infos, sub_mappings):\n",
    "    cur_m, _ = solver.build_partial_model(sub_info)\n",
    "    cur_m = with_lic(cur_m)\n",
    "    cur_m.optimize()\n",
    "    cur_x = [v.x for v in cur_m.getVars()]\n",
    "    cur_m.dispose()\n",
    "    for new_i, old_i in sub_mapping.items():\n",
    "        stitch_x[old_i] = cur_x[new_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab80103-0b95-4ec8-8c69-736f6c92662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "predictions = []\n",
    "idxs = []\n",
    "uncertainty = []\n",
    "\n",
    "for i, (v, x) in enumerate(zip(m.getVars(), stitch_x)):\n",
    "    if v.vtype != \"B\":\n",
    "        continue\n",
    "    predictions.append(x)\n",
    "    idxs.append(i)\n",
    "    uncertainty.append(random.random())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970b5304-2ca0-46f1-b443-cb6b322feedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_idxs = []\n",
    "fixed_vals = []\n",
    "\n",
    "for i, p in zip(idxs, predictions):\n",
    "    if random.random() > 0.05:\n",
    "        continue\n",
    "    fixed_idxs.append(i)\n",
    "    fixed_vals.append(p)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8242150-7a18-4553-aed9-0022940134a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = with_lic(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c785a6-e510-4063-92d8-719b703dad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = fix_var(m, fixed_idxs, fixed_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3128b6-0391-4be0-bad7-64564e7528ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "freed = repair(m, fixed_idxs, bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ce1ac7-e02e-44af-8443-0cc43a6e2f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a9825-e900-4337-9b73-d6db0eb4d3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.setParam(\"MIPFocus\", 1)\n",
    "m.setParam(\"RINS\", 10)\n",
    "m.setParam(\"TimeLimit\", 120)\n",
    "m.setParam(\"NoRelHeurTime\", 128)\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eb0896-18c0-479d-9373-9a961a06cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "{1:2}.update({3:4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a98e6a9-b6c1-48cd-b3ef-82fc5748d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(freed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c31004d-574c-4789-b253-5541dbecebc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fixed_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed12e097-36dc-4c4c-85d1-9c7d72399d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 == 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
