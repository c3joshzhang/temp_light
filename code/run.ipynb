{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gurobipy as gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learn.info import ModelInfo\n",
    "from learn.feature import VarFeature, ConFeature, EdgFeature\n",
    "from learn.train import Inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "def maximum_independent_set_problem(num_nodes=40, edge_prob=0.3, print_output=True):\n",
    "    edges = []\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(i + 1, num_nodes):\n",
    "            if np.random.rand() < edge_prob:\n",
    "                edges.append((i, j))\n",
    "    m = gp.Model(\"maximum_independent_set\")\n",
    "    x = m.addVars(num_nodes, vtype=GRB.BINARY, name=\"x\")\n",
    "    for i, j in edges:\n",
    "        m.addConstr(x[i] + x[j] <= 1, name=f\"edge_{i}_{j}\")\n",
    "    m.setObjective(gp.quicksum(x[i] for i in range(num_nodes)), GRB.MAXIMIZE)\n",
    "    m.update()\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "var_features = []\n",
    "con_features = []\n",
    "edg_features = []\n",
    "solutions = []\n",
    "\n",
    "for i in range(2048):\n",
    "    m = maximum_independent_set_problem()\n",
    "    info = ModelInfo.from_model(m)\n",
    "    var_features.append(VarFeature.from_info(info.var_info, info.obj_info))\n",
    "    con_features.append(ConFeature.from_info(info.con_info))\n",
    "    edg_features.append(EdgFeature.from_info(info.con_info))\n",
    "    m.optimize()\n",
    "    s = [v.x for v in m.getVars()]\n",
    "    solutions.append(s)\n",
    "\n",
    "inst = Inst(var_features, con_features, edg_features, solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_v_edges, v_c_edges, node_features, edge_features, n_var, n_con = inst.xs\n",
    "ys = inst.ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_mask(size, ratio):\n",
    "    num_zero = int(round(size * ratio))\n",
    "    mask = torch.ones(size, dtype=torch.bool)\n",
    "    idx = torch.randperm(size)[:num_zero]\n",
    "    mask[idx] = 0\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_solution_mask(pool, ratio):\n",
    "    mask = pool.clone()\n",
    "    ones_indices = torch.where(mask == 1)[0]\n",
    "    num_keep = int(round(len(ones_indices) * ratio))\n",
    "\n",
    "    if num_keep <= 0:\n",
    "        mask[ones_indices] = 0\n",
    "        return mask\n",
    "\n",
    "    if num_keep >= len(ones_indices):\n",
    "        return mask\n",
    "\n",
    "    selected_indices = torch.randperm(len(ones_indices))[:num_keep]\n",
    "    keep_indices = ones_indices[selected_indices]\n",
    "    mask[ones_indices] = 0\n",
    "    mask[keep_indices] = 1\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_mask_node_feature(node_feature, y, mask):\n",
    "    node_feature_with_y = torch.hstack([node_feature, y.unsqueeze(1)])\n",
    "    mask = torch.cat([mask, torch.zeros(len(y) - len(mask), dtype=torch.bool)])\n",
    "    masked = node_feature_with_y.clone()\n",
    "    masked[mask, -1] = 0\n",
    "    return torch.hstack([masked, mask.unsqueeze(1)]), mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from learn.model import FocalLoss, SpGAT\n",
    "import torch.optim as optim\n",
    "\n",
    "model = SpGAT(\n",
    "    nfeat=inst.xs[2][0].shape[1] + 2,\n",
    "    nhid=64,\n",
    "    nclass=2,\n",
    "    dropout=0.1,\n",
    "    nheads=6,\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "ce = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.5\n",
    "train_sets = []\n",
    "for i in range(len(ys)):\n",
    "    n = n_var[i]\n",
    "    s = get_train_mask(n, train_ratio)\n",
    "    train_sets.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.45530298 0.54469705]\n",
      " [0.45808306 0.54191697]\n",
      " [0.45958635 0.5404137 ]\n",
      " [0.45820785 0.54179215]\n",
      " [0.46140248 0.5385975 ]\n",
      " [0.442054   0.55794597]\n",
      " [0.45850283 0.5414972 ]\n",
      " [0.45685524 0.54314476]\n",
      " [0.4581124  0.54188764]\n",
      " [0.44167218 0.5583278 ]\n",
      " [0.4606896  0.5393104 ]\n",
      " [0.45411906 0.54588103]\n",
      " [0.45695007 0.5430499 ]\n",
      " [0.45878154 0.54121846]\n",
      " [0.43883634 0.56116366]\n",
      " [0.4464167  0.55358326]\n",
      " [0.45913425 0.5408657 ]\n",
      " [0.4587377  0.54126227]\n",
      " [0.45910347 0.54089653]\n",
      " [0.45852512 0.5414749 ]] [0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0] tensor(10)\n",
      "tensor(47.2926, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.65019065 0.34980926]\n",
      " [0.59560895 0.40439102]\n",
      " [0.59867465 0.40132535]\n",
      " [0.64758635 0.35241362]\n",
      " [0.64893025 0.35106972]\n",
      " [0.5975978  0.40240225]\n",
      " [0.6511746  0.3488254 ]\n",
      " [0.5981437  0.4018563 ]\n",
      " [0.64693564 0.35306436]\n",
      " [0.59562576 0.40437424]\n",
      " [0.64479154 0.35520846]\n",
      " [0.6515223  0.34847772]\n",
      " [0.6487963  0.35120365]\n",
      " [0.6456065  0.35439348]\n",
      " [0.59515494 0.40484503]\n",
      " [0.65336514 0.34663486]\n",
      " [0.6524867  0.34751335]\n",
      " [0.6454991  0.3545009 ]\n",
      " [0.6530066  0.34699333]\n",
      " [0.5981299  0.40187004]] [0 1 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1] tensor(10)\n",
      "tensor(35.0795, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.7543198  0.24568021]\n",
      " [0.7550097  0.24499029]\n",
      " [0.7514559  0.24854413]\n",
      " [0.75502026 0.24497972]\n",
      " [0.75605536 0.2439446 ]\n",
      " [0.69683427 0.30316567]\n",
      " [0.7578662  0.2421338 ]\n",
      " [0.7481238  0.25187615]\n",
      " [0.7531066  0.24689344]\n",
      " [0.7000133  0.29998666]\n",
      " [0.75509393 0.24490605]\n",
      " [0.74871385 0.25128618]\n",
      " [0.7589951  0.24100488]\n",
      " [0.7619014  0.23809864]\n",
      " [0.7571148  0.24288519]\n",
      " [0.7582122  0.2417878 ]\n",
      " [0.75200975 0.24799025]\n",
      " [0.69595885 0.30404112]\n",
      " [0.6919235  0.3080765 ]\n",
      " [0.6973306  0.30266938]] [0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1] tensor(10)\n",
      "tensor(33.5200, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.663506   0.33649406]\n",
      " [0.65417016 0.3458299 ]\n",
      " [0.65068877 0.3493112 ]\n",
      " [0.7556771  0.24432297]\n",
      " [0.7583242  0.24167576]\n",
      " [0.76201344 0.23798662]\n",
      " [0.75966275 0.24033718]\n",
      " [0.76024425 0.23975573]\n",
      " [0.7530859  0.2469141 ]\n",
      " [0.75722235 0.24277756]\n",
      " [0.7592218  0.24077818]\n",
      " [0.7614142  0.23858583]\n",
      " [0.6589559  0.3410441 ]\n",
      " [0.76021016 0.23978986]\n",
      " [0.7629603  0.23703967]\n",
      " [0.76307917 0.23692082]\n",
      " [0.7685886  0.23141141]\n",
      " [0.76380205 0.23619798]\n",
      " [0.6548191  0.3451809 ]\n",
      " [0.75929487 0.24070506]] [1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0] tensor(10)\n",
      "tensor(31.1392, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.6749158  0.32508418]\n",
      " [0.54983443 0.4501656 ]\n",
      " [0.68838847 0.3116116 ]\n",
      " [0.55161893 0.4483811 ]\n",
      " [0.5564103  0.44358966]\n",
      " [0.69461536 0.30538464]\n",
      " [0.66921467 0.33078533]\n",
      " [0.55547345 0.44452652]\n",
      " [0.6825922  0.31740773]\n",
      " [0.55100054 0.44899946]\n",
      " [0.67922986 0.32077014]\n",
      " [0.68537605 0.31462395]\n",
      " [0.6789086  0.3210914 ]\n",
      " [0.54738545 0.45261446]\n",
      " [0.6745861  0.32541385]\n",
      " [0.6992272  0.3007728 ]\n",
      " [0.55214787 0.44785216]\n",
      " [0.5476932  0.4523068 ]\n",
      " [0.66959125 0.33040872]\n",
      " [0.7040933  0.29590678]] [0 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0] tensor(10)\n",
      "tensor(30.2183, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.66279846 0.33720157]\n",
      " [0.50712585 0.49287412]\n",
      " [0.6716345  0.3283655 ]\n",
      " [0.6698     0.33020002]\n",
      " [0.6693686  0.33063138]\n",
      " [0.6840994  0.3159006 ]\n",
      " [0.6767795  0.32322052]\n",
      " [0.6679798  0.33202022]\n",
      " [0.49628738 0.5037126 ]\n",
      " [0.5082771  0.49172285]\n",
      " [0.4970253  0.5029746 ]\n",
      " [0.6533218  0.34667823]\n",
      " [0.65860546 0.34139445]\n",
      " [0.6814835  0.31851655]\n",
      " [0.50414103 0.49585897]\n",
      " [0.67267644 0.32732356]\n",
      " [0.6706806  0.3293194 ]\n",
      " [0.6769146  0.32308543]\n",
      " [0.6868013  0.31319866]\n",
      " [0.67084265 0.32915735]] [0 1 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0] tensor(10)\n",
      "tensor(29.1081, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.7362529  0.26374704]\n",
      " [0.720201   0.27979904]\n",
      " [0.7199358  0.28006423]\n",
      " [0.7381417  0.26185828]\n",
      " [0.73887104 0.261129  ]\n",
      " [0.7358709  0.2641291 ]\n",
      " [0.51920223 0.4807978 ]\n",
      " [0.5242732  0.4757268 ]\n",
      " [0.73490006 0.26509997]\n",
      " [0.7184524  0.2815476 ]\n",
      " [0.71655554 0.28344446]\n",
      " [0.7319617  0.2680383 ]\n",
      " [0.53811705 0.46188292]\n",
      " [0.52378845 0.47621152]\n",
      " [0.73171747 0.26828253]\n",
      " [0.7298     0.2702    ]\n",
      " [0.73530596 0.26469406]\n",
      " [0.7316878  0.2683122 ]\n",
      " [0.5251495  0.47485045]\n",
      " [0.7370399  0.26296014]] [0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0] tensor(10)\n",
      "tensor(26.5514, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.8167202  0.18327989]\n",
      " [0.58408463 0.4159154 ]\n",
      " [0.7948224  0.20517756]\n",
      " [0.80447114 0.19552888]\n",
      " [0.79992616 0.20007385]\n",
      " [0.79819787 0.2018021 ]\n",
      " [0.8031977  0.19680226]\n",
      " [0.57375205 0.42624804]\n",
      " [0.8053477  0.1946523 ]\n",
      " [0.8060703  0.19392967]\n",
      " [0.5734204  0.42657956]\n",
      " [0.7876312  0.21236876]\n",
      " [0.80002975 0.19997022]\n",
      " [0.7964932  0.20350684]\n",
      " [0.58935106 0.4106489 ]\n",
      " [0.8059578  0.1940422 ]\n",
      " [0.81283754 0.18716246]\n",
      " [0.5758793  0.42412075]\n",
      " [0.5668605  0.43313947]\n",
      " [0.8193988  0.18060112]] [0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0] tensor(10)\n",
      "tensor(25.0661, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.855072   0.14492798]\n",
      " [0.58278966 0.41721034]\n",
      " [0.5565038  0.44349614]\n",
      " [0.8435919  0.15640812]\n",
      " [0.8433413  0.1566587 ]\n",
      " [0.8104649  0.18953508]\n",
      " [0.5693844  0.43061557]\n",
      " [0.8275883  0.1724117 ]\n",
      " [0.5701286  0.4298714 ]\n",
      " [0.81795675 0.18204325]\n",
      " [0.8244397  0.17556034]\n",
      " [0.82176626 0.17823374]\n",
      " [0.8215203  0.17847973]\n",
      " [0.8364424  0.16355763]\n",
      " [0.8397135  0.16028647]\n",
      " [0.5626394  0.43736055]\n",
      " [0.8230811  0.17691886]\n",
      " [0.83654326 0.16345678]\n",
      " [0.8306415  0.16935845]\n",
      " [0.81496847 0.1850316 ]] [0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0] tensor(10)\n",
      "tensor(23.5561, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.79958344 0.20041658]\n",
      " [0.8138111  0.18618888]\n",
      " [0.805149   0.194851  ]\n",
      " [0.8264595  0.1735405 ]\n",
      " [0.48738274 0.5126173 ]\n",
      " [0.8056788  0.19432129]\n",
      " [0.79105437 0.20894565]\n",
      " [0.82576084 0.17423917]\n",
      " [0.83024657 0.1697534 ]\n",
      " [0.813505   0.18649496]\n",
      " [0.46116194 0.5388381 ]\n",
      " [0.4752799  0.52472013]\n",
      " [0.75180286 0.24819714]\n",
      " [0.7959021  0.20409791]\n",
      " [0.8240539  0.17594618]\n",
      " [0.81037104 0.18962887]\n",
      " [0.47785425 0.52214575]\n",
      " [0.80165976 0.19834024]\n",
      " [0.802139   0.19786106]\n",
      " [0.4838622  0.5161378 ]] [0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1] tensor(10)\n",
      "tensor(20.7266, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.7880977  0.21190228]\n",
      " [0.7790429  0.22095707]\n",
      " [0.76603365 0.23396629]\n",
      " [0.74345857 0.2565414 ]\n",
      " [0.77755374 0.22244628]\n",
      " [0.33565214 0.6643478 ]\n",
      " [0.7631092  0.23689073]\n",
      " [0.33780602 0.662194  ]\n",
      " [0.74616677 0.2538333 ]\n",
      " [0.33755714 0.66244286]\n",
      " [0.75677925 0.24322076]\n",
      " [0.72170025 0.27829978]\n",
      " [0.7437779  0.25622213]\n",
      " [0.7355592  0.26444077]\n",
      " [0.75298387 0.24701612]\n",
      " [0.7588506  0.24114946]\n",
      " [0.34769166 0.65230834]\n",
      " [0.7403579  0.25964212]\n",
      " [0.7429655  0.25703454]\n",
      " [0.7726757  0.22732428]] [0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0] tensor(10)\n",
      "tensor(19.6455, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.73066676 0.2693332 ]\n",
      " [0.702707   0.297293  ]\n",
      " [0.6979432  0.30205682]\n",
      " [0.7107789  0.28922117]\n",
      " [0.27907336 0.72092664]\n",
      " [0.7595013  0.24049874]\n",
      " [0.28291565 0.7170844 ]\n",
      " [0.7381408  0.26185918]\n",
      " [0.7473853  0.25261474]\n",
      " [0.2862807  0.7137193 ]\n",
      " [0.74327123 0.25672883]\n",
      " [0.711701   0.288299  ]\n",
      " [0.76279384 0.23720615]\n",
      " [0.75537515 0.24462487]\n",
      " [0.2772543  0.7227457 ]\n",
      " [0.71317613 0.28682387]\n",
      " [0.28276804 0.71723187]\n",
      " [0.7264315  0.27356848]\n",
      " [0.7315762  0.2684239 ]\n",
      " [0.74554324 0.25445676]] [0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0] tensor(10)\n",
      "tensor(19.3066, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.796598   0.20340197]\n",
      " [0.7569008  0.24309924]\n",
      " [0.71937525 0.28062475]\n",
      " [0.2820019  0.7179981 ]\n",
      " [0.7764219  0.22357813]\n",
      " [0.7841965  0.2158035 ]\n",
      " [0.27657372 0.7234263 ]\n",
      " [0.27406892 0.72593105]\n",
      " [0.8095053  0.1904947 ]\n",
      " [0.8115999  0.18840012]\n",
      " [0.29281935 0.7071807 ]\n",
      " [0.79932195 0.20067804]\n",
      " [0.78778404 0.21221592]\n",
      " [0.7967045  0.2032955 ]\n",
      " [0.8015128  0.19848724]\n",
      " [0.2813763  0.7186237 ]\n",
      " [0.79885507 0.2011449 ]\n",
      " [0.27946925 0.72053075]\n",
      " [0.7834549  0.21654516]\n",
      " [0.80166525 0.19833478]] [0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 0 0] tensor(10)\n",
      "tensor(16.3421, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.8686299  0.1313701 ]\n",
      " [0.37063447 0.6293655 ]\n",
      " [0.8644656  0.13553448]\n",
      " [0.7739007  0.2260993 ]\n",
      " [0.3506531  0.6493469 ]\n",
      " [0.8646133  0.1353867 ]\n",
      " [0.85177094 0.14822905]\n",
      " [0.8692468  0.13075317]\n",
      " [0.34110218 0.65889776]\n",
      " [0.35840282 0.6415972 ]\n",
      " [0.858619   0.141381  ]\n",
      " [0.35592186 0.6440782 ]\n",
      " [0.34298503 0.65701497]\n",
      " [0.8619446  0.1380554 ]\n",
      " [0.3473919  0.65260816]\n",
      " [0.8614754  0.13852467]\n",
      " [0.86624175 0.13375825]\n",
      " [0.36684993 0.6331501 ]\n",
      " [0.81762725 0.18237272]\n",
      " [0.86589104 0.13410892]] [0 1 0 0 1 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0] tensor(10)\n",
      "tensor(14.8120, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.89272505 0.10727491]\n",
      " [0.87940294 0.12059706]\n",
      " [0.88192445 0.11807557]\n",
      " [0.89807916 0.10192083]\n",
      " [0.89612544 0.10387457]\n",
      " [0.8810371  0.11896292]\n",
      " [0.8904671  0.10953287]\n",
      " [0.8976714  0.10232862]\n",
      " [0.89714146 0.10285851]\n",
      " [0.34208965 0.65791035]\n",
      " [0.33684945 0.66315055]\n",
      " [0.8883718  0.11162816]\n",
      " [0.8792773  0.12072271]\n",
      " [0.8805185  0.11948155]\n",
      " [0.35408476 0.6459153 ]\n",
      " [0.89715993 0.10284005]\n",
      " [0.8842297  0.1157703 ]\n",
      " [0.8931174  0.1068826 ]\n",
      " [0.39171374 0.6082863 ]\n",
      " [0.8880006  0.11199935]] [0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0] tensor(10)\n",
      "tensor(14.0355, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.88800365 0.1119964 ]\n",
      " [0.88564277 0.11435723]\n",
      " [0.87479347 0.12520649]\n",
      " [0.2707341  0.7292659 ]\n",
      " [0.2834657  0.7165342 ]\n",
      " [0.8827659  0.11723413]\n",
      " [0.8699926  0.13000736]\n",
      " [0.3143918  0.68560815]\n",
      " [0.29667222 0.7033278 ]\n",
      " [0.8644678  0.1355322 ]\n",
      " [0.89615846 0.10384155]\n",
      " [0.87002474 0.12997523]\n",
      " [0.89129317 0.10870684]\n",
      " [0.87994784 0.12005217]\n",
      " [0.9049792  0.09502079]\n",
      " [0.27214885 0.7278512 ]\n",
      " [0.8642344  0.13576563]\n",
      " [0.2671351  0.73286486]\n",
      " [0.28769064 0.71230936]\n",
      " [0.89697593 0.10302407]] [0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0] tensor(10)\n",
      "tensor(12.3941, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.87588954 0.12411047]\n",
      " [0.80437106 0.19562896]\n",
      " [0.853837   0.14616302]\n",
      " [0.19150132 0.8084987 ]\n",
      " [0.8838798  0.11612017]\n",
      " [0.85969687 0.14030318]\n",
      " [0.8741803  0.12581965]\n",
      " [0.20631804 0.793682  ]\n",
      " [0.8670685  0.13293146]\n",
      " [0.19589694 0.804103  ]\n",
      " [0.8739754  0.12602457]\n",
      " [0.8670436  0.13295637]\n",
      " [0.8763447  0.12365525]\n",
      " [0.20631786 0.7936821 ]\n",
      " [0.8699162  0.13008377]\n",
      " [0.87536263 0.12463733]\n",
      " [0.8625848  0.13741522]\n",
      " [0.8863166  0.11368338]\n",
      " [0.8882173  0.11178276]\n",
      " [0.83386254 0.16613749]] [0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0] tensor(10)\n",
      "tensor(11.5656, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.8240848  0.17591518]\n",
      " [0.8433914  0.15660857]\n",
      " [0.88081396 0.11918606]\n",
      " [0.8490245  0.15097558]\n",
      " [0.86803806 0.13196194]\n",
      " [0.8451718  0.15482827]\n",
      " [0.8628173  0.13718277]\n",
      " [0.16003755 0.8399625 ]\n",
      " [0.86281294 0.13718705]\n",
      " [0.8478353  0.15216464]\n",
      " [0.17304367 0.82695633]\n",
      " [0.16885273 0.83114725]\n",
      " [0.1739212  0.8260788 ]\n",
      " [0.87350816 0.12649187]\n",
      " [0.1707421  0.8292579 ]\n",
      " [0.8508732  0.14912681]\n",
      " [0.8749336  0.12506635]\n",
      " [0.1701436  0.82985634]\n",
      " [0.8855915  0.11440852]\n",
      " [0.8848117  0.11518832]] [0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0] tensor(10)\n",
      "tensor(11.0870, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.9043678  0.09563223]\n",
      " [0.90251285 0.09748714]\n",
      " [0.9103082  0.0896918 ]\n",
      " [0.18209684 0.81790316]\n",
      " [0.9222361  0.07776391]\n",
      " [0.92183113 0.07816882]\n",
      " [0.91049844 0.08950149]\n",
      " [0.90943986 0.0905601 ]\n",
      " [0.90250105 0.09749902]\n",
      " [0.1695237  0.8304763 ]\n",
      " [0.9110368  0.08896318]\n",
      " [0.16320638 0.8367936 ]\n",
      " [0.9119813  0.08801875]\n",
      " [0.90402216 0.0959778 ]\n",
      " [0.16443458 0.8355654 ]\n",
      " [0.92146283 0.07853714]\n",
      " [0.9115302  0.08846982]\n",
      " [0.92006963 0.07993039]\n",
      " [0.9218694  0.07813063]\n",
      " [0.16017497 0.8398251 ]] [0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1] tensor(10)\n",
      "tensor(9.7435, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.9510664  0.04893363]\n",
      " [0.21038026 0.78961974]\n",
      " [0.21916054 0.78083944]\n",
      " [0.19323485 0.8067652 ]\n",
      " [0.9453415  0.05465853]\n",
      " [0.21319097 0.78680897]\n",
      " [0.9493368  0.05066315]\n",
      " [0.95022756 0.04977248]\n",
      " [0.9446183  0.05538169]\n",
      " [0.9476487  0.05235133]\n",
      " [0.94903    0.05096996]\n",
      " [0.9482234  0.05177657]\n",
      " [0.95101476 0.04898523]\n",
      " [0.9497535  0.05024641]\n",
      " [0.9445459  0.05545406]\n",
      " [0.95081216 0.0491878 ]\n",
      " [0.9460724  0.05392766]\n",
      " [0.9440543  0.05594563]\n",
      " [0.24700549 0.7529945 ]\n",
      " [0.19296765 0.80703235]] [0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1] tensor(10)\n",
      "tensor(9.4358, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.21317676 0.7868232 ]\n",
      " [0.21758725 0.78241277]\n",
      " [0.9530561  0.04694394]\n",
      " [0.9552523  0.04474776]\n",
      " [0.25258029 0.74741966]\n",
      " [0.96076494 0.03923502]\n",
      " [0.96039736 0.03960262]\n",
      " [0.9589215  0.04107843]\n",
      " [0.96128696 0.0387131 ]\n",
      " [0.203403   0.796597  ]\n",
      " [0.9583779  0.04162215]\n",
      " [0.96227574 0.03772427]\n",
      " [0.9554663  0.04453368]\n",
      " [0.24882157 0.75117844]\n",
      " [0.959535   0.04046506]\n",
      " [0.95671237 0.04328761]\n",
      " [0.9581591  0.04184095]\n",
      " [0.95934206 0.04065795]\n",
      " [0.9591978  0.04080217]\n",
      " [0.9582697  0.04173027]] [1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0] tensor(10)\n",
      "tensor(9.0435, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.12712139 0.8728786 ]\n",
      " [0.96241486 0.03758521]\n",
      " [0.9490666  0.05093342]\n",
      " [0.9604104  0.03958955]\n",
      " [0.1323484  0.8676516 ]\n",
      " [0.9574176  0.04258233]\n",
      " [0.96251136 0.03748868]\n",
      " [0.96445537 0.03554465]\n",
      " [0.96329534 0.03670467]\n",
      " [0.9604303  0.03956965]\n",
      " [0.15550165 0.84449834]\n",
      " [0.9620195  0.03798046]\n",
      " [0.96284413 0.0371559 ]\n",
      " [0.14983104 0.850169  ]\n",
      " [0.9658969  0.0341031 ]\n",
      " [0.9620248  0.03797525]\n",
      " [0.96631616 0.03368386]\n",
      " [0.9593773  0.04062271]\n",
      " [0.96198726 0.03801266]\n",
      " [0.95447326 0.04552673]] [1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0] tensor(10)\n",
      "tensor(8.0348, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.9290683  0.07093169]\n",
      " [0.96304905 0.03695094]\n",
      " [0.07960322 0.9203968 ]\n",
      " [0.9226186  0.07738137]\n",
      " [0.94875014 0.05124985]\n",
      " [0.9348274  0.06517262]\n",
      " [0.94858795 0.05141205]\n",
      " [0.08292229 0.9170777 ]\n",
      " [0.95158887 0.04841113]\n",
      " [0.95803106 0.04196897]\n",
      " [0.08110965 0.91889036]\n",
      " [0.96025586 0.03974409]\n",
      " [0.08332606 0.91667396]\n",
      " [0.9409896  0.05901041]\n",
      " [0.9543021  0.04569798]\n",
      " [0.9453483  0.05465169]\n",
      " [0.9324312  0.06756883]\n",
      " [0.9554452  0.04455483]\n",
      " [0.08443453 0.9155655 ]\n",
      " [0.96422386 0.03577606]] [0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0] tensor(10)\n",
      "tensor(7.5732, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.05268098 0.947319  ]\n",
      " [0.04956664 0.9504333 ]\n",
      " [0.925128   0.07487202]\n",
      " [0.9355021  0.06449792]\n",
      " [0.9031624  0.09683758]\n",
      " [0.931831   0.06816906]\n",
      " [0.04791789 0.9520821 ]\n",
      " [0.928172   0.07182796]\n",
      " [0.9186623  0.08133762]\n",
      " [0.93102163 0.06897841]\n",
      " [0.9349296  0.06507042]\n",
      " [0.92220217 0.07779785]\n",
      " [0.05013676 0.94986326]\n",
      " [0.94167316 0.05832682]\n",
      " [0.04719402 0.952806  ]\n",
      " [0.9365325  0.06346744]\n",
      " [0.93730396 0.06269599]\n",
      " [0.9434492  0.05655078]\n",
      " [0.05374462 0.9462554 ]\n",
      " [0.9287826  0.07121744]] [1 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0] tensor(10)\n",
      "tensor(7.7306, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.03867859 0.9613214 ]\n",
      " [0.94869554 0.05130441]\n",
      " [0.9487564  0.05124364]\n",
      " [0.03793207 0.96206796]\n",
      " [0.89182276 0.10817724]\n",
      " [0.93603194 0.06396805]\n",
      " [0.9484956  0.05150435]\n",
      " [0.9380919  0.06190813]\n",
      " [0.9130864  0.08691362]\n",
      " [0.0390661  0.9609339 ]\n",
      " [0.9185723  0.08142769]\n",
      " [0.92819244 0.07180752]\n",
      " [0.04128982 0.9587102 ]\n",
      " [0.9472734  0.05272659]\n",
      " [0.9316087  0.06839134]\n",
      " [0.93928546 0.0607145 ]\n",
      " [0.9024029  0.09759711]\n",
      " [0.9530328  0.04696723]\n",
      " [0.95098215 0.04901788]\n",
      " [0.9433108  0.0566892 ]] [1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0] tensor(10)\n",
      "tensor(7.3326, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.03444354 0.9655565 ]\n",
      " [0.9825581  0.017442  ]\n",
      " [0.9689427  0.03105723]\n",
      " [0.9811559  0.01884409]\n",
      " [0.03738804 0.962612  ]\n",
      " [0.9692833  0.03071667]\n",
      " [0.03502702 0.96497303]\n",
      " [0.95558393 0.0444161 ]\n",
      " [0.96904504 0.03095504]\n",
      " [0.97588557 0.02411444]\n",
      " [0.95884764 0.0411524 ]\n",
      " [0.96391475 0.0360852 ]\n",
      " [0.04099755 0.95900244]\n",
      " [0.9593308  0.04066917]\n",
      " [0.97566503 0.02433492]\n",
      " [0.9577741  0.04222588]\n",
      " [0.0385632  0.9614368 ]\n",
      " [0.04173944 0.95826054]\n",
      " [0.03740688 0.9625931 ]\n",
      " [0.03879154 0.9612085 ]] [1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 1 1 1] tensor(10)\n",
      "tensor(6.6341, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.06663431 0.93336564]\n",
      " [0.9896107  0.0103893 ]\n",
      " [0.06525065 0.93474936]\n",
      " [0.9910834  0.00891663]\n",
      " [0.06715423 0.9328458 ]\n",
      " [0.06197598 0.938024  ]\n",
      " [0.9890022  0.01099782]\n",
      " [0.99085325 0.00914678]\n",
      " [0.99214715 0.00785286]\n",
      " [0.9901523  0.00984773]\n",
      " [0.9902132  0.00978682]\n",
      " [0.05163699 0.94836295]\n",
      " [0.99110657 0.0088934 ]\n",
      " [0.0502941  0.9497059 ]\n",
      " [0.9895068  0.01049324]\n",
      " [0.05323859 0.94676137]\n",
      " [0.99172664 0.00827336]\n",
      " [0.9917571  0.00824284]\n",
      " [0.9906345  0.00936545]\n",
      " [0.9908331  0.00916691]] [1 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0] tensor(10)\n",
      "tensor(6.4526, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.9960336  0.00396642]\n",
      " [0.12928343 0.8707166 ]\n",
      " [0.99591225 0.00408773]\n",
      " [0.995516   0.00448398]\n",
      " [0.99518377 0.00481629]\n",
      " [0.1649403  0.8350597 ]\n",
      " [0.99547476 0.00452524]\n",
      " [0.99511886 0.00488117]\n",
      " [0.9964224  0.00357766]\n",
      " [0.9961785  0.00382155]\n",
      " [0.12893319 0.87106687]\n",
      " [0.9959571  0.00404295]\n",
      " [0.9957858  0.00421426]\n",
      " [0.99523747 0.00476253]\n",
      " [0.9957331  0.00426694]\n",
      " [0.99556774 0.0044323 ]\n",
      " [0.12467138 0.87532866]\n",
      " [0.99544674 0.00455326]\n",
      " [0.99579877 0.00420117]\n",
      " [0.99539906 0.00460099]] [0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0] tensor(10)\n",
      "tensor(7.1222, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.15451327 0.8454867 ]\n",
      " [0.9965663  0.0034337 ]\n",
      " [0.9975122  0.00248779]\n",
      " [0.16545458 0.8345454 ]\n",
      " [0.9973189  0.00268113]\n",
      " [0.9973877  0.00261229]\n",
      " [0.9969194  0.00308067]\n",
      " [0.9974195  0.00258052]\n",
      " [0.99717426 0.00282569]\n",
      " [0.99737954 0.00262047]\n",
      " [0.9972006  0.00279939]\n",
      " [0.99646604 0.00353397]\n",
      " [0.9962393  0.00376064]\n",
      " [0.9974274  0.00257261]\n",
      " [0.21755631 0.78244364]\n",
      " [0.997162   0.00283802]\n",
      " [0.99711007 0.00288995]\n",
      " [0.2122683  0.78773165]\n",
      " [0.12722568 0.87277436]\n",
      " [0.22115043 0.7788495 ]] [1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1] tensor(10)\n",
      "tensor(7.6049, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.9979012  0.00209877]\n",
      " [0.9970009  0.00299912]\n",
      " [0.99752873 0.00247132]\n",
      " [0.12628382 0.87371624]\n",
      " [0.99777275 0.00222717]\n",
      " [0.99766064 0.00233939]\n",
      " [0.99791807 0.0020819 ]\n",
      " [0.11578134 0.88421863]\n",
      " [0.9977704  0.00222964]\n",
      " [0.10506754 0.89493245]\n",
      " [0.9977187  0.00228136]\n",
      " [0.9978702  0.00212974]\n",
      " [0.9973839  0.00261608]\n",
      " [0.997827   0.00217295]\n",
      " [0.9976266  0.00237346]\n",
      " [0.99742824 0.00257174]\n",
      " [0.08563147 0.9143685 ]\n",
      " [0.9976273  0.00237271]\n",
      " [0.10977454 0.89022547]\n",
      " [0.07968163 0.92031837]] [0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1] tensor(10)\n",
      "tensor(6.8264, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.9950714  0.00492857]\n",
      " [0.9977549  0.00224517]\n",
      " [0.99734336 0.00265666]\n",
      " [0.03399067 0.9660094 ]\n",
      " [0.03201734 0.9679826 ]\n",
      " [0.9971034  0.00289657]\n",
      " [0.99730444 0.0026956 ]\n",
      " [0.9975957  0.00240426]\n",
      " [0.9978993  0.00210068]\n",
      " [0.9965088  0.0034912 ]\n",
      " [0.99671125 0.00328876]\n",
      " [0.99686265 0.00313736]\n",
      " [0.9977005  0.00229949]\n",
      " [0.04278061 0.95721936]\n",
      " [0.02500189 0.9749981 ]\n",
      " [0.9974826  0.00251746]\n",
      " [0.99739456 0.00260539]\n",
      " [0.05511105 0.94488895]\n",
      " [0.99672383 0.00327624]\n",
      " [0.03971609 0.9602839 ]] [0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1] tensor(10)\n",
      "tensor(6.0982, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.99569726 0.0043027 ]\n",
      " [0.01132081 0.98867923]\n",
      " [0.99663854 0.0033614 ]\n",
      " [0.00922391 0.9907761 ]\n",
      " [0.00935355 0.9906465 ]\n",
      " [0.9960522  0.00394781]\n",
      " [0.99476904 0.00523095]\n",
      " [0.99565166 0.00434835]\n",
      " [0.99581546 0.0041846 ]\n",
      " [0.99330753 0.00669249]\n",
      " [0.99701107 0.00298897]\n",
      " [0.9950218  0.00497815]\n",
      " [0.01056212 0.98943794]\n",
      " [0.9963953  0.00360469]\n",
      " [0.9967296  0.00327044]\n",
      " [0.9954934  0.00450651]\n",
      " [0.99470925 0.0052907 ]\n",
      " [0.00957622 0.99042374]\n",
      " [0.99467283 0.00532722]\n",
      " [0.01018425 0.9898157 ]] [0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1] tensor(10)\n",
      "tensor(5.9613, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.9875091  0.01249095]\n",
      " [0.00423724 0.99576277]\n",
      " [0.9847525  0.01524749]\n",
      " [0.99035317 0.0096469 ]\n",
      " [0.980157   0.01984297]\n",
      " [0.97704506 0.02295494]\n",
      " [0.9719657  0.02803434]\n",
      " [0.9660514  0.03394859]\n",
      " [0.9795537  0.02044632]\n",
      " [0.97136116 0.02863879]\n",
      " [0.9805823  0.01941765]\n",
      " [0.964876   0.03512402]\n",
      " [0.00426488 0.99573505]\n",
      " [0.96004015 0.03995981]\n",
      " [0.00440036 0.9955996 ]\n",
      " [0.99127555 0.00872445]\n",
      " [0.9802012  0.01979884]\n",
      " [0.00430576 0.99569416]\n",
      " [0.9623164  0.03768363]\n",
      " [0.9800883  0.01991177]] [0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0] tensor(10)\n",
      "tensor(6.3763, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.9337062  0.06629383]\n",
      " [0.90356296 0.09643704]\n",
      " [0.9430533  0.05694677]\n",
      " [0.88451856 0.11548135]\n",
      " [0.9310798  0.06892018]\n",
      " [0.94334984 0.05665014]\n",
      " [0.9459129  0.05408712]\n",
      " [0.9529231  0.04707686]\n",
      " [0.9138639  0.08613615]\n",
      " [0.93250835 0.06749166]\n",
      " [0.00282266 0.99717736]\n",
      " [0.8734587  0.12654129]\n",
      " [0.00283283 0.99716717]\n",
      " [0.85126823 0.14873175]\n",
      " [0.9104149  0.0895851 ]\n",
      " [0.9516921  0.04830787]\n",
      " [0.00295254 0.9970475 ]\n",
      " [0.9180612  0.08193883]\n",
      " [0.9520305  0.04796953]\n",
      " [0.94591194 0.05408811]] [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0] tensor(10)\n",
      "tensor(7.7436, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.9209755  0.07902446]\n",
      " [0.9307013  0.06929867]\n",
      " [0.00267268 0.9973273 ]\n",
      " [0.92708886 0.07291117]\n",
      " [0.9311327  0.06886726]\n",
      " [0.8310184  0.1689816 ]\n",
      " [0.8835292  0.11647075]\n",
      " [0.7776516  0.22234842]\n",
      " [0.8928806  0.10711936]\n",
      " [0.8114353  0.18856479]\n",
      " [0.85654724 0.14345276]\n",
      " [0.00232314 0.9976769 ]\n",
      " [0.95549786 0.0445021 ]\n",
      " [0.94627917 0.05372078]\n",
      " [0.00247829 0.9975217 ]\n",
      " [0.00238092 0.9976191 ]\n",
      " [0.89159167 0.10840838]\n",
      " [0.9263217  0.07367834]\n",
      " [0.9464432  0.05355687]\n",
      " [0.92468077 0.07531925]] [0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0] tensor(10)\n",
      "tensor(8.1662, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.95361656 0.04638341]\n",
      " [0.00252535 0.9974746 ]\n",
      " [0.96699667 0.03300333]\n",
      " [0.9663145  0.03368553]\n",
      " [0.9709565  0.02904352]\n",
      " [0.9774284  0.02257167]\n",
      " [0.9650235  0.03497641]\n",
      " [0.9411309  0.05886911]\n",
      " [0.9681541  0.03184591]\n",
      " [0.9677962  0.03220382]\n",
      " [0.97892076 0.02107927]\n",
      " [0.9745837  0.02541633]\n",
      " [0.9522892  0.04771082]\n",
      " [0.98028904 0.01971089]\n",
      " [0.00245798 0.997542  ]\n",
      " [0.968556   0.03144402]\n",
      " [0.977377   0.02262292]\n",
      " [0.97781676 0.02218324]\n",
      " [0.97300345 0.02699661]\n",
      " [0.00260464 0.9973954 ]] [0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1] tensor(10)\n",
      "tensor(6.8769, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.98452663 0.01547335]\n",
      " [0.973987   0.02601306]\n",
      " [0.00320167 0.99679834]\n",
      " [0.00366664 0.99633336]\n",
      " [0.994175   0.00582499]\n",
      " [0.99409455 0.00590544]\n",
      " [0.00319885 0.99680114]\n",
      " [0.00352656 0.9964734 ]\n",
      " [0.9883824  0.01161755]\n",
      " [0.9896309  0.01036916]\n",
      " [0.9944218  0.00557821]\n",
      " [0.992113   0.007887  ]\n",
      " [0.9860751  0.01392486]\n",
      " [0.99461824 0.00538182]\n",
      " [0.00346049 0.9965395 ]\n",
      " [0.98388    0.01612001]\n",
      " [0.99226177 0.00773818]\n",
      " [0.9729163  0.02708366]\n",
      " [0.00336599 0.99663407]\n",
      " [0.9924771  0.00752288]] [0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0] tensor(10)\n",
      "tensor(6.0516, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.0054269  0.99457306]\n",
      " [0.99741095 0.00258907]\n",
      " [0.9953472  0.0046528 ]\n",
      " [0.00639262 0.9936074 ]\n",
      " [0.9972596  0.00274041]\n",
      " [0.99702495 0.00297507]\n",
      " [0.9970765  0.00292347]\n",
      " [0.99576306 0.00423688]\n",
      " [0.00503373 0.9949662 ]\n",
      " [0.9967908  0.00320917]\n",
      " [0.99708956 0.00291042]\n",
      " [0.9972996  0.00270046]\n",
      " [0.9938034  0.0061966 ]\n",
      " [0.00587084 0.9941292 ]\n",
      " [0.00548385 0.9945161 ]\n",
      " [0.99730694 0.00269304]\n",
      " [0.9978144  0.00218561]\n",
      " [0.99598217 0.00401783]\n",
      " [0.9965339  0.00346614]\n",
      " [0.9972543  0.0027457 ]] [1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0] tensor(10)\n",
      "tensor(5.8970, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[9.98881996e-01 1.11798267e-03]\n",
      " [9.98774111e-01 1.22585811e-03]\n",
      " [9.98788893e-01 1.21113227e-03]\n",
      " [9.98873532e-01 1.12640206e-03]\n",
      " [1.37769524e-02 9.86223042e-01]\n",
      " [9.98920083e-01 1.07996596e-03]\n",
      " [9.98484552e-01 1.51552376e-03]\n",
      " [9.98963952e-01 1.03604374e-03]\n",
      " [9.99005377e-01 9.94611066e-04]\n",
      " [1.64957009e-02 9.83504295e-01]\n",
      " [9.98953342e-01 1.04668387e-03]\n",
      " [1.41037581e-02 9.85896289e-01]\n",
      " [9.98883903e-01 1.11609511e-03]\n",
      " [9.98952150e-01 1.04786409e-03]\n",
      " [9.98667598e-01 1.33244961e-03]\n",
      " [9.98938739e-01 1.06126245e-03]\n",
      " [9.98610377e-01 1.38953701e-03]\n",
      " [1.28126955e-02 9.87187266e-01]\n",
      " [1.37283038e-02 9.86271739e-01]\n",
      " [9.98735368e-01 1.26469904e-03]] [0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0] tensor(10)\n",
      "tensor(5.9419, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[3.4906760e-01 6.5093237e-01]\n",
      " [9.9946624e-01 5.3376483e-04]\n",
      " [9.9950302e-01 4.9702940e-04]\n",
      " [9.9948788e-01 5.1204773e-04]\n",
      " [2.2680674e-01 7.7319324e-01]\n",
      " [9.9944562e-01 5.5442762e-04]\n",
      " [9.9956292e-01 4.3702932e-04]\n",
      " [9.9943703e-01 5.6291965e-04]\n",
      " [2.3621656e-01 7.6378345e-01]\n",
      " [9.9952638e-01 4.7357637e-04]\n",
      " [9.9956542e-01 4.3450951e-04]\n",
      " [9.9943072e-01 5.6925259e-04]\n",
      " [9.9954152e-01 4.5846976e-04]\n",
      " [9.9952650e-01 4.7351525e-04]\n",
      " [2.0663857e-01 7.9336143e-01]\n",
      " [9.9935251e-01 6.4742356e-04]\n",
      " [2.5173235e-01 7.4826765e-01]\n",
      " [9.9953103e-01 4.6897875e-04]\n",
      " [9.9953544e-01 4.6456896e-04]\n",
      " [9.9951124e-01 4.8872468e-04]] [1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0] tensor(10)\n",
      "tensor(9.1457, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[9.9961567e-01 3.8428546e-04]\n",
      " [9.9971372e-01 2.8620992e-04]\n",
      " [9.9964166e-01 3.5837770e-04]\n",
      " [9.9970633e-01 2.9361821e-04]\n",
      " [9.9969172e-01 3.0826076e-04]\n",
      " [9.9969494e-01 3.0510363e-04]\n",
      " [9.9965978e-01 3.4023498e-04]\n",
      " [9.9970335e-01 2.9667353e-04]\n",
      " [9.9962676e-01 3.7316751e-04]\n",
      " [7.9642403e-01 2.0357594e-01]\n",
      " [9.9966085e-01 3.3910226e-04]\n",
      " [6.0294104e-01 3.9705899e-01]\n",
      " [9.9966764e-01 3.3240934e-04]\n",
      " [9.9966705e-01 3.3299738e-04]\n",
      " [9.9967802e-01 3.2201686e-04]\n",
      " [9.9966609e-01 3.3391325e-04]\n",
      " [9.9961805e-01 3.8195806e-04]\n",
      " [9.9970371e-01 2.9631794e-04]\n",
      " [9.9966335e-01 3.3661790e-04]\n",
      " [9.9969280e-01 3.0718671e-04]] [0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0] tensor(10)\n",
      "tensor(26.4902, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[8.89237881e-01 1.10762045e-01]\n",
      " [9.99687910e-01 3.12132179e-04]\n",
      " [9.99692202e-01 3.07829934e-04]\n",
      " [9.99703348e-01 2.96573678e-04]\n",
      " [9.99680281e-01 3.19778977e-04]\n",
      " [8.07364404e-01 1.92635596e-01]\n",
      " [9.99583662e-01 4.16331342e-04]\n",
      " [9.99705255e-01 2.94724363e-04]\n",
      " [9.99691248e-01 3.08799645e-04]\n",
      " [9.99653578e-01 3.46448767e-04]\n",
      " [9.99728024e-01 2.71958270e-04]\n",
      " [9.99694467e-01 3.05602036e-04]\n",
      " [9.99689341e-01 3.10717733e-04]\n",
      " [9.99732435e-01 2.67497846e-04]\n",
      " [8.75689328e-01 1.24310657e-01]\n",
      " [9.99712765e-01 2.87254195e-04]\n",
      " [7.50840545e-01 2.49159485e-01]\n",
      " [9.99729335e-01 2.70653021e-04]\n",
      " [7.71810651e-01 2.28189349e-01]\n",
      " [9.13568914e-01 8.64311010e-02]] [1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 1] tensor(10)\n",
      "tensor(36.3069, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "batch_size = 256\n",
    "for epoch in range(500):\n",
    "\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    agg_loss = 0\n",
    "    inst_idxs = list(range(len(ys)))\n",
    "    random.shuffle(inst_idxs)\n",
    "\n",
    "    counter = 0\n",
    "    for i in inst_idxs:\n",
    "        counter += 1\n",
    "\n",
    "        t_mask = train_sets[i]\n",
    "        s_mask = get_solution_mask(t_mask, 0.5)\n",
    "        nf, mask = get_mask_node_feature(node_features[i], ys[i], s_mask)\n",
    "\n",
    "        output, _ = model(nf, c_v_edges[i], v_c_edges[i], edge_features[i].detach())\n",
    "        fl = FocalLoss()\n",
    "\n",
    "        train_mask = torch.cat(\n",
    "            [~t_mask, torch.zeros(len(mask) - len(t_mask), dtype=torch.bool)]\n",
    "        )\n",
    "        loss = fl(output[train_mask, :], ys[i][train_mask])\n",
    "        agg_loss += loss\n",
    "\n",
    "        if counter >= batch_size:\n",
    "            (agg_loss / batch_size).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "            optimizer.step()\n",
    "            print(\n",
    "                output[train_mask, :].detach().numpy(),\n",
    "                ys[i][train_mask].detach().numpy(),\n",
    "                mask.sum(),\n",
    "            )\n",
    "            print(agg_loss)\n",
    "            print(\"-\" * 100)\n",
    "            agg_loss = 0\n",
    "            counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys[i].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = Inst(\n",
    "    [VarFeature.from_info(info.var_info, info.obj_info)],\n",
    "    [ConFeature.from_info(info.con_info)],\n",
    "    [EdgFeature.from_info(info.con_info)],\n",
    "    [[v.x for v in m.getVars()]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for epoch in range(10):\n",
    "\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    agg_loss = 0\n",
    "    for i in range(5):\n",
    "        inst_idx = random.randint(0, len(ys) - 1)\n",
    "        train_idx = torch.as_tensor(range(2), dtype=torch.int32)\n",
    "\n",
    "        output, edge_features[inst_idx] = model(\n",
    "            node_features[inst_idx],\n",
    "            c_v_edges[inst_idx],\n",
    "            v_c_edges[inst_idx],\n",
    "            edge_features[inst_idx].detach(),\n",
    "        )\n",
    "        fl = FocalLoss()\n",
    "        loss = fl(output[train_idx], ys[inst_idx][train_idx])\n",
    "        agg_loss += loss\n",
    "\n",
    "    print(output[train_idx].detach().numpy(), ys[inst_idx][train_idx].detach().numpy())\n",
    "    print(agg_loss)\n",
    "\n",
    "    agg_loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, num):\n",
    "    global data_edge_features\n",
    "    t = time.time()\n",
    "\n",
    "    output, data_edge_features[num] = model(\n",
    "        data_features[num],\n",
    "        data_edge_A[num],\n",
    "        data_edge_B[num],\n",
    "        data_edge_features[num].detach(),\n",
    "    )\n",
    "    print(data_solution[num][idx_train])\n",
    "\n",
    "    lf = Focal_Loss(torch.as_tensor(data_labels[num]))\n",
    "    loss_train = lf(output[idx_train], data_solution[num][idx_train])\n",
    "\n",
    "    return loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_total = time.time()\n",
    "loss_values = []\n",
    "for epoch in range(args.epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    now_loss = 0\n",
    "\n",
    "    for i in range(5):\n",
    "        now_data = random.randint(0, data_num - 1)\n",
    "        now_loss += train(epoch, now_data)\n",
    "\n",
    "    loss_values.append(now_loss)\n",
    "    now_loss.backward()\n",
    "    optimizer.step()\n",
    "    print(\"Epoch: {:04d}\".format(epoch + 1), \"loss_train: {:.4f}\".format(now_loss))\n",
    "\n",
    "    torch.save(model.state_dict(), \"{}.pkl\".format(epoch))\n",
    "    if loss_values[-1] < best:\n",
    "        best = loss_values[-1]\n",
    "        best_epoch = epoch\n",
    "        bad_counter = 0\n",
    "    else:\n",
    "        bad_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and optimizer\n",
    "model = SpGAT(\n",
    "    nfeat=data_features[0].shape[1],  # Feature dimension\n",
    "    nhid=args.hidden,  # Feature dimension of each hidden layer\n",
    "    nclass=int(data_solution[0].max()) + 1,  # Number of classes\n",
    "    dropout=args.dropout,  # Dropout\n",
    "    nheads=args.nb_heads,  # Number of heads\n",
    "    alpha=args.alpha,\n",
    ")  # LeakyReLU alpha coefficient\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), lr=args.lr, weight_decay=args.weight_decay  # Learning rate\n",
    ")  # Weight decay to prevent overfitting\n",
    "\n",
    "if args.cuda:  # Move to GPU\n",
    "    model.to(device)\n",
    "    for now_data in range(data_num):\n",
    "        data_features[now_data] = data_features[now_data].to(device)\n",
    "        data_labels[now_data] = data_labels[now_data].to(device)\n",
    "        data_solution[now_data] = data_solution[now_data].to(device)\n",
    "        data_edge_A[now_data] = data_edge_A[now_data].to(device)\n",
    "        data_edge_B[now_data] = data_edge_B[now_data].to(device)\n",
    "        data_edge_features[now_data] = data_edge_features[now_data].to(device)\n",
    "        data_idx_train[now_data] = data_idx_train[now_data].to(device)\n",
    "\n",
    "\n",
    "for now_data in range(data_num):\n",
    "    data_features[now_data] = Variable(data_features[now_data])\n",
    "    data_edge_A[now_data] = Variable(data_edge_A[now_data])\n",
    "    data_edge_B[now_data] = Variable(data_edge_B[now_data])\n",
    "    data_solution[now_data] = Variable(data_solution[now_data])\n",
    "    # Define computation graph for automatic differentiation\n",
    "\n",
    "\n",
    "def train(epoch, num):\n",
    "    global data_edge_features\n",
    "    t = time.time()\n",
    "\n",
    "    output, data_edge_features[num] = model(\n",
    "        data_features[num],\n",
    "        data_edge_A[num],\n",
    "        data_edge_B[num],\n",
    "        data_edge_features[num].detach(),\n",
    "    )\n",
    "    print(data_solution[num][idx_train])\n",
    "\n",
    "    lf = Focal_Loss(torch.as_tensor(data_labels[num]))\n",
    "    loss_train = lf(output[idx_train], data_solution[num][idx_train])\n",
    "\n",
    "    return loss_train\n",
    "\n",
    "\n",
    "t_total = time.time()\n",
    "loss_values = []\n",
    "bad_counter = 0\n",
    "best = args.epochs + 1\n",
    "best_epoch = 0\n",
    "for epoch in range(args.epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    now_loss = 0\n",
    "    for i in range(5):\n",
    "        now_data = random.randint(0, data_num - 1)\n",
    "        now_loss += train(epoch, now_data)\n",
    "    loss_values.append(now_loss)\n",
    "    now_loss.backward()\n",
    "    optimizer.step()\n",
    "    print(\"Epoch: {:04d}\".format(epoch + 1), \"loss_train: {:.4f}\".format(now_loss))\n",
    "\n",
    "    torch.save(model.state_dict(), \"{}.pkl\".format(epoch))\n",
    "    if loss_values[-1] < best:\n",
    "        best = loss_values[-1]\n",
    "        best_epoch = epoch\n",
    "        bad_counter = 0\n",
    "    else:\n",
    "        bad_counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
