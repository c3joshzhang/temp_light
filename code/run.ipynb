{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gurobipy as gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learn.info import ModelInfo\n",
    "from learn.feature import VarFeature, ConFeature, EdgFeature\n",
    "from learn.train import Inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "def maximum_independent_set_problem(\n",
    "    num_nodes=64,\n",
    "    edge_prob=0.3,\n",
    "    print_output=True\n",
    "):\n",
    "    edges = []\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(i+1, num_nodes):\n",
    "            if np.random.rand() < edge_prob:\n",
    "                edges.append((i, j))\n",
    "    m = gp.Model(\"maximum_independent_set\")\n",
    "    x = m.addVars(num_nodes, vtype=GRB.BINARY, name=\"x\")\n",
    "    for (i, j) in edges:\n",
    "        m.addConstr(x[i] + x[j] <= 1, name=f\"edge_{i}_{j}\")\n",
    "    m.setObjective(gp.quicksum(x[i] for i in range(num_nodes)), GRB.MAXIMIZE)\n",
    "    m.update()\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "var_features = []\n",
    "con_features = []\n",
    "edg_features = []\n",
    "solutions = []\n",
    "\n",
    "for i in range(2048):\n",
    "    m = maximum_independent_set_problem()\n",
    "    info = ModelInfo.from_model(m)\n",
    "    var_features.append(VarFeature.from_info(info.var_info, info.obj_info))\n",
    "    con_features.append(ConFeature.from_info(info.con_info))\n",
    "    edg_features.append(EdgFeature.from_info(info.con_info))\n",
    "    m.optimize()\n",
    "    s = [v.x for v in m.getVars()]\n",
    "    solutions.append(s)\n",
    "\n",
    "inst = Inst(var_features, con_features, edg_features, solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_v_edges, v_c_edges, node_features, edge_features, n_var, n_con = inst.xs\n",
    "ys = inst.ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_mask(size, ratio):\n",
    "    num_zero = int(round(size * ratio))\n",
    "    mask = torch.ones(size, dtype=torch.bool)\n",
    "    idx = torch.randperm(size)[:num_zero]\n",
    "    mask[idx] = 0\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_solution_mask(pool, ratio):\n",
    "    mask = pool.clone()\n",
    "    ones_indices = torch.where(mask == 1)[0]\n",
    "    num_keep = int(round(len(ones_indices) * ratio))\n",
    "    \n",
    "    if num_keep <= 0:\n",
    "        mask[ones_indices] = 0\n",
    "        return mask\n",
    "        \n",
    "    if num_keep >= len(ones_indices):\n",
    "        return mask\n",
    "\n",
    "    selected_indices = torch.randperm(len(ones_indices))[:num_keep]\n",
    "    keep_indices = ones_indices[selected_indices]\n",
    "    mask[ones_indices] = 0\n",
    "    mask[keep_indices] = 1\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_mask_node_feature(node_feature, y, mask):\n",
    "    node_feature_with_y = torch.hstack([node_feature, y.unsqueeze(1)])\n",
    "    mask = torch.cat([mask, torch.zeros(len(y) - len(mask), dtype=torch.bool)])\n",
    "    masked = node_feature_with_y.clone()\n",
    "    masked[mask, -1] = 0\n",
    "    return torch.hstack([masked, mask.unsqueeze(1)]), mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(problem, max_level):\n",
    "    sub_problems = partition(problem)\n",
    "    if max_level == 0:\n",
    "        partial_solution = solve_exact(sub_problems[0])\n",
    "        approx_solution = infer(partial_solution, problem)\n",
    "        fixed = gb_fix(approx_solution)\n",
    "        return fixed\n",
    "    sols = solve(sub_problems, max_level-1)\n",
    "    combined = combine(sols) # crossover\n",
    "    fixed = gb_fix(combined)\n",
    "    return fixed\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from learn.model import FocalLoss, SpGAT\n",
    "import torch.optim as optim\n",
    "\n",
    "model = SpGAT(\n",
    "    nfeat=inst.xs[2][0].shape[1] + 2,\n",
    "    nhid=64,\n",
    "    nclass=2,\n",
    "    dropout=0.1,\n",
    "    nheads=6,\n",
    "    alpha=0.2\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "ce = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.5\n",
    "train_sets = []\n",
    "for i in range(len(ys)):\n",
    "    n = n_var[i]\n",
    "    s = get_train_mask(n, train_ratio)\n",
    "    train_sets.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.54240626 0.45759374]\n",
      " [0.53063524 0.46936476]\n",
      " [0.53687495 0.46312502]\n",
      " [0.5366877  0.46331233]\n",
      " [0.54531837 0.4546817 ]\n",
      " [0.5369345  0.4630655 ]\n",
      " [0.523825   0.47617504]\n",
      " [0.53083795 0.46916202]\n",
      " [0.5364077  0.4635923 ]\n",
      " [0.53413343 0.46586654]\n",
      " [0.5336314  0.46636862]\n",
      " [0.5461938  0.45380622]\n",
      " [0.53969324 0.46030676]\n",
      " [0.53477573 0.46522427]\n",
      " [0.54295903 0.45704097]\n",
      " [0.54177976 0.4582202 ]\n",
      " [0.5365297  0.46347022]\n",
      " [0.53098625 0.46901372]\n",
      " [0.5386334  0.46136662]\n",
      " [0.5350969  0.4649031 ]\n",
      " [0.5301887  0.46981132]\n",
      " [0.5372725  0.46272746]\n",
      " [0.5411987  0.45880124]\n",
      " [0.5348985  0.46510148]\n",
      " [0.54060894 0.45939106]\n",
      " [0.541353   0.45864704]\n",
      " [0.54069686 0.4593031 ]\n",
      " [0.54346263 0.4565374 ]\n",
      " [0.5407713  0.45922866]\n",
      " [0.53801525 0.46198478]\n",
      " [0.54070103 0.45929897]\n",
      " [0.5359832  0.46401677]] [0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0] tensor(16)\n",
      "tensor(40.6731, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.7777239  0.22227603]\n",
      " [0.7579052  0.2420948 ]\n",
      " [0.7690788  0.2309212 ]\n",
      " [0.7789201  0.22107993]\n",
      " [0.76530695 0.23469307]\n",
      " [0.7696946  0.23030536]\n",
      " [0.7727898  0.22721025]\n",
      " [0.7667857  0.23321424]\n",
      " [0.7673312  0.23266883]\n",
      " [0.7723014  0.22769858]\n",
      " [0.7622695  0.23773052]\n",
      " [0.7661335  0.23386647]\n",
      " [0.7685145  0.23148544]\n",
      " [0.77886844 0.22113153]\n",
      " [0.773132   0.22686794]\n",
      " [0.76657003 0.23342992]\n",
      " [0.7657664  0.23423359]\n",
      " [0.78048885 0.21951114]\n",
      " [0.76122034 0.23877963]\n",
      " [0.7761423  0.2238577 ]\n",
      " [0.76043093 0.23956905]\n",
      " [0.76886034 0.23113957]\n",
      " [0.77603745 0.22396252]\n",
      " [0.7662023  0.2337977 ]\n",
      " [0.7628313  0.23716877]\n",
      " [0.76012665 0.23987335]\n",
      " [0.75524575 0.24475423]\n",
      " [0.7798695  0.22013047]\n",
      " [0.74983126 0.2501688 ]\n",
      " [0.7719493  0.22805065]\n",
      " [0.7592565  0.24074352]\n",
      " [0.76048094 0.23951913]] [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0] tensor(16)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[[0.75725377 0.24274626]\n",
      " [0.7674646  0.2325354 ]\n",
      " [0.7695927  0.23040727]\n",
      " [0.75944036 0.24055961]\n",
      " [0.77405614 0.22594388]\n",
      " [0.763863   0.23613699]\n",
      " [0.7660278  0.23397224]\n",
      " [0.77868676 0.22131321]\n",
      " [0.7573288  0.24267118]\n",
      " [0.76580495 0.2341951 ]\n",
      " [0.7753936  0.22460645]\n",
      " [0.7808905  0.21910946]\n",
      " [0.77610624 0.22389373]\n",
      " [0.7663847  0.23361523]\n",
      " [0.7718595  0.22814041]\n",
      " [0.7664359  0.23356408]\n",
      " [0.744381   0.255619  ]\n",
      " [0.7795524  0.22044766]\n",
      " [0.7579862  0.24201386]\n",
      " [0.7531127  0.24688733]\n",
      " [0.77632695 0.22367306]\n",
      " [0.7789842  0.22101587]\n",
      " [0.7715601  0.22843996]\n",
      " [0.77124405 0.22875594]\n",
      " [0.74899143 0.25100863]\n",
      " [0.76684564 0.23315439]\n",
      " [0.7818816  0.2181184 ]\n",
      " [0.7707063  0.22929367]\n",
      " [0.77640754 0.22359255]\n",
      " [0.7775636  0.22243644]\n",
      " [0.7633715  0.23662846]\n",
      " [0.76033974 0.23966022]] [0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0] tensor(16)\n",
      "tensor(31.8952, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.85356385 0.14643615]\n",
      " [0.8005001  0.1994999 ]\n",
      " [0.84819967 0.1518003 ]\n",
      " [0.8562069  0.1437932 ]\n",
      " [0.84572846 0.1542715 ]\n",
      " [0.85100454 0.14899547]\n",
      " [0.8523985  0.14760152]\n",
      " [0.8462263  0.15377373]\n",
      " [0.8458601  0.15413985]\n",
      " [0.8526909  0.14730914]\n",
      " [0.83765966 0.16234028]\n",
      " [0.84869856 0.1513014 ]\n",
      " [0.8490134  0.15098661]\n",
      " [0.85831857 0.14168149]\n",
      " [0.8509048  0.14909513]\n",
      " [0.8485345  0.15146552]\n",
      " [0.84591144 0.15408847]\n",
      " [0.8563186  0.14368139]\n",
      " [0.83715403 0.16284601]\n",
      " [0.854902   0.14509805]\n",
      " [0.8354181  0.16458187]\n",
      " [0.8485612  0.15143879]\n",
      " [0.8578601  0.1421399 ]\n",
      " [0.84747726 0.15252268]\n",
      " [0.80550456 0.19449545]\n",
      " [0.83556277 0.16443723]\n",
      " [0.7973198  0.2026802 ]\n",
      " [0.85484034 0.14515968]\n",
      " [0.78971666 0.21028335]\n",
      " [0.85312086 0.14687908]\n",
      " [0.80330706 0.19669288]\n",
      " [0.83577394 0.16422607]] [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0] tensor(16)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[[0.835707   0.16429304]\n",
      " [0.83693117 0.16306883]\n",
      " [0.7925369  0.20746306]\n",
      " [0.8447186  0.1552814 ]\n",
      " [0.8434245  0.15657555]\n",
      " [0.85365254 0.14634743]\n",
      " [0.8572798  0.14272024]\n",
      " [0.8411316  0.15886837]\n",
      " [0.8545483  0.14545171]\n",
      " [0.7899037  0.21009637]\n",
      " [0.85377437 0.14622568]\n",
      " [0.85171884 0.14828108]\n",
      " [0.7930065  0.2069935 ]\n",
      " [0.8471801  0.15281995]\n",
      " [0.8514063  0.14859378]\n",
      " [0.8505435  0.14945647]\n",
      " [0.8514455  0.14855447]\n",
      " [0.85862184 0.14137815]\n",
      " [0.85390013 0.14609988]\n",
      " [0.83486706 0.16513294]\n",
      " [0.8572447  0.14275534]\n",
      " [0.849864   0.150136  ]\n",
      " [0.80203813 0.1979619 ]\n",
      " [0.851871   0.14812902]\n",
      " [0.80156875 0.19843127]\n",
      " [0.8466333  0.15336664]\n",
      " [0.79326206 0.20673797]\n",
      " [0.85811275 0.14188732]\n",
      " [0.8516663  0.14833367]\n",
      " [0.8393248  0.16067517]\n",
      " [0.8461058  0.15389411]\n",
      " [0.8547343  0.1452657 ]] [0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0] tensor(16)\n",
      "tensor(30.8950, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.80668724 0.19331278]\n",
      " [0.7228752  0.27712476]\n",
      " [0.8006371  0.19936289]\n",
      " [0.81297886 0.18702109]\n",
      " [0.8018726  0.19812743]\n",
      " [0.81006324 0.18993682]\n",
      " [0.8104052  0.18959484]\n",
      " [0.8040214  0.19597858]\n",
      " [0.8005236  0.19947648]\n",
      " [0.80872816 0.19127189]\n",
      " [0.80045253 0.19954744]\n",
      " [0.8094904  0.19050963]\n",
      " [0.805743   0.19425704]\n",
      " [0.8161201  0.18387991]\n",
      " [0.8067306  0.19326937]\n",
      " [0.80762416 0.19237582]\n",
      " [0.807824   0.19217597]\n",
      " [0.81689864 0.18310136]\n",
      " [0.8043152  0.1956848 ]\n",
      " [0.81150466 0.18849535]\n",
      " [0.79344934 0.20655073]\n",
      " [0.8042826  0.19571735]\n",
      " [0.8158156  0.18418436]\n",
      " [0.8031957  0.19680427]\n",
      " [0.7298434  0.27015668]\n",
      " [0.80814344 0.19185662]\n",
      " [0.71810573 0.28189433]\n",
      " [0.81509167 0.18490832]\n",
      " [0.711264   0.28873593]\n",
      " [0.8094519  0.19054815]\n",
      " [0.72768795 0.27231196]\n",
      " [0.79943687 0.20056306]] [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0] tensor(16)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[[0.7954795  0.20452055]\n",
      " [0.8086649  0.19133505]\n",
      " [0.8096063  0.19039363]\n",
      " [0.8069156  0.19308439]\n",
      " [0.7970957  0.20290427]\n",
      " [0.72076625 0.27923372]\n",
      " [0.70908034 0.2909197 ]\n",
      " [0.8025346  0.19746545]\n",
      " [0.79559076 0.20440923]\n",
      " [0.8105301  0.18946989]\n",
      " [0.8019665  0.1980335 ]\n",
      " [0.7344652  0.26553485]\n",
      " [0.7976417  0.2023583 ]\n",
      " [0.72632235 0.27367762]\n",
      " [0.80809736 0.19190264]\n",
      " [0.7949176  0.20508245]\n",
      " [0.79861325 0.2013868 ]\n",
      " [0.8111067  0.18889332]\n",
      " [0.80744475 0.1925553 ]\n",
      " [0.8070601  0.1929399 ]\n",
      " [0.715081   0.28491905]\n",
      " [0.80697435 0.1930257 ]\n",
      " [0.8077898  0.1922102 ]\n",
      " [0.7979603  0.20203966]\n",
      " [0.811922   0.18807796]\n",
      " [0.79842407 0.20157595]\n",
      " [0.8042062  0.19579378]\n",
      " [0.78827286 0.21172714]\n",
      " [0.81587833 0.18412168]\n",
      " [0.8007168  0.19928318]\n",
      " [0.7980557  0.2019443 ]\n",
      " [0.71336794 0.28663203]] [0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1] tensor(16)\n",
      "tensor(28.6565, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.69764745 0.3023525 ]\n",
      " [0.5789788  0.42102128]\n",
      " [0.6971739  0.3028261 ]\n",
      " [0.71706283 0.28293717]\n",
      " [0.7095052  0.2904947 ]\n",
      " [0.71314704 0.286853  ]\n",
      " [0.71291447 0.28708556]\n",
      " [0.7053835  0.29461646]\n",
      " [0.70344454 0.29655543]\n",
      " [0.71475816 0.28524187]\n",
      " [0.7021192  0.2978808 ]\n",
      " [0.7111991  0.2888008 ]\n",
      " [0.7091153  0.29088467]\n",
      " [0.71210575 0.28789422]\n",
      " [0.70966595 0.29033408]\n",
      " [0.70998275 0.2900173 ]\n",
      " [0.7116799  0.2883201 ]\n",
      " [0.718028   0.281972  ]\n",
      " [0.7105845  0.28941545]\n",
      " [0.70921874 0.29078123]\n",
      " [0.69464934 0.30535072]\n",
      " [0.7045116  0.29548848]\n",
      " [0.7199756  0.28002438]\n",
      " [0.7082635  0.29173642]\n",
      " [0.58813035 0.41186967]\n",
      " [0.71457785 0.2854222 ]\n",
      " [0.57681054 0.42318943]\n",
      " [0.7188481  0.28115195]\n",
      " [0.5702459  0.42975408]\n",
      " [0.71583986 0.28416014]\n",
      " [0.584161   0.41583908]\n",
      " [0.7022616  0.2977383 ]] [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0] tensor(16)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[[0.585574   0.4144261 ]\n",
      " [0.7127997  0.2872002 ]\n",
      " [0.7113544  0.2886456 ]\n",
      " [0.6966162  0.30338383]\n",
      " [0.7031985  0.29680148]\n",
      " [0.5809971  0.41900295]\n",
      " [0.7187983  0.28120175]\n",
      " [0.7119058  0.2880942 ]\n",
      " [0.5737648  0.42623517]\n",
      " [0.57779145 0.42220855]\n",
      " [0.69544274 0.30455726]\n",
      " [0.71405095 0.28594902]\n",
      " [0.6945798  0.30542028]\n",
      " [0.7035345  0.29646555]\n",
      " [0.7004028  0.29959723]\n",
      " [0.71090764 0.28909236]\n",
      " [0.70190483 0.2980951 ]\n",
      " [0.7197693  0.2802307 ]\n",
      " [0.70994204 0.29005796]\n",
      " [0.5774962  0.42250377]\n",
      " [0.5798354  0.42016453]\n",
      " [0.7020212  0.2979789 ]\n",
      " [0.6952543  0.30474564]\n",
      " [0.7131872  0.28681278]\n",
      " [0.6934284  0.3065716 ]\n",
      " [0.7099706  0.29002938]\n",
      " [0.7148828  0.28511715]\n",
      " [0.7096311  0.29036888]\n",
      " [0.5776928  0.4223072 ]\n",
      " [0.59300673 0.40699327]\n",
      " [0.5784118  0.42158815]\n",
      " [0.7173056  0.2826944 ]] [1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0] tensor(16)\n",
      "tensor(27.5197, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.70381385 0.2961862 ]\n",
      " [0.5388179  0.46118212]\n",
      " [0.69768745 0.30231255]\n",
      " [0.7191923  0.28080773]\n",
      " [0.70873374 0.29126626]\n",
      " [0.7110853  0.28891468]\n",
      " [0.70878047 0.2912195 ]\n",
      " [0.70661616 0.29338378]\n",
      " [0.69720924 0.30279082]\n",
      " [0.7096596  0.29034033]\n",
      " [0.69948363 0.30051634]\n",
      " [0.7145002  0.28549987]\n",
      " [0.702389   0.297611  ]\n",
      " [0.71902484 0.28097516]\n",
      " [0.70707077 0.2929292 ]\n",
      " [0.71778476 0.2822152 ]\n",
      " [0.7077508  0.29224917]\n",
      " [0.71191686 0.28808317]\n",
      " [0.71287215 0.28712788]\n",
      " [0.7121111  0.28788882]\n",
      " [0.6919329  0.30806705]\n",
      " [0.7041008  0.29589927]\n",
      " [0.71268207 0.28731793]\n",
      " [0.70955026 0.29044977]\n",
      " [0.5437259  0.45627412]\n",
      " [0.7210312  0.27896878]\n",
      " [0.5376274  0.46237254]\n",
      " [0.7083883  0.2916116 ]\n",
      " [0.53324026 0.4667597 ]\n",
      " [0.71689487 0.2831052 ]\n",
      " [0.54191023 0.45808977]\n",
      " [0.7038765  0.2961235 ]] [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0] tensor(16)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[[0.71106505 0.28893492]\n",
      " [0.7030173  0.29698274]\n",
      " [0.70837516 0.29162484]\n",
      " [0.54041004 0.45958993]\n",
      " [0.7085303  0.2914696 ]\n",
      " [0.69398516 0.3060149 ]\n",
      " [0.5439372  0.45606276]\n",
      " [0.7011785  0.29882154]\n",
      " [0.7074836  0.29251644]\n",
      " [0.70140517 0.2985948 ]\n",
      " [0.5371639  0.46283612]\n",
      " [0.70900214 0.29099783]\n",
      " [0.7090275  0.29097244]\n",
      " [0.7110223  0.28897768]\n",
      " [0.69926393 0.3007361 ]\n",
      " [0.7092955  0.29070446]\n",
      " [0.7077623  0.2922377 ]\n",
      " [0.69832003 0.3016799 ]\n",
      " [0.7162742  0.2837258 ]\n",
      " [0.5359699  0.46403003]\n",
      " [0.7172856  0.28271446]\n",
      " [0.7130891  0.2869109 ]\n",
      " [0.7187128  0.28128722]\n",
      " [0.7056951  0.29430494]\n",
      " [0.5369584  0.46304166]\n",
      " [0.538631   0.46136895]\n",
      " [0.69819    0.30181003]\n",
      " [0.70350504 0.29649493]\n",
      " [0.6865186  0.31348133]\n",
      " [0.53959894 0.46040103]\n",
      " [0.7047114  0.2952886 ]\n",
      " [0.7136808  0.28631917]] [0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0] tensor(16)\n",
      "tensor(26.5572, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.7549556  0.24504443]\n",
      " [0.565879   0.43412098]\n",
      " [0.7683187  0.23168127]\n",
      " [0.7695446  0.23045541]\n",
      " [0.7723305  0.2276694 ]\n",
      " [0.76848334 0.2315167 ]\n",
      " [0.7713868  0.22861321]\n",
      " [0.76248074 0.23751928]\n",
      " [0.75518054 0.24481948]\n",
      " [0.7757721  0.22422796]\n",
      " [0.7614061  0.23859385]\n",
      " [0.7720509  0.22794907]\n",
      " [0.7694508  0.23054925]\n",
      " [0.7766707  0.22332935]\n",
      " [0.76202154 0.23797846]\n",
      " [0.7794275  0.22057249]\n",
      " [0.7766157  0.22338435]\n",
      " [0.7675982  0.23240179]\n",
      " [0.77663565 0.22336428]\n",
      " [0.7724964  0.22750364]\n",
      " [0.75540453 0.24459548]\n",
      " [0.76502407 0.23497598]\n",
      " [0.78109723 0.21890278]\n",
      " [0.77360857 0.22639148]\n",
      " [0.570849   0.42915106]\n",
      " [0.7760982  0.22390181]\n",
      " [0.5612911  0.43870887]\n",
      " [0.77034557 0.22965443]\n",
      " [0.55448866 0.44551134]\n",
      " [0.77525324 0.2247468 ]\n",
      " [0.57073957 0.42926046]\n",
      " [0.7694979  0.2305021 ]] [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0] tensor(16)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[[0.78182757 0.21817239]\n",
      " [0.7747474  0.22525269]\n",
      " [0.76172197 0.23827806]\n",
      " [0.7710841  0.228916  ]\n",
      " [0.5645691  0.4354309 ]\n",
      " [0.78577274 0.2142273 ]\n",
      " [0.77329224 0.22670773]\n",
      " [0.7643565  0.23564346]\n",
      " [0.7717189  0.228281  ]\n",
      " [0.7787623  0.2212377 ]\n",
      " [0.78034025 0.21965976]\n",
      " [0.5657729  0.4342271 ]\n",
      " [0.7704448  0.2295552 ]\n",
      " [0.7753226  0.22467732]\n",
      " [0.77007025 0.22992973]\n",
      " [0.76697344 0.23302655]\n",
      " [0.57281613 0.42718384]\n",
      " [0.7731715  0.22682855]\n",
      " [0.77844477 0.22155528]\n",
      " [0.76904833 0.23095164]\n",
      " [0.7825152  0.21748477]\n",
      " [0.773861   0.22613904]\n",
      " [0.77666473 0.22333534]\n",
      " [0.7735043  0.22649565]\n",
      " [0.7853632  0.21463679]\n",
      " [0.7801516  0.2198484 ]\n",
      " [0.74219406 0.2578059 ]\n",
      " [0.7679407  0.23205933]\n",
      " [0.7659737  0.23402637]\n",
      " [0.76565504 0.23434493]\n",
      " [0.7676674  0.2323326 ]\n",
      " [0.5712759  0.42872408]] [0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1] tensor(16)\n",
      "tensor(23.9024, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.8258308  0.17416917]\n",
      " [0.6292783  0.37072164]\n",
      " [0.84170127 0.15829867]\n",
      " [0.83895814 0.16104184]\n",
      " [0.843642   0.15635803]\n",
      " [0.8513085  0.14869146]\n",
      " [0.8423515  0.15764844]\n",
      " [0.8422576  0.15774232]\n",
      " [0.83154404 0.16845599]\n",
      " [0.84895515 0.1510449 ]\n",
      " [0.84449273 0.15550727]\n",
      " [0.84792787 0.15207212]\n",
      " [0.84344643 0.15655355]\n",
      " [0.8433743  0.15662573]\n",
      " [0.84614784 0.1538522 ]\n",
      " [0.84809417 0.15190588]\n",
      " [0.85500926 0.1449907 ]\n",
      " [0.8437232  0.15627685]\n",
      " [0.84880877 0.15119128]\n",
      " [0.840505   0.15949497]\n",
      " [0.8354236  0.1645764 ]\n",
      " [0.8348378  0.16516218]\n",
      " [0.8507967  0.14920327]\n",
      " [0.84569085 0.15430912]\n",
      " [0.63750297 0.36249703]\n",
      " [0.8552725  0.14472756]\n",
      " [0.62741923 0.37258074]\n",
      " [0.84574544 0.15425456]\n",
      " [0.6143628  0.38563725]\n",
      " [0.85110134 0.1488987 ]\n",
      " [0.6394519  0.36054802]\n",
      " [0.8409429  0.1590571 ]] [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0] tensor(16)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[[0.8406964  0.15930365]\n",
      " [0.6240983  0.37590173]\n",
      " [0.8516829  0.14831711]\n",
      " [0.6460645  0.35393545]\n",
      " [0.85062546 0.14937454]\n",
      " [0.6368232  0.36317682]\n",
      " [0.8493098  0.15069026]\n",
      " [0.84497255 0.1550274 ]\n",
      " [0.8414454  0.1585546 ]\n",
      " [0.84460104 0.15539896]\n",
      " [0.84163237 0.15836763]\n",
      " [0.64186054 0.35813943]\n",
      " [0.6317273  0.36827272]\n",
      " [0.8425744  0.15742552]\n",
      " [0.836075   0.16392498]\n",
      " [0.8484571  0.15154289]\n",
      " [0.6266017  0.37339827]\n",
      " [0.8444298  0.15557022]\n",
      " [0.83703446 0.16296555]\n",
      " [0.8505869  0.14941312]\n",
      " [0.8534614  0.14653857]\n",
      " [0.8427197  0.1572803 ]\n",
      " [0.84239465 0.15760534]\n",
      " [0.83446234 0.16553766]\n",
      " [0.84327656 0.15672344]\n",
      " [0.85073286 0.14926718]\n",
      " [0.84715426 0.15284579]\n",
      " [0.8426207  0.15737937]\n",
      " [0.84857374 0.15142629]\n",
      " [0.8352454  0.16475469]\n",
      " [0.8457625  0.15423752]\n",
      " [0.84671986 0.15328008]] [0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] tensor(16)\n",
      "tensor(22.5745, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.8606677  0.13933226]\n",
      " [0.61266625 0.38733375]\n",
      " [0.86457866 0.13542137]\n",
      " [0.86061317 0.13938682]\n",
      " [0.8668581  0.1331418 ]\n",
      " [0.8705525  0.1294475 ]\n",
      " [0.8629017  0.13709834]\n",
      " [0.8609122  0.13908783]\n",
      " [0.8602722  0.13972777]\n",
      " [0.86728853 0.13271147]\n",
      " [0.8595209  0.14047909]\n",
      " [0.8693679  0.13063215]\n",
      " [0.85937417 0.14062585]\n",
      " [0.8632047  0.13679525]\n",
      " [0.862147   0.13785303]\n",
      " [0.8690946  0.13090537]\n",
      " [0.8732535  0.1267464 ]\n",
      " [0.85855925 0.1414408 ]\n",
      " [0.87525296 0.12474704]\n",
      " [0.86253655 0.13746342]\n",
      " [0.8533696  0.14663033]\n",
      " [0.8596676  0.14033243]\n",
      " [0.8677475  0.13225245]\n",
      " [0.8633134  0.13668665]\n",
      " [0.61630946 0.38369048]\n",
      " [0.87253326 0.12746674]\n",
      " [0.6050378  0.39496216]\n",
      " [0.85487515 0.1451248 ]\n",
      " [0.59444994 0.40555006]\n",
      " [0.87376547 0.12623459]\n",
      " [0.6163809  0.38361916]\n",
      " [0.86429304 0.13570696]] [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0] tensor(16)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[[0.8699752  0.13002476]\n",
      " [0.6160071  0.38399294]\n",
      " [0.8625792  0.1374208 ]\n",
      " [0.8473939  0.15260608]\n",
      " [0.86617464 0.1338253 ]\n",
      " [0.86075723 0.13924272]\n",
      " [0.86871225 0.1312877 ]\n",
      " [0.8696657  0.13033433]\n",
      " [0.8570457  0.14295435]\n",
      " [0.86252874 0.13747124]\n",
      " [0.6040964  0.39590356]\n",
      " [0.8597419  0.14025803]\n",
      " [0.6211724  0.3788276 ]\n",
      " [0.86208475 0.13791524]\n",
      " [0.8692009  0.13079914]\n",
      " [0.856099   0.1439009 ]\n",
      " [0.8569682  0.14303179]\n",
      " [0.85808426 0.14191574]\n",
      " [0.6046615  0.39533854]\n",
      " [0.60810363 0.39189637]\n",
      " [0.8664121  0.13358788]\n",
      " [0.86309093 0.13690901]\n",
      " [0.8665682  0.13343185]\n",
      " [0.8715955  0.12840453]\n",
      " [0.8643568  0.13564318]\n",
      " [0.852371   0.147629  ]\n",
      " [0.86175877 0.13824123]\n",
      " [0.856464   0.14353599]\n",
      " [0.6281056  0.37189445]\n",
      " [0.8691317  0.13086827]\n",
      " [0.8730727  0.12692733]\n",
      " [0.612521   0.387479  ]] [0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1] tensor(16)\n",
      "tensor(21.3262, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.8140891  0.18591085]\n",
      " [0.53075004 0.46924996]\n",
      " [0.83118504 0.16881491]\n",
      " [0.8238802  0.17611983]\n",
      " [0.83998007 0.1600199 ]\n",
      " [0.849563   0.15043698]\n",
      " [0.84216535 0.15783462]\n",
      " [0.83521134 0.16478865]\n",
      " [0.8262331  0.17376696]\n",
      " [0.8445872  0.15541282]\n",
      " [0.84676135 0.15323867]\n",
      " [0.8428523  0.15714768]\n",
      " [0.8360702  0.16392983]\n",
      " [0.8328312  0.16716884]\n",
      " [0.8350508  0.16494918]\n",
      " [0.8416129  0.1583871 ]\n",
      " [0.8585522  0.14144778]\n",
      " [0.8356821  0.16431786]\n",
      " [0.8532271  0.14677294]\n",
      " [0.82539105 0.17460893]\n",
      " [0.82689816 0.17310186]\n",
      " [0.8273878  0.17261218]\n",
      " [0.84535074 0.15464924]\n",
      " [0.8391998  0.16080026]\n",
      " [0.5348088  0.46519113]\n",
      " [0.8592128  0.14078724]\n",
      " [0.53148293 0.46851704]\n",
      " [0.83698326 0.16301669]\n",
      " [0.5226105  0.47738948]\n",
      " [0.84512454 0.1548755 ]\n",
      " [0.5418657  0.45813423]\n",
      " [0.8432755  0.15672448]] [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0] tensor(16)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[[0.5278567  0.47214326]\n",
      " [0.8354367  0.1645633 ]\n",
      " [0.8319281  0.16807188]\n",
      " [0.5313636  0.4686364 ]\n",
      " [0.81348944 0.18651053]\n",
      " [0.8411792  0.15882085]\n",
      " [0.84555686 0.15444319]\n",
      " [0.8383831  0.16161686]\n",
      " [0.5339314  0.46606863]\n",
      " [0.8343205  0.16567947]\n",
      " [0.8588596  0.14114037]\n",
      " [0.8533407  0.14665927]\n",
      " [0.85489947 0.14510055]\n",
      " [0.81524193 0.18475802]\n",
      " [0.8381864  0.16181357]\n",
      " [0.823142   0.17685804]\n",
      " [0.82970977 0.17029029]\n",
      " [0.83743334 0.16256672]\n",
      " [0.5377291  0.46227098]\n",
      " [0.8164302  0.18356977]\n",
      " [0.83572155 0.16427842]\n",
      " [0.8525374  0.14746268]\n",
      " [0.53442234 0.46557763]\n",
      " [0.53385687 0.46614316]\n",
      " [0.8447187  0.15528136]\n",
      " [0.8414517  0.15854831]\n",
      " [0.8469358  0.15306415]\n",
      " [0.5377576  0.4622425 ]\n",
      " [0.8414614  0.15853862]\n",
      " [0.8430918  0.15690827]\n",
      " [0.8348687  0.16513132]\n",
      " [0.83504033 0.1649597 ]] [1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0] tensor(16)\n",
      "tensor(19.4263, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.7945052  0.20549487]\n",
      " [0.46002746 0.53997254]\n",
      " [0.7952036  0.20479636]\n",
      " [0.80432284 0.19567716]\n",
      " [0.804724   0.19527599]\n",
      " [0.82148904 0.17851098]\n",
      " [0.805884   0.19411601]\n",
      " [0.8092429  0.19075707]\n",
      " [0.8001537  0.19984627]\n",
      " [0.8183153  0.18168461]\n",
      " [0.8111645  0.1888355 ]\n",
      " [0.82092625 0.17907372]\n",
      " [0.8069248  0.1930752 ]\n",
      " [0.8053442  0.19465578]\n",
      " [0.8084109  0.19158909]\n",
      " [0.8199207  0.1800793 ]\n",
      " [0.8273812  0.17261882]\n",
      " [0.7976461  0.20235391]\n",
      " [0.8343883  0.16561167]\n",
      " [0.8039928  0.19600719]\n",
      " [0.8031109  0.19688912]\n",
      " [0.79766023 0.20233974]\n",
      " [0.8155467  0.18445334]\n",
      " [0.8128017  0.1871983 ]\n",
      " [0.4577677  0.5422323 ]\n",
      " [0.8498681  0.15013182]\n",
      " [0.45406133 0.54593873]\n",
      " [0.7962     0.2038    ]\n",
      " [0.44840026 0.55159974]\n",
      " [0.81852657 0.18147346]\n",
      " [0.46178648 0.53821355]\n",
      " [0.81486326 0.18513677]] [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0] tensor(16)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[[0.8080351  0.1919649 ]\n",
      " [0.78075826 0.21924175]\n",
      " [0.81319827 0.18680173]\n",
      " [0.4562374  0.54376256]\n",
      " [0.81084085 0.18915917]\n",
      " [0.8081508  0.19184917]\n",
      " [0.79866266 0.20133731]\n",
      " [0.81996906 0.18003093]\n",
      " [0.8055226  0.19447741]\n",
      " [0.82123274 0.17876726]\n",
      " [0.45521164 0.5447883 ]\n",
      " [0.8045081  0.19549191]\n",
      " [0.810771   0.18922903]\n",
      " [0.7902021  0.20979795]\n",
      " [0.78712696 0.21287306]\n",
      " [0.45432496 0.54567504]\n",
      " [0.8133603  0.18663979]\n",
      " [0.8160908  0.18390916]\n",
      " [0.8315832  0.16841683]\n",
      " [0.8265862  0.17341389]\n",
      " [0.7828789  0.21712111]\n",
      " [0.8094648  0.19053511]\n",
      " [0.79800904 0.20199096]\n",
      " [0.8082355  0.19176446]\n",
      " [0.4571884  0.5428116 ]\n",
      " [0.80768776 0.19231227]\n",
      " [0.79770917 0.2022909 ]\n",
      " [0.45551527 0.5444848 ]\n",
      " [0.45915166 0.5408483 ]\n",
      " [0.8023245  0.19767554]\n",
      " [0.81216574 0.18783432]\n",
      " [0.78612435 0.21387562]] [0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0] tensor(16)\n",
      "tensor(18.5220, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.7959835  0.20401652]\n",
      " [0.42492494 0.5750751 ]\n",
      " [0.81580704 0.18419291]\n",
      " [0.8144951  0.18550488]\n",
      " [0.81985277 0.18014726]\n",
      " [0.83415526 0.16584474]\n",
      " [0.81911683 0.18088318]\n",
      " [0.82009554 0.17990442]\n",
      " [0.8086072  0.1913927 ]\n",
      " [0.8329731  0.16702694]\n",
      " [0.82695913 0.1730409 ]\n",
      " [0.8331666  0.16683343]\n",
      " [0.8224046  0.17759532]\n",
      " [0.81581694 0.18418309]\n",
      " [0.8243385  0.1756615 ]\n",
      " [0.82834315 0.17165686]\n",
      " [0.8439206  0.15607944]\n",
      " [0.81517494 0.1848251 ]\n",
      " [0.84550893 0.154491  ]\n",
      " [0.81435347 0.18564652]\n",
      " [0.8086051  0.1913949 ]\n",
      " [0.80934083 0.19065915]\n",
      " [0.8298989  0.17010115]\n",
      " [0.8209777  0.17902227]\n",
      " [0.41975766 0.5802424 ]\n",
      " [0.85265195 0.14734805]\n",
      " [0.4186559  0.58134407]\n",
      " [0.808591   0.19140895]\n",
      " [0.41200566 0.58799434]\n",
      " [0.8404177  0.15958232]\n",
      " [0.42423442 0.5757656 ]\n",
      " [0.8284071  0.17159282]] [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0] tensor(16)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[[0.8281025  0.17189749]\n",
      " [0.81831855 0.18168145]\n",
      " [0.8300835  0.16991656]\n",
      " [0.8526854  0.1473146 ]\n",
      " [0.85047454 0.14952551]\n",
      " [0.81453574 0.18546422]\n",
      " [0.83661956 0.16338046]\n",
      " [0.42157027 0.57842976]\n",
      " [0.81653595 0.18346407]\n",
      " [0.8443685  0.15563142]\n",
      " [0.42300427 0.57699573]\n",
      " [0.82271916 0.17728084]\n",
      " [0.82475317 0.17524688]\n",
      " [0.42278355 0.5772165 ]\n",
      " [0.8098626  0.19013737]\n",
      " [0.83065647 0.16934349]\n",
      " [0.8368045  0.16319545]\n",
      " [0.85329264 0.14670739]\n",
      " [0.4254772  0.57452273]\n",
      " [0.83194304 0.16805698]\n",
      " [0.79576176 0.2042382 ]\n",
      " [0.8209425  0.17905751]\n",
      " [0.85244846 0.14755155]\n",
      " [0.7994861  0.20051387]\n",
      " [0.8253237  0.17467633]\n",
      " [0.81733114 0.18266882]\n",
      " [0.428915   0.571085  ]\n",
      " [0.80468905 0.195311  ]\n",
      " [0.8202971  0.17970286]\n",
      " [0.42365047 0.57634956]\n",
      " [0.7976516  0.20234844]\n",
      " [0.8294336  0.17056638]] [0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0] tensor(16)\n",
      "tensor(16.7060, grad_fn=<AddBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[0.8624195  0.13758045]\n",
      " [0.41656044 0.5834395 ]\n",
      " [0.87788653 0.12211344]\n",
      " [0.87548417 0.12451586]\n",
      " [0.8877667  0.11223324]\n",
      " [0.8940257  0.1059743 ]\n",
      " [0.87893736 0.12106259]\n",
      " [0.87949276 0.12050728]\n",
      " [0.8763758  0.12362412]\n",
      " [0.88618034 0.11381967]\n",
      " [0.8888254  0.11117462]\n",
      " [0.8881717  0.11182833]\n",
      " [0.8768686  0.12313139]\n",
      " [0.87555295 0.12444708]\n",
      " [0.88437444 0.11562559]\n",
      " [0.8896337  0.11036628]\n",
      " [0.89700216 0.10299791]\n",
      " [0.8756244  0.12437558]\n",
      " [0.8960118  0.10398816]\n",
      " [0.8779276  0.12207238]\n",
      " [0.87186927 0.12813078]\n",
      " [0.8718056  0.12819436]\n",
      " [0.8841986  0.11580144]\n",
      " [0.88324434 0.11675565]\n",
      " [0.4208662  0.57913375]\n",
      " [0.90096676 0.09903319]\n",
      " [0.42395863 0.57604134]\n",
      " [0.8750173  0.12498272]\n",
      " [0.4110588  0.58894116]\n",
      " [0.89357835 0.10642163]\n",
      " [0.4266971  0.57330287]\n",
      " [0.8877659  0.11223409]] [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0] tensor(16)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "batch_size = 256\n",
    "for epoch in range(500):\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    agg_loss = 0\n",
    "    inst_idxs = list(range(len(ys) - 100))\n",
    "    random.shuffle(inst_idxs)\n",
    "\n",
    "    counter = 0\n",
    "    for i in inst_idxs:\n",
    "        counter += 1        \n",
    "\n",
    "        t_mask = train_sets[i]\n",
    "        s_mask = get_solution_mask(t_mask, 0.5)\n",
    "        nf, mask = get_mask_node_feature(node_features[i], ys[i], s_mask)\n",
    "        \n",
    "        output, _ = model(\n",
    "            nf, \n",
    "            c_v_edges[i], \n",
    "            v_c_edges[i], \n",
    "            edge_features[i].detach()\n",
    "        )\n",
    "        fl = FocalLoss()\n",
    "\n",
    "        train_mask = torch.cat([~t_mask, torch.zeros(len(mask) - len(t_mask), dtype=torch.bool)])\n",
    "        loss = fl(output[train_mask, :], ys[i][train_mask])\n",
    "        agg_loss += loss\n",
    "        \n",
    "        if counter >= batch_size:\n",
    "            (agg_loss/batch_size).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "            optimizer.step()\n",
    "            print(output[train_mask, :].detach().numpy(), ys[i][train_mask].detach().numpy(), mask.sum())\n",
    "            print(agg_loss)\n",
    "            \n",
    "            print('-'*100)\n",
    "            test_idx = -1\n",
    "            \n",
    "            t_mask = train_sets[test_idx]\n",
    "            s_mask = get_solution_mask(t_mask, 0.5)\n",
    "            nf, mask = get_mask_node_feature(node_features[test_idx], ys[test_idx], s_mask)\n",
    "            output, _ = model(\n",
    "                nf, \n",
    "                c_v_edges[test_idx], \n",
    "                v_c_edges[test_idx], \n",
    "                edge_features[test_idx].detach()\n",
    "            )\n",
    "            test_mask = torch.cat([~t_mask, torch.zeros(len(mask) - len(t_mask), dtype=torch.bool)])\n",
    "            print(output[test_mask, :].detach().numpy(), ys[test_idx][test_mask].detach().numpy(), mask.sum())\n",
    "            print('^'*100)\n",
    "            agg_loss = 0\n",
    "            counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_features = []\n",
    "con_features = []\n",
    "edg_features = []\n",
    "solutions = []\n",
    "\n",
    "for i in range(1):\n",
    "    m = maximum_independent_set_problem()\n",
    "    info = ModelInfo.from_model(m)\n",
    "    var_features.append(VarFeature.from_info(info.var_info, info.obj_info))\n",
    "    con_features.append(ConFeature.from_info(info.con_info))\n",
    "    edg_features.append(EdgFeature.from_info(info.con_info))\n",
    "    m.optimize()\n",
    "    s = [v.x for v in m.getVars()]\n",
    "    solutions.append(s)\n",
    "\n",
    "inst = Inst(var_features, con_features, edg_features, solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = build_partial_model(info, const_vars={1: 0.5, 2: 0.5})\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys[i].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = Inst(\n",
    "    [VarFeature.from_info(info.var_info, info.obj_info)],\n",
    "    [ConFeature.from_info(info.con_info)],\n",
    "    [EdgFeature.from_info(info.con_info)],\n",
    "    [[v.x for v in m.getVars()]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for epoch in range(10):\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    agg_loss = 0\n",
    "    for i in range(5):\n",
    "        inst_idx = random.randint(0, len(ys) - 1)\n",
    "        train_idx = torch.as_tensor(range(2), dtype=torch.int32)\n",
    "        \n",
    "        output, edge_features[inst_idx] = model(\n",
    "            node_features[inst_idx], \n",
    "            c_v_edges[inst_idx], \n",
    "            v_c_edges[inst_idx], \n",
    "            edge_features[inst_idx].detach()\n",
    "        )\n",
    "        fl = FocalLoss()\n",
    "        loss = fl(output[train_idx], ys[inst_idx][train_idx])\n",
    "        agg_loss += loss\n",
    "        \n",
    "    print(output[train_idx].detach().numpy(), ys[inst_idx][train_idx].detach().numpy())\n",
    "    print(agg_loss)\n",
    "    \n",
    "    agg_loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, num):\n",
    "    global data_edge_features\n",
    "    t = time.time()\n",
    "\n",
    "    output, data_edge_features[num] = model(data_features[num], data_edge_A[num], data_edge_B[num], data_edge_features[num].detach())\n",
    "    print(data_solution[num][idx_train])\n",
    "\n",
    "    lf = Focal_Loss(torch.as_tensor(data_labels[num]))\n",
    "    loss_train = lf(output[idx_train], data_solution[num][idx_train])\n",
    "\n",
    "    return loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_total = time.time()\n",
    "loss_values = []\n",
    "for epoch in range(args.epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    now_loss = 0\n",
    "    \n",
    "    for i in range(5):\n",
    "        now_data = random.randint(0, data_num - 1)\n",
    "        now_loss += train(epoch, now_data)\n",
    "        \n",
    "    loss_values.append(now_loss)\n",
    "    now_loss.backward()\n",
    "    optimizer.step()\n",
    "    print('Epoch: {:04d}'.format(epoch+1),\n",
    "          'loss_train: {:.4f}'.format(now_loss))\n",
    "\n",
    "    torch.save(model.state_dict(), '{}.pkl'.format(epoch))\n",
    "    if loss_values[-1] < best:\n",
    "        best = loss_values[-1]\n",
    "        best_epoch = epoch\n",
    "        bad_counter = 0\n",
    "    else:\n",
    "        bad_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and optimizer\n",
    "model = SpGAT(nfeat=data_features[0].shape[1],    # Feature dimension\n",
    "            nhid=args.hidden,             # Feature dimension of each hidden layer\n",
    "            nclass=int(data_solution[0].max()) + 1, # Number of classes\n",
    "            dropout=args.dropout,         # Dropout\n",
    "            nheads=args.nb_heads,         # Number of heads\n",
    "            alpha=args.alpha)             # LeakyReLU alpha coefficient\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),    \n",
    "                       lr=args.lr,                        # Learning rate\n",
    "                       weight_decay=args.weight_decay)    # Weight decay to prevent overfitting\n",
    "\n",
    "if args.cuda: # Move to GPU\n",
    "    model.to(device)\n",
    "    for now_data in range(data_num):\n",
    "        data_features[now_data] = data_features[now_data].to(device)\n",
    "        data_labels[now_data] = data_labels[now_data].to(device)\n",
    "        data_solution[now_data] = data_solution[now_data].to(device)\n",
    "        data_edge_A[now_data] = data_edge_A[now_data].to(device)\n",
    "        data_edge_B[now_data] = data_edge_B[now_data].to(device)\n",
    "        data_edge_features[now_data] = data_edge_features[now_data].to(device)\n",
    "        data_idx_train[now_data] = data_idx_train[now_data].to(device)\n",
    "\n",
    "\n",
    "for now_data in range(data_num):\n",
    "    data_features[now_data] = Variable(data_features[now_data])\n",
    "    data_edge_A[now_data] = Variable(data_edge_A[now_data])\n",
    "    data_edge_B[now_data] = Variable(data_edge_B[now_data])\n",
    "    data_solution[now_data] = Variable(data_solution[now_data])\n",
    "    # Define computation graph for automatic differentiation\n",
    "\n",
    "def train(epoch, num):\n",
    "    global data_edge_features\n",
    "    t = time.time()\n",
    "\n",
    "    output, data_edge_features[num] = model(data_features[num], data_edge_A[num], data_edge_B[num], data_edge_features[num].detach())\n",
    "    print(data_solution[num][idx_train])\n",
    "\n",
    "    lf = Focal_Loss(torch.as_tensor(data_labels[num]))\n",
    "    loss_train = lf(output[idx_train], data_solution[num][idx_train])\n",
    "\n",
    "    return loss_train\n",
    "\n",
    "t_total = time.time()\n",
    "loss_values = []\n",
    "bad_counter = 0\n",
    "best = args.epochs + 1\n",
    "best_epoch = 0\n",
    "for epoch in range(args.epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    now_loss = 0\n",
    "    for i in range(5):\n",
    "        now_data = random.randint(0, data_num - 1)\n",
    "        now_loss += train(epoch, now_data)\n",
    "    loss_values.append(now_loss)\n",
    "    now_loss.backward()\n",
    "    optimizer.step()\n",
    "    print('Epoch: {:04d}'.format(epoch+1),\n",
    "          'loss_train: {:.4f}'.format(now_loss))\n",
    "\n",
    "    torch.save(model.state_dict(), '{}.pkl'.format(epoch))\n",
    "    if loss_values[-1] < best:\n",
    "        best = loss_values[-1]\n",
    "        best_epoch = epoch\n",
    "        bad_counter = 0\n",
    "    else:\n",
    "        bad_counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
